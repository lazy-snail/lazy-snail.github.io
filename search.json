[{"title":"","url":"/2022/06/21/java/spring/AOP/","content":"AOPAOP是一种编程思想。日志、安全、事务管理、缓存等，在软件系统中都是非常重要的功能，但它们与软件本身所关注的“功能”即业务逻辑，从概念上讲（应该）是分离的，然而它们散布嵌入在业务逻辑之中，需要在业务逻辑功能执行的过程中被动地触发。这些功能通常被称为横切关注点（cross-cutting concern）。把这些横切关注点与业务逻辑相分离就是面向切面编程（AOP，Aspect Oriented Programming），实现横切关注点与它们所影响的对象之间的解耦。重用通用功能的方案一般为继承或委托，而切面是另一种实现该目标的方案。在使用面向切面编程时，仍然在一个地方定义通用功能，但是可以通过声明的方式定义这个功能要以合何种方式在何处应用，而无需修改受影响的类。横切关注点可以被模块化为特殊的类，这些类被称为切面（aspect）。有两个好处：\n\n每个关注点都集中在一个地方，而不是分散在多处代码中；\n服务模块更加简洁，因为它们都只包含主要关注点（核心功能）的代码，而次要关注的代码被转移到切面中。\n\n相关术语增强 advice切面的工作被称为增强。增强定义了切面是什么以及何时使用（what and when）。除了描述切面要完成的工作，增强还解决了何时执行这个工作的问题：它应该应用在某个方法被调用之前、之后还是只在方法抛出异常时，等。Spring切面支持5种类型的增强：\n\n前置增强（Before）：在目标方法被调用之前调用增强功能；\n后置增强（After）：在目标方法完成之后调用增强，此时不会关心方法的输出是什么；\n环绕增强（Around）：在被增强方法调用前后都执行自定义的行为；\n返回增强（After-returning）：在目标方法成功执行之后调用增强；\n异常增强（After-throwing）：在目标方法抛出异常之后调用增强。\n\n连接点 join point应用增强的时机，被称为连接点。连接点是在应用执行过程中能够插入切面的一个点，这个点可以是调用方法时、抛出异常时、甚至修改一个字段时，切面代码可以利用这些点插入到应用的正常流程之中，并添加新的行为。\n切点 pointcut增强定义了切面的“what”和“when”，切点定义了切面的“where”，切点的定义会匹配增强所要织入的一个或多个连接点。通常使用明确的类和方法名，或利用正则表达式定义所匹配的类和方法名来指定这些切点。\n切面 aspect切面是增强和切点的结合。增强和切点共同定义了切面的全部内容——它是什么，在何时何处完成其功能。 \n引入 introduction引入允许向现有的类添加新方法或属性，从而在无需修改现有类的情况下，让这些类具有新的行为和状态。是一种特殊的增强。\n织入 weaving把切面应用到目标对象并创建新的代理对象的过程。切面在指定的连接点被织入到目标对象中，在目标对象的生命周期里有多个点可以进行织入：\n\n编译期：切面在目标类编译时被织入。这种方式需要特殊的编译器。AspectJ的织入编译器就是以这种方式织入切面的。\n类加载期：切面在目标类加载到JVM时被织入。这种方式需要特殊的类加载器，它可以在目标类被引入应用之前增强该目标类的字节码。AspectJ 5的加载时织入（load-time weaving，LTW）就支持以这种方式织入切面。\n运行期：切面在应用运行的某个时刻被织入。一般，在织入切面时，AOP容器会为目标对象动态地创建一个代理对象。Spring AOP就是以这种方式织入切面的。\n\nSpring种的AOPAOP框架在连接点模型上有强弱之分，比如有些允许在字段修饰符级别应用增强，有些只支持与方法调用相关的连接点。此外，框架织入切面的方式和时机也有所不同。但无论如何，创建切点来定义切面所织入的连接点是AOP框架的基本功能。\nSpring提供4种类型的AOP支持：\n\n基于代理的经典Spring AOP（现在来看笨重且复杂）；\n纯POJO切面（需要xml配置）；\n@AspectJ注解驱动的切面（本质上依然是基于代理的AOP）；\n注入式AspectJ切面（基本的方法调用级别切面满足不了需求时）。\n\n前三种都是Spring AOP实现的变体。Spring AOP构建在动态代理基础之上，因此，Spring对AOP的支持局限于方法拦截。\n运行时增强对象通过在代理类中包裹切面，Spring在运行期把切面织入到Spring管理的bean中。代理类封装了目标类，拦截被增强方法的调用，再把调用转发给真正的目标bean。即代理类处理方法的调用，执行额外的切面逻辑，并调用目标方法。Spring运行时才创建代理对象。\n切点类型Spring提供6种类型的切点：\n\n静态方法切点：org.springframework.aop.support.StaticMethodMatcherPointcut是静态方法切点的抽象基类，默认情况下它可以匹配所有的类。包含两个主要的子类：NameMatchMethodPointcut &amp; AbstractRegexpMethodPointcut，前者提供简单的字符串匹配方法签名，后者使用正则表达式匹配方法签名；\n动态方法切点：org.springframework.aop.support.DynamicMethodMatcherPointcut是动态方法切点的抽象基类，默认情况下匹配所有的类；\n注解切点：org.springframework.aop.support.annotation.AnnotationMatchingPointcut的实现类表示注解切点，支持在Bean中直接通过java5.0注解标签定义的切点；\n表达式切点：org.springframework.aop.support.ExpressionPointcut接口主要是为了支持AspectJ切点表达式语法而定义的接口；\n流程切点：org.springframework.aop.support.ControlFlowPointcut实现类表示控制流程切点。ControlFlowPointcut是一类特殊的切点，它根据程序执行堆栈的信息查看目标方法\n\n","categories":[],"tags":[]},{"title":"","url":"/2022/06/21/java/spring/SpringBoot%E5%90%AF%E5%8A%A8%E6%B5%81%E7%A8%8B/","content":"SpringBoot启动流程","categories":[],"tags":[]},{"title":"","url":"/2022/06/21/java/spring/ThreadLocal/","content":"ACA系统API Server层需要从BCE-WebFramework框架获取request-id等信息，涉及ThreadLocal相关内容，稍作整理。\nThreadLocalThreadLocal用于提供线程局部变量。在多线程环境可以保证各个线程里的变量独立于其它线程里的变量，即ThreadLocal可以为每个线程创建一个单独的变量副本，相当于线程里的 private static类型变量。ThreadLocal的作用和同步机制有些相反：同步机制是为了保证多线程环境下数据的一致性；ThreadLocal是保证多线程环境下数据的独立性。\n代码实现ThreadLocal的构造方法是一个简单无参方法，并且没有任何实现。\nset()方法public void set(T value) &#123;\n    Thread t = Thread.currentThread();\n    ThreadLocalMap map = getMap(t);\n    if (map != null)\n        map.set(this, value);\n    else\n        createMap(t, value);\n&#125;\n首先获取当前线程，然后获取当前线程的ThreadLocalMap，如果不为null，则将value保存到map中，并用当前ThreadLocal作为key，否则创建一个ThreadLocalMap并给到当前线程，然后保存value。\nget()public T get() &#123;\n    Thread t = Thread.currentThread();\n    ThreadLocalMap map = getMap(t);\n    if (map != null) &#123;\n        ThreadLocalMap.Entry e = map.getEntry(this);\n        if (e != null) &#123;\n            @SuppressWarnings(\"unchecked\")\n            T result = (T)e.value;\n            return result;\n        &#125;\n    &#125;\n    return setInitialValue();\n&#125;\n同样，get()也会获取当前线程的ThreadLoalMap，如果不为null，则获取以当前线程为key的value；否则调用setInitialValue()返回初始值（默认设置为null，子类可重写），并保存到新创建的ThreadLocalMap中。\nremove()public void remove() &#123;\n    ThreadLocalMap m = getMap(Thread.currentThread());\n    if (m != null)\n        m.remove(this);\n&#125;\n用来移除当前ThreadLocal对应的值，通过当前线程的ThreadLocalMap来移除相应的值。\n场景","categories":[],"tags":[]},{"title":"","url":"/2022/06/21/java/spring/%E6%B3%A8%E8%A7%A3-Transactional/","content":"@TransactionalSpring事务管理分为编码式和声明式两种：编码式指通过编码方式实现事务；声明式事务基于AOP，将具体业务逻辑与事务处理解耦。声明式事务管理使得业务代码逻辑不不受污染，在实际场景中使用得更多。\n两种声明式事务：配置文件（xml等）和基于@Transactional注解。一般采用注解配置。\n简单使用Spring boot默认配置下，只需要在方法上添加@Transactional注解就可以了，以mybatis为例，spring boot会自动配置一个DataSourceTransactionManager，添加注解后就自动纳入Spring的事务管理。默认情况下，该注解要注意两个问题：\n\nSpring只会回滚运行时、未检查异常（继承自RuntimeException的异常）或者Error；\n只能应用到public方法上才有效。\n\n属性\nvalue、transactionManager：具有相同含义，当配置了多个事务管理器时，可以使用该属性指定事务管理器；\n\npropagation：事务的传播行为，默认为Propagation.REQUIRED，可选值有：\n\nPropagation.REQUIRED：如果当前存在事务，则加入该事务，如果不存在，则创建一个新的事务；\nPropagation.SUPPORTS：如果当前存在事务，则加入该事务；如果当前不存在事务，则以非事务的方式继续运行；\nPropagation.MANDATORY：如果当前存在事务，则加入该事务；如果当前不存在事务，则抛出异常；\nPropagation.REQUIRES_NEW：重新创建一个新的事务，如果当前存在事务，暂停当前的事务；\nPropagation.NOT_SUPPORTED：以非事务的方式运行，如果当前存在事务，暂停当前的事务；\nPropagation.NEVER：以非事务的方式运行，如果当前存在事务，则抛出异常；\nPropagation.NESTED：和Propagation.REQUIRED效果一样。\n\n\nisolation：事务的隔离级别，默认为Isolation.DEFAULT，可选值有：\n\nIsolation.DEFAULT：使用底层数据库默认的隔离级别；\nIsolation.READ_UNCOMMITTED；\nIsolation.READ_COMMITTED；\nIsolation.REPEATABLE_READ；\nIsolation.SERIALIZABLE。\n\n\ntimeout：事务超时时间，默认为-1，即不超时。如果超过该时间限制但事务还没有完成，则自动回滚事务。\n\nreadOnly：指定事务是否为只读事务，默认值为false。为了忽略那些不需要事务的方法，比如读取数据，可以设置read-only为true。\n\nrollbackFor：用于指定能够触发事务回滚的异常类型，可以指定多个异常类型。\n\nnoRollbackFor：抛出指定的异常类型，不回滚事务，也可以指定多个异常类型。\n\n\nspring中的@TransactionalTransactional 可以作用于接口、接口方法、类以及类方法上。当作用于类上时，该类的所有 public 方法将都具有该类型的事务属性，同时也可以在方法级别使用该标注来覆盖类级别的定义。Spring 建议不要在接口或者接口方法上使用该注解，因为这只有在使用基于接口的代理时它才会生效；并且应该只被应用到 public 方法上，这是由 Spring AOP 的本质决定的。如果在 protected、private 或者默认可见性的方法上使用 @Transactional 注解，这将被忽略，也不会抛出任何异常。不建议在Dao层使用事务注解，一般在Service实现层。@Transactional 可以继承，并且使用方法级别优先类级别和最近原则，而且不会将所有的 @Transactional 结合使用。在使用基于 ORM 的框架时，只读标志基本上毫无用处，在大多数情况下会被忽略。如果使用它，将传播模式设置为SUPPORTS，这样就不会启动事务。\n","categories":[],"tags":[]},{"title":"","url":"/2022/06/21/java/spring/SpringMVC%20%E6%8B%A6%E6%88%AA%E5%99%A8/","content":"拦截器的概念拦截器Interceptor的拦截功能是基于Java的动态代理（反射机制）来实现的。\n","categories":[],"tags":[]},{"title":"","url":"/2022/06/21/java/spring/IoC/","content":"IoCInversion of Control，控制反转，也称依赖注入（DI，Dependency Injection）。应用对象之间的解耦。通常所讨论的依赖注入是将一个bean的引用注入到另一个bean的属性或构造器参数中，即将一个对象与另一个对象关联起来。java的反射是实现依赖注入的底层技术。依赖注入是Spring容器的内核，AOP、声明式事务等功能也都基于此。Spring是一种容器框架，它帮助完成类的初始化和装配工作，让开发者从这些底层实现类的实例化、依赖关系装配等工作中解脱出来，专注于业务逻辑的开发工作。它通过配置文件或注解描述类和类之间的依赖关系，利用java的反射功能实例化Bean并建立Bean之间的依赖关系，自动完成类的初始化和依赖注入工作。此外，Spring还提供Bean实例缓存、生命周期管理、Bean实例代理、事件发布、资源装载等高级服务。BeanFactory(com.springframework.beans.factory.BeanFactory)是Spring框架最核心的接口，它提供了高级IoC的配置机制。BeanFactory使管理不同类型的java对象成为可能，应用上下文(com.springframework.context.ApplicationContext)建立在BeanFactory基础之上，提供了更多面向应用的功能，如i18n和框架事件体系等，更易于创建实际应用。一般称BeanFactory为IoC容器，称ApplicationContext为应用上下文，有时也称后者为Spring容器。用途上，BeanFactory是Spring框架的基础设施，面向Spring本身；ApplicationContext面向使用Spring框架的开发者，几乎所有的应用场合都可以直接使用ApplicationContext而非底层的BeanFactory。\nBeanFactory和普通的工厂类不同，BeanFactory是类的通用工厂，它可以创建并管理各种类的对象。这些可被创建和管理的对象本身并没有什么特别之处，仅仅是一个POJO，Spring称这些被创建和管理的java对象为Bean。javaBean需要满足一定的规范：提供一个默认不带参数的构造方法；不依赖于某一特定的容器等。Spring所说的Bean比javaBean更宽泛一些，所有可以被Spring容器实例化并管理的java类都可以成为Bean。\nSpring为BeanFactory提供了多种实现，建议使用XmlBeanDefinitionReader、DefaultListableBeaFactory。BeanFactory接口位于类结构树的顶端，最主要的方法就是getBean(String beanName)，该方法从容器中返回特定名称的bean。BeanFactory的功能通过其它接口得到不断扩展。主要有：\n\nListableBeanFactory：该接口定义了访问容器中Bean基本信息的一些方法，如查看bean的个数、获取某一类型bean的配置名、查看容器中是否包括某一bean等；\nHierarchicalBeanFactory：父子级联IoC容器的接口，子容器可以通过接口方法访问父容器；\nConfigurableBeanFactory：增强了IoC容器的可定制性。它定义了设置类装载器、属性编辑器、容器初始化后置处理器等方法。是一个重要的接口；\nAutowireCapableBeanFactory：定义了将容器中的Bean按某种规则（如按名字匹配、按类型匹配等）进行自动装配的方法；\nSingletonBeanRegistry：定义了允许在运行期向容器注册单实例bean的方法；\nBeanDefinitionRegistry：Spring配置文件中每一个&lt;bean&gt;节点元素在Spring容器中都通过一个BeanDefinition对象表示，它描述了bean的配置信息。而该接口提供向容器手动注册BeanDefinition对象的方法；\n\n初始化XmlBeanDefinitionReader通过Resource装载Spring配置信息并启动IoC容器，然后就可以通过BeanFactory#getBean(beanName)从IoC容器获取bean。通过BeanFactory启动IoC容器时，并不会初始化配置文件中定义的bean，初始化动作发生在第一次调用时。对应单实例的bean来说，BeanFactory会缓存bean实例，所以第二次使用getBean()获取bean时，将直接从IoC容器的缓存中获取。Spring在DefaultSingletonBeanRegistry类中提供了一个用于缓存单实例bean的缓存器，由HashMap实现，单实例的bean以beanName为键保存在该map中。初始化BeanFactory时，必须为其提供一种日志框架，否则会报错。\nApplicationContext如果说BeanFactory是Spring的”心脏“，那么ApplicationContext就是完整的”身躯“。ApplicationContext由BeanFactory派生而来，提供了更多面向实际应用的功能。在BeanFactory中，很多功能需要以编程的方式实现，而在ApplicationContext中则可以通过配置的方式实现。ApplicationContext的主要实现类是ClassPathXmlApplicationContext和FileSystemXmlApplicationContext，前者默认从类路径加载配置文件，后者默认从文件系统中装载配置文件。可见，除继承HierarchicalBeanFactory和ListableBeanFactory接口外，ApplicationContext还通过多个其它接口扩展BeanFactory的功能：\n\nApplicationEventPublisher：让容器拥有发布应用上下文事件的功能，包括容器启动事件、关闭事件等。实现了ApplicationListener事件监听接口的Bean可以接收到容器事件，并对事件进行响应处理。在ApplicationContext抽象实现类AbstractApplicationContext中存在一个ApplicationEventMulticaster，它负责保存所有的监听器，以便在容器产生上下文事件时通知这些事件监听者；\nMessageSource：为应用提供i18n国际化消息访问的功能；\nResourcePatternResolver：所有ApplicationContext实现类都实现了类似于PathMatchingResourcePatternResolver的功能，可以通过带前缀的ant风格的资源文件路径装载Spring配置文件；\nLifeCycle：提供start()、和stop()，主要用于控制异步处理过程。在具体使用时，该接口同时被ApplicationContext实现以及具体Bean实现，ApplicationContext会将start&#x2F;stop的信息传递给容器中所有实现了该接口的Bean，以达到管理和控制JMX、任务调度等目的。\n\nConfigurableApplicationContext扩展于ApplicationContext，它新增了两个主要方法：refresh()、close()，使得ApplicationContext具有启动、刷新、关闭应用上下文的能力。在应用上下文关闭的情况下可以调用refresh()即可启动应用上下文，在已经启动的状态下调用refresh()则可清除缓存并重新装载配置信息，而调用close()则可关闭应用上下文。这些接口方法为容器的控制管理带来了便利，但作为开发者并不需要过多关心它们。  \n初始化和BeanFactory初始化类似，如果配置文件放在类路径下，优先考虑使用ClassPathXmlApplicationContext实现；如果放在文件系统路径下，则优先考虑FileSystemXmlApplicationContext实现。也可以指定一组配置文件，Spring会完成自动整合\u0010。获取ApplicationContext实例后，就可以像BeanFactory一样调用getBean(beaName)返回bean了。而ApplicationContext的初始化和BeanFactory有一个很大区别：后者在初始化容器时，并未初始化所有的Bean，直到第一次访问某个Bean时才实例化该目标Bean；而ApplicationContext则在初始化应用上下文时就实例化所有单实例的Bean。因此，ApplicationContext的初始化时间会比BeanFactory稍长。Spring支持基于类注解的配置方式，主要功能来自JavaConfig的子项目。一个标注了@Configuration注解的POJO即可提供Spring所需的Bean配置信息。而且Spring为基于注解类的配置专门提供了ApplicationContext实现类：AnnotationConfigApplicationContext，可以直接调用方法实例化Bean，启动容器并装配Bean。\nWebApplicationContextWebApplicationContext是专门为Web应用准备的，它允许从相对于Web根目录的路径中装载配置文件完成初始化工作。从WebApplicationContext中可以获得ServletContext的引用，整个Web应用上下文对象将作为属性放置到ServletContext中，以便Web应用环境可以访问Spring应用上下文。Spring专门为此提供了一个工具类WebApplicationContextUtils，通过该类的getWebApplicationContext(ServletContext sc)，可以从ServletContext中获取WebApplicationContext实例。在非Web应用的环境下，Bean只有singleton、prototype两种作用域。WebApplicationContext为Bean添加了三个新的作用域：request、session、global session。ConfigurableWebApplicationContext扩展了WebApplicationContext，它允许通过配置的方式实例化WebApplicationContext，同时定义了两个重要方法：\n\nsetServletContext(ServletContext servletContext)：为Spring设置Web应用上下文，以便二者整合；\nsetConfigLocations(String[] configLocations)：设置Spring配置文件地址，一般是相对于Web根目录的地址，如&#x2F;WEB-INF&#x2F;xxx-dao.xml、&#x2F;WEB-INF&#x2F;xxx-service.xml。用户也可以使用带资源类型前缀的地址，如classpath:com&#x2F;baidu&#x2F;beans.xml等。\n\n初始化WebApplicationContext的初始化方式和BeanFactory、ApplicationContext有所区别，因为需要ServletContext实例。即必须在拥有Web容器的前提下才能完成启动工作，可以在web.xml中配置自启动的Servlet或定义Web容器监听器(ServletContextListener)，二者均可完成启动Spring Web应用上下文的工作。Spring为二者均提供了支持：\n\norg.springframework.web.context.ContextLoaderServlet\norg.springframework.web.context.ContextLoaderListener\n\n二者内部都实现了启动WebApplicationContext实例的逻辑，只需根据Web容器的具体情况选择其一并在web.xml中完成配置即可。\nWebApplicationContext同样需要日志功能，可以将Log4J配置文件放置在类路径&#x2F;WEB-INF&#x2F;classes下以便启动Log4J引擎。或在web.xml文件指定自定义的配置文件位置。\n注解基本上，@Component和@Service具有相同的效果：这两个注解都告诉Spring，注解的类是使用基于注解的配置和类路径扫描进行自动检测时的候选对象。事实上，@Service是@Component的一个特例，它表明注解的类正在向应用程序中的其它层提供业务服务。\n反射主要涉及java类加载机制，参考《深入理解java虚拟机》。每个类在jvm中都拥有一个对应的java.lang.Class对象，即类描述对象，它提供了类结构信息的描述。数组、枚举、注解、基本数据类型、void等都有对应的Class对象。Class反射对象描述类语义结构，可以从Class对象中获取构造方法、成员变量、方法类等类元素的反射对象，并以编程的方式通过这些反射对象对目标类对象进行操作。这些反射对象类在java.reflect包中定义。主要的反射类：\n\nConstructor：类的构造函数反射类。通过Class#getConstructor()可以获取类的所有构造方法反射对象数组。Constructor的一个主要方法是newInstance(Object… initargs)，通过该方法可以创建一个对象类的实例，相当于new关键字。\nMethod：类方法的反射类。通过Class#getDeclaredMethods()可以获取类的所有方法反射类对象数组Method[]。Method主要的方法有：\ninvoke(Object obj, Object… args)；\nClass getReturnType()：获取方法的返回值类型；\nClass[] getParameterTypes()：获取方法的入参类型数组；\nAnnotation[][] getParameterAnnotations()：获取方法的注解信息。\n\n\nField：类的成员变量的反射类。通过Class#getDeclaredFields()可以获取类的成员变量反射对象数组，通过Class#getDeclaredField(String name)则可以获得某个特定名称的成员变量反射对象。其最主要的方法是set(Object obj, Object value)，通过value为操作对象obj赋值。如果成员变量为基础类型，则可以使用Field类中提供的带类型名的值设置方法，如setBoolean(Object obj, boolean value)。\n\n此外，java还为包提供了Package反射类，为注解提供了AnnotatedElement反射类。总之，java的反射体系保证了可以通过程序化的方式访问目标类中所有的元素，对于private或protectec成员变量和方法，只要jvm的安全机制允许，也可以通过反射进行调用，此时需要通过setAccessible(boolean access)取消java语言检查，否则将抛出IllegalAccessException。如果jvm安全管理器设置了相应的安全机制，调用会抛出SecurityException。\n","categories":[],"tags":[]},{"title":"","url":"/2022/06/21/db/sql-join/","content":"sql join语句INNER JOIN(JOIN) 内连接&#x2F;等值连接获取两个表中字段匹配关系的记录。如tb_auth和tb_job可以以user_id作为连接字段。一般使用ON来设定连接条件，使用WHERE进行结果的过滤，但ON也可以用WHERE代替。\n\nLEFT JOIN 左连接（左外连接）获取左表所有记录，即使右表没有对应匹配的记录。\n\nRIGHT JOIN 右连接与LEFT JOIN相反，获取右表所有记录，即使左表没有对应的记录。\n\nref：MYSQL数据库-join连接讲解\n","categories":[],"tags":[]},{"title":"","url":"/2022/06/21/db/%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB/","content":"READ UNCOMMITTED 未提交读事务的修改，即使还没有提交，对其他事务也是可见的。事务可以读取到其他事务修改但尚未提交的数据，即产生脏读（Dirty Read）。采用“读未提交”的翻译即可理解这个隔离级别可能产生的问题：即可能读到未提交的修改。\nREAD COMMITTED 提交读一个事务开始时，只能“看见”已经提交的事务所做的修改。即一个事务从开始直到提交之前，所做的任何修改对其他事务都是不可见的。但这可能造成的一个问题是，当一个事务多次读取同一数据，过程中，另一个事务完成了对该数据的修改并提交，导致前一事务两次读取结果不一致，即“不可重复读”问题。\nREPEATABLE READ 可重复读该级别保证在同一事务中多次读取同样记录的结果是一致的，解决了“不可重复度”问题。理论上，可重复读隔离级别无法解决另一个问题：幻读（Phantom Read），当某个事务在读取某个范围内的记录时，另一个事务又在该范围内插入了新的记录，当之前的事务再次读取该范围的记录时，会产生幻行（Phantom Row）。InnoDB通过多版本并发控制（MVCC, Multiversion Concurrency Control）解决幻读问题。\nMySQL默认事务隔离级别为可重复读。\n","categories":[],"tags":[]},{"title":"","url":"/2022/06/21/db/index1/","content":"…上述索引的作用中最关键的地方在于“优化查询速度”，那首先需要了解的是，一条sql语句，它的执行顺序是怎样的，才能更好地理解如何加速，以及背后的为什么能够加速。（比这个“首先”更首先需要了解的是，为什么要“优化”？无非一：数据量太大了；二：数据量太大了内存存不下而硬盘又太慢但又不得不放在硬盘上因为它很便宜。根因是数据量太大了，以至于不优化的话又回到了点个按钮可以喝杯咖啡再回来看结果的原始状态，用户就要爆炸，用户一爆炸老板就要爆炸，so…）…多数博客会用“书的目录”作解释，这是个很好的例子，为小白科普CS常识的时候可以用，我们还是用程序员之间的交流语言比较愉快。…综上，索引是关系型、大量数据场景下优化查询效率的产物。 同时既然老板们选择了便宜的存储介质，那就需要广大的程序员们奉献头发来尽可能减少“便宜”所带来的副作用，也就是访问过慢的问题了。…这就不可避免地要继续延伸索引的发展史了，从BST开始，因缺乏社交活动而时间精力异常充沛的程序员（中的大神）们尝试引入过很多方案，…\n","categories":[],"tags":[]},{"title":"","url":"/2022/06/21/OS/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%85%B1%E6%80%A7%E9%97%AE%E9%A2%98/","content":"系统和复杂性各式各样的系统的共性问题表现在以下4个方面：\n\nEmergent properties，隐性特征；\nPropagation of effects，传播效应；\nIncommensurate scaling，不相称的扩张；\nTrade-offs，权衡、取舍\n\n","categories":[],"tags":[]},{"title":"","url":"/2022/06/21/OS/%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/%E4%BB%A3%E7%90%86%E6%A8%A1%E5%BC%8F/","content":"代理模式Intent:Provide a surrogate or placeholder for another object to control access to it. 为其他对象提供一种代理以控制对这个对象的访问。\n代理的目的是在目标对象方法的基础上作增强，这种增强的本质通常是对目标对象的方法进行拦截、过滤。\n动态代理代理模式也称委托模式。许多其他的模式如状态模式、策略模式、访问者模式等，本质上是在更特殊的场合采用了委托模式。\n \n","categories":[],"tags":[]},{"title":"","url":"/2022/06/21/ING/N/","content":"0728jdk new featurespring frameworkrediskafkanettyzkdocker k8sES\n躲不开的 nio、多路复用、select、poll、epoll\n","categories":[],"tags":[]},{"title":"","url":"/2022/06/21/ING/Bean%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/","content":"什么是BeanIoC容器初始化这是第一步，包括配置解析、beanDefinition加载、注册等。\n容器初始化入口包括经典的ClassPathXmlApplicationContext、AnnotationConfigApplicationContext等，类似new ***ApplicationContext的方式，很少直接用于开发环境，一般是通过Spring MVC 中 ServletContext 为 Spring 的 IoC容器提供宿主环境，从宿主环境开始进行容器的初始化工作。初始化，或者说启动容器，实际上指的就是实例化ApplicationContext的这个动作。只是在不同情况下可能有不同的表现形式。以ClassPathXmlApplicationContext为例，容器初始化主要包括：\n\nBeanDefinition 的 Resource 定位这里的Resource定位 是通过继承ResourceLoader获得的，ResourceLoader代表了加载资源的一种方式，正是策略模式的实现；\n从 Resource中解析、载入BeanDefinition；\nBeanDefinition 在IoC 容器中的注册；\n\n实例化ApplicationContext这个上下文，就是在启动 IoC 容器，从它的构造函数入手：\npublic ClassPathXmlApplicationContext(String[] configLocations, boolean refresh, @Nullable ApplicationContext parent)\n\t\tthrows BeansException &#123;\n\n\tsuper(parent);\n\tsetConfigLocations(configLocations);\n\tif (refresh) &#123;\n\t\trefresh();\n\t&#125;\n&#125;\n入参中的configLocations在这里就是XML配置文件的classpath。setConfigLocations(configLocations)就是把一些带有占位符的地址解析成实际的地址。再之后就是refresh()，我们说的容器初始化，就是在这里面进行的，这里取名为refresh，是因为容器启动之后，再调用refresh()会刷新IoC容器。\nBean的生命周期Spring容器中Bean的生命周期由多个特定的阶段组成，每个阶段都允许外界对Bean加以控制。在Spring中可以从两个层面定义Bean的生命周期：Bean的作用范围；实例化Bean时所经理的一系列阶段。\n文字描述\nBean容器在配置文件中找到Spring Bean的定义。\n\nBean容器使用Java Reflection API创建Bean的实例。\n\n如果声明了任何属性，声明的属性会被设置。如果属性本身是Bean，则将对其进行解析和设置。以上步骤见“spring IoC 源码解析”。\n\n如果Bean类实现BeanNameAware接口，则将通过传递Bean的名称来调用setBeanName()方法。如果Bean类实现BeanClassLoaderAware接口，则将通过传递加载此Bean的ClassLoader对象的实例来调用setBeanClassLoader()方法。如果Bean类实现BeanFactoryAware接口，则将通过传递BeanFactory对象的实例来调用setBeanFactory()方法。如果有任何与BeanFactory关联的BeanPostProcessors对象已加载Bean，则将在设置Bean属性之前调用postProcessBeforeInitialization()方法。如果Bean类实现了InitializingBean接口，则在设置了配置文件中定义的所有Bean属性后，将调用afterPropertiesSet()方法。如果配置文件中的Bean定义包含init-method属性，则该属性的值将解析为Bean类中的方法名称，并将调用该方法。如果为Bean Factory对象附加了任何Bean 后置处理器，则将调用postProcessAfterInitialization()方法。如果Bean类实现DisposableBean接口，则当Application不再需要Bean引用时，将调用destroy()方法。如果配置文件中的Bean定义包含destroy-method属性，那么将调用Bean类中的相应方法定义。\n\n\nBeanFactory中Bean的生命周期具体过程：\n\n当调用者通过getBean(beanName)向容器请求某一个Bean时，如果容器注册了org.springframework.beans.factory.config.InstantiationAwareBeanPostProcessor接口，则在实例化Bean之前，将调用接口的postProcessBeforeInstantiation()；\n根据配置情况调用Bean构造方法或工厂方法实例化Bean；\n如果容器注册了InstantiationAwareBeanPostProcessor接口，那么在实例化Bean之后，调用该接口的postProcessAfterInstantiation()，可在这里对已经实例化的对象进行一些“梳妆打扮”；\n如果Bean配置了属性信息，那么容器在这一步着手将配置值设置到Bean对应的属性中，不过在设置每个属性之前将先调用InstantiationAwareBeanPostProcessor接口的postProcessPropertyValues()；\n调用Bean的属性设置方法设置属性值；\n如果Bean实现了org.springframework.beans.factory.BeanNameAware接口，则将调用setBeanName()，将配置文件中该Bean对应的名称设置到Bean中；\n如果Bean实现了org.springframework.beans.factory.BeanFactoryAware接口，则将调用setBeanFactory()，将BeanFactory容器实例设置到Bean中；\n如果BeanFactory装配了org.springframework.beans.factory.config.BeanPostProcessor后处理器，则将调用BeanPostProcessor的Object postProcessBeforeInitialization(Object bean, String beanName)对Bean进行加工操作。其中，入参bean是当前正在处理的bean，beanName时当前bean的配置名，返回的对象为加工处理后的Bean。可以使用该方法对Bean进行处理，甚至改变Bean的行为。BeanPostProcessor在Spring框架中占有重要地位，为容器提供对Bean进行后续加工处理的切入点，Spring容器所提供的各种“神奇功能”，如AOP，动态代理等，都是通过它来实施的；\n如果Bean实现了InitializingBean接口，则将调用接口的afterPropertiesSet()；\n如果在&lt;bean&gt;中通过init-method属性定义了初始化方法，则将执行这个方法；\nBeanPostProcessor后处理器定义了两个方法：其一是postProcessBeforeInitialization()，在(8)步调用；其二是Object postProcessAfterInitialization(Object bean, String beanName)，这个方法在此时调用，容器再次获得对Bean进行加工处理的机会；\n如果在&lt;bean&gt;中指定Bean的作用范围是scope&#x3D;”prototype”，则将Bean返回给调用者，调用者负责Bean后续生命周期的管理，Spring不再管理这个Bean的生命周期。如果将作用范围设置为scope&#x3D;”singleton”，则将Bean放入Spring IoC容器的缓存池中，并将Bean引用返回给调用者，Spring继续对这些Bean进行后续的生命管理；\n对于scope&#x3D;”singleton”的Bean（默认情况），当容器关闭时，将触发Spring对Bean后续生命周期的管理工作。如果Bean实现了DisposableBean接口，则将调用接口的destory()，可以在此编写释放资源、记录日志等操作；\n对于scope&#x3D;”singleton”的Bean，如果通过&lt;bean&gt;的destory-method属性指定了Bean的销毁方法，那么Spring将执行Bean的这个方法，完成Bean资源的释放等操作。\n\nBean的完整生命周期从Spring容器着手实例化Bean开始，直到最终销毁Bean。其中经过了许多关键点，每个关键点都涉及特定的方法调用，可以将这些方法大致分为4类：\n\nBean自身的方法：如调用Bean构造方法实例化Bean、调用setter设置Bean的属性值以及通过&lt;bean&gt;的init-method和destory-method所指定的方法；\nBean级生命周期接口方法：如BeanNameAware、BeanFactoryAware、InitializingBean和DisposableBean，这些接口方法由Bean类直接实现；\n容器级生命周期接口方法：图示中⭐标识的步骤是由InstantiationAwareBeanPostProcessor和BeanPostProcessor这两个接口实现的，一般称它们的实现类为“后处理器”。后处理器接口一般不由Bean本身实现，它们独立于Bean，实现类以容器附加装置的形式注册到Spring容器中，并通过接口反射为Spring容器扫描识别。当Spring创建任何Bean的时候，这些后处理器都会发生作用，所以这些后处理器的影响是全局性的。也可以自行编写后处理器，让其仅对感兴趣的Bean进行加工处理；\n工厂后处理器接口方法：包括AspectJWeavingEnabler、CustomAutowireConfigurer、ConfigurationClassPostProcessor等方法。工厂后处理器也是容器级的，在应用上下文装配配置文件后立即调用。\n\nApplicationContext中Bean的生命周期Bean在应用上下文中的生命周期和在BeanFactory中的生命周期类似，不同的是，如果Bean实现了org.springframework.context.ApplicationContextAware接口，则会增加一个调用接口方法setApplicationContext()的步骤。  \n作用域Spring定义了多种作用域：\n\n单例（singleton），在整个应用中，只创建bean的一个实例。\n原型（prototype），每次注入或者通过Spring应用上下文获取的时候，都会创建一个新的bean实例。\n会话（session），在web应用中，为每个会话创建一个bean实例。\n请求（request），在web应用中，为每个请求创建一个bean实例。\n\n默认情况下，Spring的所有bean都是单例（singleton）的。使用@Scope注解来选择其它作用域，它可与@Component、@Bean一起使用。两种方式（推荐1）：\n\n&#96;&#96;&#96;java @Component @Scope(ConfigurableBeanFactory.SCOPE_PROTOTYPE) public class AClass{…}2. &#96;&#96;&#96;java\n    @Component\n    @Scope(&quot;prototype&quot;)\n    public class AClass&#123;...&#125;\n\n   \t@Override\n\tpublic Object getBean(String name) throws BeansException &#123;\n\t\treturn doGetBean(name, null, null, false);\n\t&#125;\n\t\n在xxxConfig类中使用@Bean注解声明bean时和上述方式相同。会话和请求作用域，使用场景是web应用，从命名理解：会话作用域是指该bean的生命周期和一个会话的起始保持一致，比如典型的电商场景，用户登录，搜索商品，加入购物车，购买，付费，结束，这个流程就是一个完整的会话；请求作用域是指用户从发起一个请求开始，到服务器相应该请求的过程。这两种作用域的bean就是在该场景下，随着会话&#x2F;请求的生命周期实例化到销毁，典型的，如电商场景中的”购物车”。\n\n\nprotected BeanWrapper createBeanInstance(String beanName, RootBeanDefinition mbd, Object[] args) &#123;\n\t// Make sure bean class is actually resolved at this point.\n\t// 解析出 Class\n\tClass&lt;?> beanClass = resolveBeanClass(mbd, beanName);\n\n\tif (beanClass != null &amp;&amp; !Modifier.isPublic(beanClass.getModifiers()) &amp;&amp; !mbd.isNonPublicAccessAllowed()) &#123;\n\t\tthrow new BeanCreationException(mbd.getResourceDescription(), beanName,\n\t\t\t\t\"Bean class isn't public, and non-public access not allowed: \" + beanClass.getName());\n\t&#125;\n\n\t// 如果工厂方法不为空，则是用工厂方法初始化\n\tif (mbd.getFactoryMethodName() != null)  &#123;\n\t\t// 相关知识点看另一篇文章关于FactoryBean的\n\t\treturn instantiateUsingFactoryMethod(beanName, mbd, args);\n\t&#125;\n\n\t// Shortcut when re-creating the same bean...\n\t// 如果不是第一次创建，比如第二次创建 prototype bean。\n\t// 这种情况下，我们可以从第一次创建知道，采用无参构造函数，还是构造函数依赖注入 来完成实例化\n\t// 所以注释说叫shortcut\n\tboolean resolved = false;\n\tboolean autowireNecessary = false;\n\tif (args == null) &#123;\n\t\tsynchronized (mbd.constructorArgumentLock) &#123;\n\t\t\tif (mbd.resolvedConstructorOrFactoryMethod != null) &#123;\n\t\t\t\t// 有已经解析过的构造方法\n\t\t\t\tresolved = true;\n\t\t\t\tautowireNecessary = mbd.constructorArgumentsResolved;\n\t\t\t&#125;\n\t\t&#125;\n\t&#125;\n\t// 如果已经解析过则使用解析好的构造方法不需要再次锁定\n\tif (resolved) &#123;\n\t\tif (autowireNecessary) &#123;\n\t\t\t// 构造方法自动注入\n\t\t\treturn autowireConstructor(beanName, mbd, null, null);\n\t\t&#125;\n\t\telse &#123;\n\t\t\t// 默认构造方法\n\t\t\treturn instantiateBean(beanName, mbd);\n\t\t&#125;\n\t&#125;\n\n\t// Need to determine the constructor...\n\t// 判断是否采用有参构造函数\n\t// 构造器自动装配\n\tConstructor&lt;?>[] ctors = determineConstructorsFromBeanPostProcessors(beanClass, beanName);\n\tif (ctors != null ||\n\t\t\tmbd.getResolvedAutowireMode() == RootBeanDefinition.AUTOWIRE_CONSTRUCTOR ||\n\t\t\tmbd.hasConstructorArgumentValues() || !ObjectUtils.isEmpty(args))  &#123;\n\t\treturn autowireConstructor(beanName, mbd, ctors, args);\n\t&#125;\n\n\t// No special handling: simply use no-arg constructor.\n\t// 使用无参构造器\n\treturn instantiateBean(beanName, mbd);\n&#125;","categories":[],"tags":[]},{"title":"","url":"/2022/06/21/ING/Reading/%E8%AF%BB-%E6%B0%91%E4%B8%BB%E7%9A%84%E7%BB%86%E8%8A%82/","content":"很少写书评影评，翻过的书过去了就过去了，也许化成了血肉的一部分，也许没个一两天就代谢得干干净净，想来，都没关系。不过会保留书摘的习惯。其实不太愿意翻政治相关的东西，可是聊经济话题还是会落到政治上。还有一点就是，我们的环境确实复杂得无法用一个好或者坏，简单而不负责地评价。比如刚合上这本书，翻开的一篇新闻就是图二，五味杂陈。\n只有当你不知道自己可能是谁时，才能想清楚什么是正义。政府的目的是帮助人们帮助他们自己。自由的悖论恰恰在于，自由的保障，来自于对自由的限制。…权利和责任，是自由这枚金币的两面。我不在乎别人的观点是不是和我的一致，甚至不在乎别人的观点是不是愚蠢，我在乎别人的观点是不是“独立思考”的结果。每次在中国听见熟人朋友说“中国什么都便宜”，“雇一个保姆才XX钱”，“按摩一个小时才XX钱”，“买一斤蔬菜才XX钱”，我都不知道该高兴还是难过。从消费者“利益”的角度来说，当然很高兴。但是从“消费者责任”的角度来说，我又深感不安。有时候，我会感到奇怪，当爱国愤青们对“购买日货就是支持日本军国主义”这种似是而非的逻辑而热血沸腾时，为什么这个国家里没有更多的消费者，对更显然的“消费责任”，比如抵制本国的血汗工厂，抵制某些企业对环境的严重破坏，呼吁改善那些给我们盖房子修马路的民工的生存条件，表现出同样的激情？——《民主的细节》\n","categories":[],"tags":[]},{"title":"","url":"/2022/06/21/ING/Reading/%E6%96%AF%E5%9D%A6%E7%A6%8F%E6%9E%81%E7%AE%80%E7%BB%8F%E6%B5%8E%E5%AD%A6/","content":"研究经济学的理由就是“为了避免被经济学家欺骗”。\n听过很多次“人人都应该学一点经济学和心理学”，到目前我大概对这个忠告的理解是：经济学为个体解释群体现象的合理性，它的阐述方式是理性的，以数据为依据屏蔽掉个体的“趣闻逸事”，说白了对普通群众而言就是，先有了某种现象，那么为这现象找出一个相对合理的解释以求心理别太拧巴，再简化一点就是为普通人解释现象。但这朵“社科明珠”是能解决大问题的。后者为个体与个体之间的社交活动提供一些合乎当下社会规约的范例，会把很多感性的东西考虑进去，是个体而具化的。\n听过很多次“人人都应该学一点经济学和心理学”，前者作为“社科明珠”，它对普通群众的意义也许就在于，解释现象，那些可能会让个体感觉很拧巴的社会现象。\n","categories":[],"tags":[]},{"title":"","url":"/2022/06/21/ING/Reading/Google%E5%B7%A5%E4%BD%9C%E6%95%B4%E7%90%86%E6%9C%AF/","content":"\n为了实现大脑压力最小化，要把生活组织得有条不紊。\n让信息尽可能快地离开大脑。\n多重任务通常会让你降低效率。\n利用故事去记忆。\n仅仅因为一直都按照某种特定方式做某件事，并不意味着就该永远这样做。\n知识不是力量，共享知识才是力量。\n进行组织安排时，要绕开的是实际制约而非假性制约。\n对自己要坦诚，但是千万不要自我评判。\n要懂得什么时候忽略制约。\n在发动汽车之前，一定要确切地搞清楚自己要到哪里去，还要知道选择什么途径去。\n在实现目标的方式上要灵活变通。\n不要给信息归档，用的时候搜索就行了。\n大脑中只保存真正需要记忆的内容。\n\n\n","categories":[],"tags":[]},{"title":"BeanFactory vs FactoryBean","url":"/2022/06/21/ING/BeanFactory%20vs%20FactoryBean/","content":"[toc]\n首先，它们都是spring framework里比较顶层的接口：BeanFactory可以看做最简版的容器形式，也给具体的IOC容器实现提供规范，比如ApplicationContext；FactoryBean为IOC容器中的Bean创建提供更加灵活的方式，通过给Bean的实现加上一个简单的工厂模式和装饰器模式，使得对Bean的配置更加便捷灵活。\nBeanFactory以Factory结尾的都是工厂类&#x2F;接口。它是IOC容器的核心接口，其职责包括：实例化、定位、配置应用程序中的对象，以及建立这些对象间的依赖。FactoryBean只是一个接口，并非IOC容器的具体实现，但spring给出了很多种实现：ApplicationContext、DefaultListableBeanFactory、AnnotationConfigApplicationContext等。其中AnnotationConfigApplicationContext是目前构建具体应用很常用的一个，它实现将以注解方式描述组成应用的对象和对象间的依赖关系。AnnotationConfigApplicationContext类将持有注解配置的所有元数据信息，并用这些元数据构建一个完全可配置的系统或应用。再如，ApplicationContext，派生自BeanFactory，仍然是一个接口，但它提供一种更面向框架的方式工作，并且对上下文进行分层和实现继承关系。同时它还派生自MessageSource、ApplicationEventPublisher、HierarchicalBeanFactory、ResourcePatternResolver等接口，从而扩充了以下能力：\n\nMessageSource, 提供国际化的消息访问;\n资源访问，如URL和文件;\n事件传播;\n载入多个（有继承关系）上下文 ，使得每一个上下文都专注于一个特定的层次，比如应用的web层;\n\n主要提供以下一些方法：\nFactoryBean","categories":["java"],"tags":["java","spring"]},{"title":"BeanFactory vs FactoryBean","url":"/2022/06/21/ING/BeanFactory_vs_FactoryBean/","content":"[toc]\n首先，它们都是spring framework里比较顶层的接口：BeanFactory可以看做最简版的容器形式，也给具体的IOC容器实现提供规范，比如ApplicationContext；FactoryBean为IOC容器中的Bean创建提供更加灵活的方式，通过给Bean的实现加上一个简单的工厂模式和装饰器模式，使得对Bean的配置更加便捷灵活。\nBeanFactory以Factory结尾的都是工厂类&#x2F;接口。它是IOC容器的核心接口，其职责包括：实例化、定位、配置应用程序中的对象，以及建立这些对象间的依赖。FactoryBean只是一个接口，并非IOC容器的具体实现，但spring给出了很多种实现：ApplicationContext、DefaultListableBeanFactory、AnnotationConfigApplicationContext等。其中AnnotationConfigApplicationContext是目前构建具体应用很常用的一个，它实现将以注解方式描述组成应用的对象和对象间的依赖关系。AnnotationConfigApplicationContext类将持有注解配置的所有元数据信息，并用这些元数据构建一个完全可配置的系统或应用。再如，ApplicationContext，派生自BeanFactory，仍然是一个接口，但它提供一种更面向框架的方式工作，并且对上下文进行分层和实现继承关系。同时它还派生自MessageSource、ApplicationEventPublisher、HierarchicalBeanFactory、ResourcePatternResolver等接口，从而扩充了以下能力：\n\nMessageSource, 提供国际化的消息访问;\n资源访问，如URL和文件;\n事件传播;\n载入多个（有继承关系）上下文 ，使得每一个上下文都专注于一个特定的层次，比如应用的web层;\n\n主要提供以下一些方法：\nFactoryBean","categories":["java"],"tags":["java","spring"]},{"title":"Integer","url":"/2021/04/18/ING/Integer/","content":"[toc]\nRTFSCInteger 类本身没有太多值得关注的东西，除了内部类 IntegerCache，这里涉及到的内容有：缓存池、享元模式、getSavedProperty、CDS。\n缓存池很多时候我们能看到这么个面试题，思考以下代码的输出：\nInteger i = 127;\nInteger j = 127;\nSystem.out.println(\"i == j：\" + (i == j)); # true\nInteger i = 128;\nInteger j = 128;\nSystem.out.println(\"i == j：\" + (i == j)); # false\n回答对了继续问为啥，因为有个缓存池。vm 默认缓存了[-128, 127]这么多 Integer 对象，如果试图创建的对象落在了这个范围，那么不会新建而是直接从这个缓存里取，所以从地址上相等。源码可以看到，server 模式下有个参数控制缓存池大小，只是默认取 high = 127。由此引出另两个问题。\n\n怎么修改默认的缓存池大小？  两个方法：  -Djava.lang.Integer.IntegerCache.high=xxx  -XX:AutoBoxCacheMax=xxx。\n内部类是怎么获取这个默认参数的？   VM.getSavedProperty(&quot;java.lang.Integer.IntegerCache.high&quot;);  其实这里可以继续往下问的，jvm 加载默认参数的方式有哪些，这里先跳过吧。\n\n很无聊的一个题。\n享元模式顺着缓存池再往前问一句就是这个缓存池用到了什么设计模式，回答享元模式。大多数解释说得很递归：因为用到了缓存池，所以享元。（wtf???）算了还是看一下享元模式的定义吧。Flyweight：Use sharing to support large numbers of fine-grained objects efficiently.\n噢，好吧解释是对的，起这么个高大上的中文名字是干嘛。。。\nCDS在初始化 IntegerCache 的过程中，会先尝试使用 CDS 的 initializeFromArchive() 来完成，这是个本地方法，先看一下定义吧：class data sharing，核心类的 vm 级别的共享。这么看的话，应该是开辟一片空间来归档一些类，在 jvm 这个级别改变类的装载方式，从而优化性能和内存使用。记个 todo 后面再看。\n","categories":["java"],"tags":["jdk src"]},{"title":"jdk源码阅读","url":"/2021/04/16/ING/RTFSC/","content":"[toc]\nRTFSC我就不解释上面这个缩写啥意思了。之前在 IDEA 上搭建的是 jdk-1.8 的阅读环境，网搜的大多数搭建教程都是靠谱的。心血来潮想切换到最新的 jdk-17，中英文教程全部失效，摸索了一个暂时可行的方案，记录如下。\n新建工程新建简单 java 项目，举例如图：找到 jdk 安装路径的 src.zip 压缩包，解压到某文件夹下，取出 src&#x2F;java.base 下的所有文件夹，包括 module-info.java，放到 prj&#x2F;…&#x2F;source 文件夹下即可。\n配置同 jdk-1.8 的配置方法：\n\n点击“+”添加 jdk 环境；\n把 sourcepath 指向项目的 …&#x2F;source 文件夹；\n把项目的 jdk 设置为新加的 jdk 环境；\n配置一下 debug 的 step in 等，done.\n\n好了放着吃灰吧\n","categories":["java"],"tags":["jdk java"]},{"title":"tools","url":"/2021/04/09/ING/tools/","content":"[toc]\n工作原因会用到不少开发工具集，近来切换了其中的两款：postman -&gt; IDEA 自带的 scratches，Navicat -&gt; DataGrip。\nscratches背景postman 可以自动抓取并填充 cookie，这是非常好用的地方，但它越来越笨重了，以至于完整打开开发工具集——IDEA + VSCode + chrome(约 40+ 常用页面) + iTerm2 + 云音乐(是的这也是生产力工具之一)——之后，实在是不想再打开一个内存占用混乱的 postman，后来出了个 postwoman(哈，平权运动的副作用)，轻量但也不好用并且缺失了我最喜欢的 cookie 填充功能。继续寻找替代方案的过程中发现 IDEA 自带的 scratches 就很好用，虽然依然需要手动填充 cookie，但胜在轻量。\n使用没啥学习成本。\nDataGrip背景Navicat 本身很好用，但由于我的 OS 基本是 beta 版，更新频繁，每次更新多多少少会出现一点问题。当 DG 出来之后果断尝试了一下，嗯，真香——毕竟 JB 家的套装，没有什么学习成本，风格也易于统一——白色背景实在是难以忍受，尽管 DB 操作是低频场景。当然 IDEA 本身也集成了 database 插件，或者说 DG 本身就是用 JB 的 IDE 模板加上这个插件搞出来的东西，经过几个大版本的迭代，目前已经非常好用了。\n不得不说 JB 家族的产品是真的太值得尝试了，这个开发团队几乎有能力发掘程序员开发过程中的所有痛点，并且解决这些痛点。很期待它能够出一款轻量级的编辑器，它大可以做出一款不逊色于 VSCode、Atom 的来。\n","categories":["tools"],"tags":["tools"]},{"title":"错误vs异常","url":"/2020/07/30/CS/%E9%94%99%E8%AF%AFvs%E5%BC%82%E5%B8%B8/","content":"","categories":["CS"],"tags":["CS"]},{"title":"跳表","url":"/2020/07/04/Algs/skipList/","content":"[toc]\n算法 &amp; 数据结构$$程序 &#x3D; 算法 + 数据结构$$TAOCP中，Donald并没有直接给出“算法”的定义，而是在用了几页的篇幅追溯了一番“Algorithms”这个词的起源以尝试让读者理解它的含义之后，用了欧几里得求解两个正整数最大公因子的例子做阐述：其中最重要的是→，赋值&#x2F;代替。他的学生、红皮算法书的作者-Robert Sedgewick沿用这个例子并尝试给出了一个定义：The term algorithm is used in computer science to describe a finite, deterministic, and effective problem-solving method suitable for implementation as a computer program.同时指出了二者之间的关系：大多数算法需要适当地组织数据，为了组织数据就产生了数据结构。一脉相承的观点是，数据结构是算法的副产品&#x2F;结果（data structures exist as the byproducts or end products of algorithms）。\n\n  数据结构的作用\n\n数据结构的作用前面说算法需要组织数据，所谓组织，其实就是操作（增、删、改、查）。有关数据结构和算法的课程对中所涉及到的数据结构：数组、链表；以及以前面两者为基础的高级数据结构：堆、树、图；延展开到特定领域&#x2F;方向上优化的数据结构：各种队列，红黑树，B、B+树，拓扑图等等。所有的数据结构的目的都是在特定场景下，优化数据的操作效率。可以用算法书给的demo跑一遍十几条排序算法的效率，便能直观感受到，即使在现在这样高性能的计算机面前，$n^2$ → $n\\log(n)$所带来巨大效率的提升；而在特定场景下，采用位图、$O(n)$复杂度的排序算法所能带来的更可观的空间、时间上的节省。绝大多数场景下，我们期待的数据结构是：在保持“有序”的前提下，满足高效的增、删、查操作。其中“有序”是一个相对的概念，堆、单端&#x2F;双端队列、查找树、拓扑图等，都满足以我们所期待的方式的有序性、或者我们所关心的那部分数据的有序性。\n\n\n哈希、红黑树、跳表这里关注K-V型数据结构。\n合适的数据结构关注以下速查表数据。其中，常用的key-value数据结构有三种：Hash表：插入、查找最快，为$O(1)$；如使用链表实现则可实现无锁；数据有序化需要显式的排序操作。红黑树：插入、查找为$\\log(n)$，但常数项较小；无锁实现的复杂性很高，一般需要加锁；数据天然有序。SkipList：插入、查找为$\\log(n)$，但常数项比红黑树要大；底层结构为链表，可无锁实现；数据天然有序。\n\n首先，如果能确定某些数据是静态的，以ACA为例，我们的文案数据目前就可以看成是静态的：可能有描述上的调整，但频次很低，并且数据量不大。这部分数据如果采用直接加载到内存或是中间缓存的话，结构化为HashMap是不错的选择；\n如前所述，大部分数据操作场景是需要增删改操作的，而非仅仅只有读操作。这里不再讨论堆、队列等使用场景，专注通常情况下的数据的存取操作，此时需要兼顾读取、和操作后恢复有序的效率，此时Hash表不再是好的选择：迭代、修改操作的时间复杂度比较高，\b而红黑树则能很好地满足功能需求；\n\n为什么还要有跳表作为平衡树的一种替代实现，跳表主要拥有以下优势：\n\n更简单的实现红黑树增删改元素需要进行旋转、变色，实现起来比较复杂，需要考虑的细节也比较多，到了并发场景下更难以写出可用且高效的红黑树实现；而跳表实现原理相当简单，就是升级版的链表，把链表的某一些元素随机抽出来再组成一个链表，作为一级索引，在该索引集中再次进行抽取，再做一级索引，依次实现多级链表索引，就组成了一个跳表。\n\n为了解决在高并发下，红黑树的锁实现导致的可能的死锁和并发度降低问题。首先这句话意味着，在单线程、低线程数场景下，红黑树可能是更好的选择：以jdk11为例，ConcurrentHashMap存取速度是ConcurrentSkipListMap的4倍左右，而随着并发的线程数增多，后者的性能优势会逐渐体现出来，它的存取时间复杂度几乎和线程数无关，且无锁开销。\n\n\n特点上述可见跳表也是一种典型的“空间换时间”的数据结构。其底层采用二维链表，而非通常采用的数组实现。基本特点：\n\n由很多层结构组成；\n每一层都是一个有序的链表；\n最底层(Level 1)的链表包含所有元素；\n如果一个元素出现在 Level i 的链表中，则它在 Level i 之下的链表也都会出现；\n每个节点包含两个指针，一个指向同一链表中的下一个元素，一个指向下面一层的元素。\n\n跳表实现构造考虑一个链表：从该有序表中搜索元素&lt; 23, 43, 59&gt;，需要比较的次数分别为&lt; 2, 4, 6 &gt;，总共比较的次数为 2 + 4 + 6 &#x3D; 12 次。有没有优化的算法？链表是有序的，但不能使用二分查找。类似二叉搜索树，我们把一些节点提取出来，作为索引。得到如下结构：这里把&lt; 14, 34, 50, 72 &gt;提取出来作为一级索引，这样搜索的时候就可以减少比较次数了。还可以再从一级索引提取一些元素出来，作为二级索引，变成如下结构：\n\n  节点类\n\nstatic final class Node&lt;K,V> &#123;\n    final K key; // currently, never detached\n    V val;\n    Node&lt;K,V> next;\n    Node(K key, V value, Node&lt;K,V> next) &#123;\n        this.key = key;\n        this.val = value;\n        this.next = next;\n    &#125;\n&#125;\n\nredis 使用C实现，详见：https://github.com/antirez/redis/blob/unstable/src/server.h\n\n\n搜索元素查找元素 117：\n\n比较21，比 21 大，往后面找\n比较37，比 37大，比链表最大值小，从 37 的下面一层开始找\n比较71，比 71 大，比链表最大值小，从 71 的下面一层开始找\n比较85，比 85 大，从后面找\n比较117，等于 117， 找到了节点。\n\n\n  搜索\n\nprivate Node&lt;K,V> findNode(Object key) &#123;\n    if (key == null)\n        throw new NullPointerException(); // don't postpone errors\n    Comparator&lt;? super K> cmp = comparator;\n    Node&lt;K,V> b;\n    outer: while ((b = findPredecessor(key, cmp)) != null) &#123;\n        for (;;) &#123;\n            Node&lt;K,V> n; K k; V v; int c;\n            if ((n = b.next) == null)\n                break outer;               // empty\n            else if ((k = n.key) == null)\n                break;                     // b is deleted\n            else if ((v = n.val) == null)\n                unlinkNode(b, n);          // n is deleted\n            else if ((c = cpr(cmp, key, k)) > 0)\n                b = n;\n            else if (c == 0)\n                return n;\n            else\n                break outer;\n        &#125;\n    &#125;\n    return null;\n&#125;\n\n\n新增元素先确定该元素要占据的层数 K（丢硬币，随机），然后在 Level 1 … Level K 各个层的链表都插入元素：插入 119， K &#x3D; 2其中，然随机变量 K 满足参数为 $p &#x3D; 1&#x2F;2$ 的几何分布，期望值 $E[K] &#x3D; 1&#x2F;p &#x3D; 2$。即各个元素的层数，期望值是 2 层。\n\n  插入\n\nprivate V doPut(K key, V value, boolean onlyIfAbsent) &#123;\n    if (key == null)\n        throw new NullPointerException();\n    Comparator&lt;? super K> cmp = comparator;\n    for (;;) &#123;\n        Index&lt;K,V> h; Node&lt;K,V> b;\n        VarHandle.acquireFence();\n        int levels = 0;                    // number of levels descended\n        if ((h = head) == null) &#123;          // try to initialize\n            Node&lt;K,V> base = new Node&lt;K,V>(null, null, null);\n            h = new Index&lt;K,V>(base, null, null);\n            b = (HEAD.compareAndSet(this, null, h)) ? base : null;\n        &#125;\n        else &#123;\n            for (Index&lt;K,V> q = h, r, d;;) &#123; // count while descending\n                while ((r = q.right) != null) &#123;\n                    Node&lt;K,V> p; K k;\n                    if ((p = r.node) == null || (k = p.key) == null ||\n                        p.val == null)\n                        RIGHT.compareAndSet(q, r, r.right);\n                    else if (cpr(cmp, key, k) > 0)\n                        q = r;\n                    else\n                        break;\n                &#125;\n                if ((d = q.down) != null) &#123;\n                    ++levels;\n                    q = d;\n                &#125;\n                else &#123;\n                    b = q.node;\n                    break;\n                &#125;\n            &#125;\n        &#125;\n        if (b != null) &#123;\n            Node&lt;K,V> z = null;              // new node, if inserted\n            for (;;) &#123;                       // find insertion point\n                Node&lt;K,V> n, p; K k; V v; int c;\n                if ((n = b.next) == null) &#123;\n                    if (b.key == null)       // if empty, type check key now\n                        cpr(cmp, key, key);\n                    c = -1;\n                &#125;\n                else if ((k = n.key) == null)\n                    break;                   // can't append; restart\n                else if ((v = n.val) == null) &#123;\n                    unlinkNode(b, n);\n                    c = 1;\n                &#125;\n                else if ((c = cpr(cmp, key, k)) > 0)\n                    b = n;\n                else if (c == 0 &amp;&amp;\n                         (onlyIfAbsent || VAL.compareAndSet(n, v, value)))\n                    return v;\n\n                if (c &lt; 0 &amp;&amp;\n                    NEXT.compareAndSet(b, n,\n                                       p = new Node&lt;K,V>(key, value, n))) &#123;\n                    z = p;\n                    break;\n                &#125;\n            &#125;\n\n            if (z != null) &#123;\n                int lr = ThreadLocalRandom.nextSecondarySeed();\n                if ((lr &amp; 0x3) == 0) &#123;       // add indices with 1/4 prob\n                    int hr = ThreadLocalRandom.nextSecondarySeed();\n                    long rnd = ((long)hr &lt;&lt; 32) | ((long)lr &amp; 0xffffffffL);\n                    int skips = levels;      // levels to descend before add\n                    Index&lt;K,V> x = null;\n                    for (;;) &#123;               // create at most 62 indices\n                        x = new Index&lt;K,V>(z, x, null);\n                        if (rnd >= 0L || --skips &lt; 0)\n                            break;\n                        else\n                            rnd &lt;&lt;= 1;\n                    &#125;\n                    if (addIndices(h, skips, x, cmp) &amp;&amp; skips &lt; 0 &amp;&amp;\n                        head == h) &#123;         // try to add new level\n                        Index&lt;K,V> hx = new Index&lt;K,V>(z, x, null);\n                        Index&lt;K,V> nh = new Index&lt;K,V>(h.node, h, hx);\n                        HEAD.compareAndSet(this, h, nh);\n                    &#125;\n                    if (z.val == null)       // deleted while adding indices\n                        findPredecessor(key, cmp); // clean\n                &#125;\n                addCount(1L);\n                return null;\n            &#125;\n        &#125;\n    &#125;\n&#125;\n\n\n\n删除元素采用标准的链表删除即可。删除 71\n\n  删除\n\nfinal V doRemove(Object key, Object value) &#123;\n    if (key == null)\n        throw new NullPointerException();\n    Comparator&lt;? super K> cmp = comparator;\n    V result = null;\n    Node&lt;K,V> b;\n    outer: while ((b = findPredecessor(key, cmp)) != null &amp;&amp;\n                  result == null) &#123;\n        for (;;) &#123;\n            Node&lt;K,V> n; K k; V v; int c;\n            if ((n = b.next) == null)\n                break outer;\n            else if ((k = n.key) == null)\n                break;\n            else if ((v = n.val) == null)\n                unlinkNode(b, n);\n            else if ((c = cpr(cmp, key, k)) > 0)\n                b = n;\n            else if (c &lt; 0)\n                break outer;\n            else if (value != null &amp;&amp; !value.equals(v))\n                break outer;\n            else if (VAL.compareAndSet(n, v, null)) &#123;\n                result = v;\n                unlinkNode(b, n);\n                break; // loop to clean up\n            &#125;\n        &#125;\n    &#125;\n    if (result != null) &#123;\n        tryReduceLevel();\n        addCount(-1L);\n    &#125;\n    return result;\n&#125;\n\n\n适用场景\njdk从1.6开始引入了两个跳表相关的实现类：ConcurrentSkipListMap、ConcurrentSkipListSet（基于ConcurrentSkipListMap），在jdk中主要是用于高并发场景下代替红黑树的实现，不过从jdk8开始，线程安全的Hash表：ConcurrentHashMap采用了CAS、取消分段锁改用大数组、哈希碰撞超过阈值时树化（红黑树）等手段进一步提升了线程安全Hash表相关实现，性能上也有了很大提升。\n\nredis：redis的有序集合zset是采用跳表实现的。分析一下zset所支持的操作就不难理解为啥采用跳表而非红黑树了：\n\n\n\n插入元素\n删除元素\n查找元素\n有序输出所有元素\n查找区间内所有元素除了易于实现这个因素外。zset所支持的操作中，前4项红黑树都可以完成，且时间复杂度与跳表一致。但是，最后一项，红黑树的效率就没有跳表高了。在跳表中，要查找区间的元素，我们只要定位到两个区间端点在最低层级的位置，然后按顺序遍历元素就可以了，非常高效。而红黑树只能定位到端点后，再从首位置开始每次都要查找后继节点，相对来说是比较耗时的。\n\n\nLevelDB：Google 开源的 key&#x2F;value 存储引擎 LevelDB 以及 Facebook 基于 LevelDB 优化的 RocksDB 都是 LSM Tree 结构的数据库，内部的 MemTable 使用跳表实现。HBase MemStore 内部存储数据就使用的跳表。为什么呢？HBase 属于 LSM Tree 结构的数据库，LSM Tree 结构的数据库有个特点，实时写入的数据先写入到内存，内存达到阈值往磁盘 flush 的时候，会生成类似于 StoreFile 的有序文件，而跳表恰好就是天然有序的，所以在 flush 的时候效率很高，而且跳表查找、插入、删除性能都很高，这应该是 HBase MemStore 内部存储数据使用跳表的原因之一。HBase 使用的是 java.util.concurrent 下的 ConcurrentSkipListMap()。\n\nES：Lucene核心数据结构采用了跳表实现倒排表。使用FST保存词典，FST可以实现快速的Seek，这种结构在当查询可以表达成自动机时(PrefixQuery、FuzzyQuery、RegexpQuery等)效率很高。(可以理解成自动机取交集)此种场景主要用在对Query进行rewrite的时候。FST可以表达出Term倒排表所在的文件偏移。倒排表使用SkipList结构。从上面的讨论可知，求倒排表的交集、并集、差集需要各种SeekTo(docId)，SkipList能对Seek进行加速。\n\n\nref：https://stackoverflow.com/questions/256511/skip-list-vs-binary-search-treehttps://en.wikipedia.org/wiki/Skip_listhttps://blog.csdn.net/sunxianghuang/article/details/52221913https://www.iteye.com/blog/imtinx-1291165《algorithms》《the art of computer programming》\n","categories":["algs"],"tags":["algs","java"]},{"title":"分布式锁","url":"/2020/06/07/ING/%E5%88%86%E5%B8%83%E5%BC%8F%E9%94%81/","content":"[toc]\n锁","categories":["middleware"],"tags":["middleware","lock"]},{"title":"NIO","url":"/2020/06/02/ING/NIO/","content":"[toc]\nnio即 Non-blocking IO.\n","categories":["java"],"tags":["java","io"]},{"title":"gRPC","url":"/2020/06/02/ING/gRPC/","content":"[toc]\nrpc以java平台为例，客户端和服务端共用一个接口(将接口打成一个jar包，在客户端和服务端分别引入这个jar包)，客户端面向接口写调用，服务端面向接口写实现，中间的网络通信交给框架去实现。\n","categories":["middleware"],"tags":["rpc","middleware"]},{"title":"java-AQS","url":"/2020/04/07/java/Thread/AQS/","content":"[toc]\nAQSjava.util.concurrent的基础是CAS，AQS就是整个Java并发包的核心。\n","categories":["java"],"tags":["java","并发"]},{"title":"java-CAS","url":"/2020/04/07/java/Thread/CAS/","content":"[toc]\nCASCAS 构建并发安全性CAS 属于底层硬件（CPU）层面的技术实现。ConcurrentSkipListMap 使用 CAS 技术构建并发安全性。ConcurrentSkipListMap 源码分析\n","categories":["java"],"tags":["java","并发"]},{"title":"Collection","url":"/2020/03/23/java/Container/Collection/","content":"[toc]\nCollection 接口Stream stream()Stream parallelStream()Spliterator spliterator()","categories":["java"],"tags":["java","容器"]},{"title":"索引","url":"/2019/11/11/db/%E7%B4%A2%E5%BC%95/","content":"[toc]\nIO 设备是计算机系统的瓶颈索引是数据库中用来优化查询速度的最为重要的技术手段。\n查询执行顺序上述索引的作用中最关键的地方在于“优化查询速度”，那首先需要了解的是，一条sql语句，它的执行顺序是怎样的，才能更好地理解如何加速，以及背后的为什么能够加速。（比这个“首先”更首先需要了解的是，为什么要“优化”？无非一：数据量太大了；二：数据量太大了内存存不下而硬盘又太慢但又不得不放在硬盘上因为它很便宜。根因是数据量太大了，以至于不优化的话又回到了点个按钮可以喝杯咖啡再回来看结果的原始状态，用户就要爆炸，用户一爆炸老板就要爆炸，so…）sql语句执行可能会划分为多个操作步骤，如下图，一个典型的sql查询，总共分为11步，其中每一步都会产生一张中间状态的虚表，作为下一步的输入，最后一步的虚表作为返回结果，其他步骤的虚表对用户透明。其中，每一步的大致过程如下：\n\nFORM: 对FROM的左边的表和右边的表计算笛卡尔积。产生虚表VT1。\nON: 对虚表VT1进行ON筛选，只有那些符合&lt;join-condition&gt;的行才会被记录在虚表VT2中。\nJOIN： 如果指定了OUTER JOIN（比如left join、 right join），那么保留表中未匹配的行就会作为外部行添加到虚拟表VT2中，产生虚拟表VT3，如果from子句中包含两个以上的表的话，那么就会对上一个join连接产生的结果VT3和下一个表重复执行步骤1~3这三个步骤，一直到处理完所有的表为止。\nWHERE： 对虚拟表VT3进行WHERE条件过滤。只有符合&lt;where-condition&gt;的记录才会被插入到虚拟表VT4中。\nGROUP BY: 根据group by子句中的列，对VT4中的记录进行分组操作，产生VT5。\nCUBE | ROLLUP: 对表VT5进行cube或者rollup操作，产生表VT6。\nHAVING： 对虚拟表VT6应用having过滤，只有符合&lt;having-condition&gt;的记录才会被 插入到虚拟表VT7中。\nSELECT： 执行select操作，选择指定的列，插入到虚拟表VT8中。\nDISTINCT： 对VT8中的记录进行去重。产生虚拟表VT9。\nORDER BY: 将虚拟表VT9中的记录按照&lt;order_by_list&gt;进行排序操作，产生虚拟表VT10。\nLIMIT：取出指定行的记录，产生虚拟表VT11, 并将结果返回。\n\n理解上述步骤之后，不难发现，为什么连接查询很可能导致低效（笛卡尔积：m * n），同时也可以看出，如果想要做一些查询优化工作，那么就要从 on、where 开始着手（join 中 on 等同于 where），对过滤条件中的字段加以优化（即挑选索引时的考虑因素）。\n索引是什么？多数博客会用“书的目录”作解释，这是个很好的例子，为小白科普CS常识的时候可以用。作为开发可以从另一个角度理解：假设我们有100w行单列的数据，比如人名，如何提高“找到特定名字”的效率呢？简单直接地，我们想到的是树结构来存储，比如最熟悉的BST，它的查找效率非常高，lg(n)级别的查询次数，百万数据的也只需要20次左右，但是考虑到数据是持久化到存储介质的，和内存、CPU存在巨大的执行速度的差异，20次依然太多了。继续优化的方向并没有转变，专门为数据库而设计的各种B-tree应运而生，简单理解就是，从原来的二分，所需数据在左侧或者右侧，改为比如，按首字母序，分为26块，所需数据肯定在26中的某一块，这样一次查找就可以把范围缩小到数据量的1&#x2F;26。其他诸如平衡性、B树到B+树、聚簇&#x2F;非聚簇、聚集&#x2F;非聚集（注意和前一组不同）等概念，也都是在此基础上，结合软硬件特性所提出来的“优化手段”。（这里未讨论hash索引、位图索引、全文索引等特殊场景下的特殊方案。）\n为什么要有索引上面这段话好像没有说明白为啥要有索引，我直接对100w数据排序到硬盘不就行了？直接排序在单列数据当然是可行的，且操作效率也都很高。问题是数据库（问这个问题的应该回去重学数据库）表有很多字段，如果表只有一个索引，自然可以这样做。如果想添加两个&#x2F;多个索引，又不能同时按照两种方式对数据进行排序，比如一个关于姓名的索引和一个电话号码索引，这种情况就无法排序。将索引从数据行中整体分离出来，就可以创建多个索引，并且不需要对原始数据排序，但搜索过程即先在索引中找到对应值，然后根据匹配的记录找到对应的数据行。此外，索引行数据通常比表里的数据行更短，插入&#x2F;删除值时，为保持排序顺序，来回移动较短的索引值，比来回移动较长的数据行更加容易。\n综上，索引是关系型数据场景下优化查询效率的产物。 同时既然老板们选择了便宜的存储介质，那就需要广大的程序员们奉献头发来尽可能减少“便宜”所带来的副作用，也就是访问过慢的问题了。\n索引类型B+索引首先从大家默认的MySQL数据库默认的InnoDB存储引擎默认的用户创建索引类型说起：B+索引。它是目前关系型数据库系统中查找最为常用和最为有效的索引（大概是InnoDB团队自己说的）。B+索引的发展和演变过程就是上面提到的那样，就是B-tree的一类变种。\n考虑过哪些轮子这就不可避免地要继续延伸索引的发展史了，从BST开始，因缺乏社交活动而时间精力异常充沛的程序员（中的大神）们尝试了很多索引方案，BST 很快显露出其不仅仅在作为索引上的短板：最差性能是线性的；于是新的轮子–AVL 诞生了，它解决了平衡性的问题，把一棵树塞得满满的，新的问题又来了：维护平衡的代价太高，继续造轮子——RBT（红黑树），这棵树已经非常优秀了，被广泛应用于STL、linux进程调度、IO多路复用（epoll）、nginx、java TreeMap等；看上去拿来作索引的底层数据结构也挺好，很快新的问题又来了：还是反复提到的，硬盘这个猪队友的速度实在太拖后腿，以至于这么优秀的轮子依然不能用，百万量级就需要20多次磁盘访问，这之间巨大的数据鸿沟是第一段内容提到的，具体就是至少为纳秒与毫秒的差距。具体可以看下这里：让 CPU 告诉你硬盘和网络到底有多慢\nB-treeB-tree就是为了磁盘或其它存储设备而设计的一种平衡多路查找树(相对于二叉，每个内节点有多个分支)。B-tree已经具有了“有效降低磁盘查询次数”的特点，具有 高扇出性 的特点，一般高度在 2-4 层，意即查找某一键值的行记录最多只需要 2-4 次 I&#x2F;O。并且具有以下特点：\n\n定义任意非叶子结点最多只有M个儿子，且M&gt;2；\n根结点的儿子数为[2, M]；\n除根结点以外的非叶子结点的儿子数为[M&#x2F;2, M]；\n每个结点存放至少M&#x2F;2-1（取上整）和至多M-1个关键字；（至少2个关键字）\n非叶子结点的关键字个数&#x3D;指向儿子的指针个数-1；\n非叶子结点的关键字：K[1], K[2], …, K[M-1]；且K[i] &lt; K[i+1]；\n非叶子结点的指针：P[1], P[2], …, P[M]；其中P[1]指向关键字小于K[1]的子树，P[M]指向关键字大于K[M-1]的子树，其它P[i]指向关键字属于(K[i-1], K[i])的子树；\n所有叶子结点位于同一层；\n\n它最终慢慢退出，或者说新的更合适的B+索引取而代之的原因是：B-tree在提高了磁盘IO性能的同时并没有解决元素遍历的效率低下的问题。在数据库中基于范围的查询是非常频繁的，而B-tree对于此类操作效率太低，因为它在节点中存储索引和数据，而数据域的存在导致B-tree一次能够读入内存的数据范围减少（相比于只把索引读入内存），从而在”减少磁盘IO“这一关键优化上依然存在很大空间。B+索引也就是B-tree的基础上，解决了这一问题：把数据域转移到叶子节点，所有非叶子节点只保存索引。\nB+tree在B-tree的基础上进行改造，具有不同于后者的特性：\n\n非叶子节点的子树指针与关键字个数相同；\n非叶子节点的子树指针p[i],指向关键字值属于[k[i],k[i+1]]的子树.(B树是开区间,也就是说B树不允许关键字重复,B+树允许重复)；\n为所有叶子节点增加一个链指针；\n所有关键字都在叶子节点出现(稠密索引). (且链表中的关键字恰好是有序的)；\n非叶子节点相当于是叶子节点的索引(稀疏索引),叶子节点相当于是存储(关键字)数据的数据层；\n更适合于文件系统；\n\nB+tree的优点，也就是它更适合作索引数据结构的原因：\n\nB+树的磁盘读写代价更低：B+树的内部节点并没有指向关键字具体信息的指针，因此其内部节点相对B树更小，如果把所有同一内部节点的关键字存放在同一盘块中，那么盘块所能容纳的关键字数量也越多，一次性读入内存的需要查找的关键字也就越多，相对IO读写次数就降低了。\nB+树的查询效率更加稳定：由于非终结点并不是最终指向文件内容的结点，而只是叶子结点中关键字的索引。所以任何关键字的查找必须走一条从根结点到叶子结点的路。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当。\n由于B+树的数据都存储在叶子结点中，分支结点均为索引，方便扫库，只需要扫一遍叶子结点即可，但是B树因为其分支结点同样存储着数据，我们要找到具体的数据，需要进行一次中序遍历按序来扫，所以B+树更加适合在区间查询的情况，所以通常B+树用于数据库索引。\n\nB+ 树索引并不能找到一个给定键值的具体行，而是查找该行所在的页，然后通过把页读入内存，再在内存中进行查找，最后得到要查找的数据行。且可以进一步分为聚集索引（Clustered Index）和辅助索引（Secondary Index），叶子节点存放着所有的数据，不同之处是，叶子节点存放的是否是一整行的信息。\n聚集索引按照每张表的主键构造一棵 B+ 树，同时叶子节点中存放的即为整张表的行记录数据，也将聚集索引的叶子节点成为数据页。聚集索引的这个特性决定了索引组织表中数据也是索引的一部分。同 B+ 树数据结构一样，每个数据页都通过一个双向链表来进行链接。由于实际的数据页只能按照一棵 B+ 树进行排序，因此每张表只能拥有一个聚集索引。查询优化器倾向于采用聚集索引，因为能够在叶子节点上直接找到数据，对于主键的排序查找和范围查找速度都非常快。聚集索引的存储并不是物理上连续的（维护成本将非常高），而是逻辑上连续的。\n辅助索引叶子节点并不包含行记录的全部数据，除了包含键值以外，每个叶子节点的索引行中还包含了一个书签，用来告诉InnoDB存储引擎哪里可以找到与索引相对应的行数据。辅助索引的存在并不影响数据在聚集索引中的组织，因此每张表上可以有多个辅助索引。当通过辅助索引来查找数据时，InnoDB存储引擎会遍历辅助索引并通过叶级别的指针获得指向主键索引的主键，然后通过主键索引来找到一个完整的行记录。例：如果在一棵高度为3的辅助索引树中查找数据，那么需要对这棵辅助索引树遍历3次找到指定主键，如果聚集索引树的高度同样为3，那么还需要对聚集索引树进行3次查找，最终找到一个完整的行数据所在的页，因此共需要6次逻辑IO访问以得到最终的一个数据页。\nHash索引基于哈希表实现，只有精确匹配索引所有列的查询才有效。对于每一行数据，存储引擎都会对所有的索引列计算一个哈希码（Hash Code），哈希码是一个比较小的值，并且不同键值的行计算出来的哈希码是不同的。哈希索引将所有的哈希码存储在索引中，同时在哈希表中保存指向每个数据行的指针。MySQL中，只有 Memory 引擎显式支持哈希索引，也是 Memory 引擎表默认索引类型，并且支持非唯一哈希索引。如果多个列的哈希值相同，索引会以链表的方式存放多个记录指针到同一个哈希条目中，所以哈希索引适合于精确查找；InnoDB 引擎支持的哈希索引是自适应的，会根据表的使用情况自动为表生成哈希索引，不能人为干预是否在一张表中生成哈希索引。\n位图索引（BitMap BitMap index）建立B+树索引的条件：高选择性的列(后续内容）。对于低选择性的列（这里应该描述成：只有固定几个值可选的列）如性别、婚否等，位图索引可能是个好的选择：适用场景\n\n只有几个固定值的列；\n不会频繁更新；位图索引原理\n\n全文索引（Full-Text Search Index)将存储于数据库中的整本书或整篇文章中的任意内容信息查找出来的技术。MyISAM支持全文索引，InnoDB 从 1.2.x 版本开始支持全文索引。Memory、NDB、Archive等不支持全文索引。\n\n  全文索引\n    \n    \n倒排索引技术全文索引通常使用倒排索引（Inverted Index）来实现：在辅助表（Auxiliary Table）中存储了单词与单词自身在一个&#x2F;多个文档中所在位置之间的映射，这通常利用关联数组实现，有两种表现形式：\n\nInverted File Index，表现形式为 {单词，单词所在文档 ID}；\nFull Inverted Index，表现形式为{单词，（单词所在文档 ID，在具体文档中的位置1，位置2…）}示例如下：\n\nInnoDB 全文索引采用 Full Inverted Index 的方式，将（DocumentId， Position1, Position2…）视为一个 ilist。故在全文索引的表中，有两个列：word字段、ilist字段，并且在word字段上设有索引。此外，由于 InnoDB 在ilist字段中存放了 Position 信息，故可以进行 Proximity Search（MyISAM不支持该特性）。为提高全文检索的并行性能，InnoDB中共有6张 Auxiliary Table，目前每张表根据 word 的 Latin 编码进行分区。Auxiliary Table 是存放在磁盘上的持久表。此外，还有一个 FTS Index Cache（全文检索索引缓存），用来提高全文检索的行能。它是一个红黑树结构，根据（word，ilist）进行排序。\n限制\n每张表只能有一个全文索引的索引；\n由多列组合而成的全文索引的索引列必须使用相同的字符集和排序规则；\n不支持没有单词界定符（delimiter）的语言，如中、日、韩等语言。\n\n相关性：在 WHERE 中使用 MATCH 函数，查询返回的结果是根据相关性（Relevance）进行降序排序的，即相关性最高的结果放在第一位，0表示没有任何相关性。计算条件：\n\nword是否在文档中出现；\nword在文档中出现的次数；\nword在索引列中的数量；\n多少个文档包含该word。\n\nBOOLEAN全文检索可以使用 IN BOOLEAN MODE 修饰符，此时查询字符串的前后字符会有特殊的含义，如：\n\n+ word：表示word必须存在；\n- word：表示word必须被排除；\n@distance：可选，表示字符字节间距最大值；\n&gt;：表示出现该词时增加相关性；\n&lt;：表示出现该词时降低相关性；\n*：表示以该词开头的单词，如lik*，可以是lik、like、likes…\n“：表示短语；\n~：表示允许出现该单词，但相关性为负\netc.\n\nQuery Expansion全文索引的扩展查询，通常在查询的关键词太短，用户需要 implied knowledge（隐含知识）时进行。如，对于单词 database 的查询，用户可能希望查询的不仅仅是 database 的文档，可能还指那些包含 MySQL、Oracle、DB2、RDBMS 等的单词，这时可以使用 Query Expansion 模式来开启全文索引的 implied knowledge。通过在查询短语中添加 WITH QUERY EXPANSION 或 IN NATURAL LANGUAGE MODE WITH QUERY EXPANSION 可以开启 blind query expansion（automatic relevance feedback）。该查询分为两个阶段：\n\n根据索引的单词进行全文索引查询；\n根据第一阶段产生的分词再进行一次全文检索的查询。\n\n由于 Query Expansion 的全文检索可能带来许多非相关性的查询，因此在使用时需要非常谨慎。    \n\n\n对比之所以InnoDB等数据库、数据库引擎选择B+而非其他类型的索引作为默认索引类型，除了上述B+索引的优势外，B+索引天然支持范围查找，这也是大部分关系型数据库的场景。\n使用索引什么时候适合&#x2F;需要索引承前，索引的出现是为了解决（大数据量）情况下的查询效率问题。\n\n根据前面说的sql执行顺序，可以确定第一条是否添加索引的判断依据：该列数据是不是出现在where后。\n并非在所有的查询条件中出现的列都需要添加索引。对于添加 B+ 树索引的一般经验是，在访问表中很少一部分时考虑使用 B+ 树索引。如果一个字段取值范围很广，重复出现较少，即属于高选择性字段，此时使用 B+ 树索引比较合适。否则，如性别、类型等字段，可取值范围很小（性别显然只能筛选 50%），即属于低选择性字段，此时不适合使用 B+ 树索引（适合使用前面说的位图索引）。事实上，在低选择性的字段上，即使建立了如 B 树索引，数据库可能也不会使用，而是仍然以全扫描（如果没有其他可用索引）的方式进行查找，因为此时使用这种索引可能反而降低性能。\n\n如何创建索引\n为用于搜索、排序、分组的列创建索引，而对于用作输出显示的列不需要建立索引。即，最佳索引候选列是出现在 WHERE、连接、ORDER BY、GROUP BY 子句中的列，而出现在 SELECT 关键字后面的输出列表里的列则不是很好的选择。\n认真考虑数据列基数列的基数（cardinality）是指它所容纳的所有非重复值的个数。相对于表的总行数来说，列的基数越大（也就是包含的唯一值越多，重复值越少，即上述的高选择性的列），使用索引的效果越好。\n选择合适的索引类型对于精确查找（使用 &#x3D;、&lt;&gt; 的查找），那么使用 MEMORY 的默认索引类型，即 hash 索引，可能效果更好：hash 的精确查找速度非常快，而对范围匹配表现欠佳；所以对于范围查找，使用 B+ 树类型的索引效果更好，InnoDB、MyISAM、MEMORY 等都支持 B 树索引。\n索引短小值应尽量选择较小的数据类型。如，当使用 MEDIUMINT 列便能够容纳所需要存储的数据时，就不要选用 BIGINT，如果值的长度都不会超过 25 个字符，那么就不要使用 CHAR(100)。短小的值可以提高索引的处理性能：\n短小的值操作更快，从而加快索引查找速度；短小的值可以让索引更小，从而减少磁盘 I&#x2F;O；对于短小的键值，键缓存里的索引块可以容纳更多的键值，也就可以在更少的磁盘 I&#x2F;O 下读取更多的索引块，从而提高找到键值的几率。\n\n\n索引字符串值的前缀要对字符串列建立索引，应该尽可能指定前缀长度。如，对于一个 CHAR(200) 列，如果大多数值的前 10 个 或 20 个字符都是唯一的，那么就可以不用为整个列进行索引，而只为前 10 个或 20 个字符进行索引，这样可以节省大量的索引空间，而且能够加速查询；但只索引列的第一个字符恐怕不行，因为会导致索引无法获得大量的唯一值。\n不要建立过多的索引显然，索引的建立并非无代价的，要考虑对性能和存储的影响。过多的索引也会导致\n\n辅助手段为数据选择利于高效查询的数据类型。多用数字运算，少用字符串运算数字运算通常比字符串运算更快。尽可能使用数字表示数据，如以点记号表示的 IP 地址，可以采用 4 组数字依次存入 INT UNSIGNED，而非直接使用字符串，尽管更方便，但数字对数据操作更高效，且更加节省空间。把数据列声明为 NOT NULL这可以加快查询，因为查询处理期间不再需要检查该列的值是否可以为 NULL，也有利于编写更简洁的 sql 语句。如果必须考虑 NULL 的情况，也可以考虑默认值等方式。考虑使用 ENUM 列如果必须采用字符串的列，恰好其基数很小（差异值较少），可以考虑转用 ENUM 列，即内部实际上采用数字形式存储，从而获得数字运算的处理速度。使用 PROCEDURE ANALYSE()运行 PROCEDURE ANALYSE()，可以根据输出得出一些优化手段。整理表碎片对频繁修改的表，尤其是包含可变长数据列的表，往往会产生大量碎片，导致空间浪费。定期使用 OPTIMIZE TABLE，可以消除&#x2F;减少碎片化的 InnoDB、MyISAM 表的空间浪费，并有助于防止性能降低。适用于各存储引擎的碎片整理方式是：先用 mysqldump 转储表，再利用该转储文件重建之：\nmysqldump db_name table_name > dump.sql\nmysql db_name &lt; dump.sql\n压缩数据把数据压缩到 BLOB 或 TEXT 列。使用 BLOB 或 TEXT 列来存储那些可以在应用程序中对其进行压缩和解压的数据，使之能够使用单个索引操作找出所有内容的目的。这种方法特别适用于存储那些难以用标准表数据结构表示的数据，或者会随时间变化的数据。把 BLOB 或 TEXT 列剥离处出来形成一个单独的表将 BLOB 或 TEXT 列单独存入一个附表，可以更好地管理原表里的数据\n如何使用索引一个索引是否适合某个查询的“三星系统”\n\n索引将相关的记录放到一起则获得一星；\n索引中的数据顺序和查找中的排练顺序一致则获得二星；\n索引中的列包含了查询中需要的全部列则获得三星。\n\n利用最左前缀当创建包含 n 个列的复合索引时，实际上会创建 n 个索引，即相当于多个索引，因为索引中最左边的任意数据列集合都可以用于匹配各个行。这样的集合即为 最左前缀。假设：多个列的复合索引中包含列：county、state、city，索引中行的排列顺序为 country&#x2F;state&#x2F;city。那么，行首先会按照 county&#x2F;state 顺序排序，然后按 country 顺序排序，这意味着，即使在查询中只指定了 county 值，或者只指定了 country 和 state 值，MySQL 也可以充分利用索引。因此，索引可用于搜索这些列组合：country, state, citycountry, statecountry对于没有包含最左前缀的搜索，如按照 state 或者 city 来搜索，MySQL 则无法使用该索引；而如果要所搜 country 和 city（索引的第 1、3 列，跳过第 2 列），那么索引能够找到与 country 匹配的行以缩小搜索范围，但无法继续用于 city 列。\n索引代价主要体现在索引导致的写操作效率降低和空间占用两方面。\n降低写操作效率写入操作（插入、删除、更新等）同时需要更新索引，所以表上的索引越多，需要做出的索引修改操作越多。所以在写操作频繁的表中，需要一些优化措施。\n占用空间索引会占用磁盘空间，尤其在多个索引的表中，索引可能导致很快达到表大小上限，这跟具体存储引擎有关：\n\nInnoDB 中，使用独立表空间的表，索引 + 数据行有文件大小限制，受操作系统影响；使用系统表空间则所有表和索引共享同一个存储空间池，添加索引会使存储空间减少得很快，但总大小不受操作系统的影响，逻辑上可以配置多个文件，所以可以使用磁盘扩容表空间。\nMyISAM 中，大量的索引可能导致索引文件比数据文件更快达到文件大小的上限。\n\nB&#x2F;B+树索引的限制：\n如果不是按照索引的最左列开始查找，则无法使用该索引；\n不能跳过索引中的列。即，如果一个索引中含有三个列，则只有在使用了第一、二列的情况下，才能使用第三列；\n如果查询中有某个列的范围查询，则其右边所有列都无法使用索引查找。如果范围查询列值的数量有限，可以通过使用多个等于条件替代之。etc.\n\nMySQL索引索引存储\n对于 MyISAM 表，其数据保留在数据文件中，索引值保留在索引文件中，即使用数据的物理位置引用被索引的行，并使用前缀压缩技术使得索引更小，一个表可以有多个索引，但它们都保存在同一个索引文件里。索引文件里的每个索引都由一组有序的关键字行构成，这组关键字行主要用于快速访问数据文件；\n对于 InnoDB 表，默认情况下，只使用一个表空间，用于管理所有的 InnoDB 数据存储和索引存储，也可以修改配置，让它创建的每个表都有自己的表空间，但此时，给定表的数据和索引也同样保存在同一个表空间文件。同样地，InnoDB 将索引值当作一组有序值。InnoDB 存储引擎表是索引组织表，即表中数据按照主键顺序存放，即根据主键引用被索引的行。\n\nsql分析explain分析语法：explain + SQL语句执行explain分析语句的结果列中，有几列是与索引使用情况相关的：\n\ntype：join 类型，判断此次查询是全表扫描还是索引扫描等信息；\npossible_keys：指出MySQL能使用哪个索引在该表中找到行；\nkey：显示MySQL实际决定使用的键(索引)。如果没有选择索引,键是NULL；\nkey_len：显示MySQL决定使用的键长度。如果键是NULL,则长度为NULL；\nref：显示使用哪个列或常数与key一起从表中选择行。\n\n语句执行分析Explain 使用分析\n","categories":["DB"],"tags":["DB","MySQL"]},{"title":"策略模式","url":"/2019/03/20/CS/DesignPatterns/%E7%AD%96%E7%95%A5%E6%A8%A1%E5%BC%8F/","content":"[toc]\n策略模式Define a family of algorithms, encapsulate each one, and make them interchangeable.定义一组算法，将每个算法都封装起来，并且使它们之间可以互换。\n一种采用了面向对象的继承和多态机制的设计模式。\n","categories":["CS"],"tags":["CS","设计模式"]},{"title":"Object","url":"/2019/03/12/java/SourceCode/Object/","content":"[toc]\n","categories":["java"],"tags":["java"]},{"title":"源码阅读","url":"/2019/03/12/java/SourceCode/%E9%98%85%E8%AF%BB%E6%BA%90%E7%A0%81/","content":"[toc]\n顺序\njava.lang\n\n\nObject 1\nString 1\nAbstractStringBuilder 1\nStringBuffer 1\nStringBuilder 1\nBoolean 2\nByte 2\nDouble 2\nFloat 2\nInteger 2\nLong 2\nShort 2\nThread 2\nThreadLocal 2\nEnum 3\nThrowable 3\nError 3\nException 3\nClass 4\nClassLoader 4\nCompiler 4\nSystem 4\nPackage 4\nVoid 4\n\n","categories":["java"],"tags":["java"]},{"title":"201842","url":"/2018/10/15/QA/201842/","content":"[toc]\nHashMap 能存储 null 吗？见 java&#x2F;Container&#x2F;Map，关于 hash 值计算等部分内容。\nequals() 和 &#x3D;&#x3D;equals() 的作用是判断两个对象是否相等，在 Object 里该方法定义是：\npublic boolean equals(Object obj) &#123;\n    return (this == obj);\n&#125;\n也就是说，如果不重写该方法，那么它就等同于“&#x3D;&#x3D;”。而“&#x3D;&#x3D;”是判断两个对象是不是“同一个对象”，即强调二者的地址是否相同。一般会重写 equals 方法，使得该比较能够逻辑上判断两个对象是否相等（值相同或内容相同等）。\nequals() 和 hashCode() 重写问题首先，如果要重写 equals 方法，则必须保证重写后依然满足以下条件：\n\n自反性：A.equals(A)要返回true.\n对称性：如果A.equals(B)返回true, 则B.equals(A)也要返回true.\n传递性：如果A.equals(B)为true, B.equals(C)为true, 则A.equals(C)也要为true. 说白了就是 A &#x3D; B , B &#x3D; C , 那么A &#x3D; C.\n一致性：只要A,B对象的状态没有改变，A.equals(B)必须始终返回true.\nA.equals(null) 要返回false.\n\n其次，必须同时重写 hashCode 方法。hashCode 方法可以看作是为涉及到哈希算法的数据结构（HashSet、HashMap 等）服务的：根据元素的哈希值确定元素所在数据结构的位置。如果仅仅改写 equals 方法而未改写 hashCode 方法，则考虑这种情况：两个逻辑上相等的对象，其哈希值可能不相同，这就可能某些方法失效，如查找某个元素是否存在于该数据结构中。重写 hashCode 的目的就在于，在 A.equals(B) 返回 true 的情况下，A 和 B 的 hashCode() 要返回相同的值。反之，仅重写 hashCode 方法而不重写 equals 方法则是可行的，一般是为了使得元素更均匀分布在数据结构的桶中，从而选择“更好”的哈希算法。\n","categories":["Daily"],"tags":["Daily"]},{"title":"201842","url":"/2018/10/15/QA/Daily/201842/","content":"[toc]\nHashMap 能存储 null 吗？见 java&#x2F;Container&#x2F;Map，关于 hash 值计算等部分内容。\nequals() 和 &#x3D;&#x3D;equals() 的作用是判断两个对象是否相等，在 Object 里该方法定义是：\npublic boolean equals(Object obj) &#123;\n    return (this == obj);\n&#125;\n也就是说，如果不重写该方法，那么它就等同于“&#x3D;&#x3D;”。而“&#x3D;&#x3D;”是判断两个对象是不是“同一个对象”，即强调二者的地址是否相同。一般会重写 equals 方法，使得该比较能够逻辑上判断两个对象是否相等（值相同或内容相同等）。\nequals() 和 hashCode() 重写问题首先，如果要重写 equals 方法，则必须保证重写后依然满足以下条件：\n\n自反性：A.equals(A)要返回true.\n对称性：如果A.equals(B)返回true, 则B.equals(A)也要返回true.\n传递性：如果A.equals(B)为true, B.equals(C)为true, 则A.equals(C)也要为true. 说白了就是 A &#x3D; B , B &#x3D; C , 那么A &#x3D; C.\n一致性：只要A,B对象的状态没有改变，A.equals(B)必须始终返回true.\nA.equals(null) 要返回false.\n\n其次，必须同时重写 hashCode 方法。hashCode 方法可以看作是为涉及到哈希算法的数据结构（HashSet、HashMap 等）服务的：根据元素的哈希值确定元素所在数据结构的位置。如果仅仅改写 equals 方法而未改写 hashCode 方法，则考虑这种情况：两个逻辑上相等的对象，其哈希值可能不相同，这就可能某些方法失效，如查找某个元素是否存在于该数据结构中。重写 hashCode 的目的就在于，在 A.equals(B) 返回 true 的情况下，A 和 B 的 hashCode() 要返回相同的值。反之，仅重写 hashCode 方法而不重写 equals 方法则是可行的，一般是为了使得元素更均匀分布在数据结构的桶中，从而选择“更好”的哈希算法。\n","categories":["Daily"],"tags":["Daily"]},{"title":"string","url":"/2018/08/16/cpp/string/","content":"[toc]\n构成C++ 里 string 包括：\n\nC++标准库中定义的 string、wstring、u16string、u32string；\nC-style 的 C-string：char *、const char *。\n\n拷贝方式str.copy()C++ 标准库 string 提供的函数。完整声明和示例：\ncopy(_CharT* __s, size_type __n, size_type __pos) const\n\n&#x2F;&#x2F;\nchar buffer[20];\nstring str(&quot;Test string...&quot;);\nsize_t length &#x3D; str.copy(buffer, 6, 5);\nbuffer[length] &#x3D; &#39;\\0&#39;;\ncout &lt;&lt; &quot;buffer contains: &quot; &lt;&lt; buffer &lt;&lt; &#39;\\n&#39;;\n\n&#x2F;&#x2F; output：\nbuffer contains: string\n\nC 标准库函数strcpy strncpyC 标准库 &lt;cstring&gt; 提供的函数：strcpy()、strncpy()。其中，strcpy 直到遇到 NULL(‘\\n’)才会结束，否则一直拷贝；strncpy 则提供额外参数，如果拷贝 n 个字节之前遇到 NULL，则停止拷贝，否则，只拷贝 n 个字节后停止。不踩内存则意味着没有结束符，因此最好为 dst 多分配一个字节并置为 NULL 作为结束符。\nstring src &#x3D;&quot;abcdabcd&quot;;\nchar* dst &#x3D; new char[8];\n\nstrcpy(dst, src.c_str()); &#x2F;&#x2F; 踩内存，src 多出一个 NULL，而 dst 分配的内存不够\nstrncpy(dst, src.c_str(), 8);&#x2F;&#x2F; 不踩内存\nmemcpy(dst, src.c_str(), 8); &#x2F;&#x2F; 不踩内存\n\n内存拷贝C 标准库 &lt;cstring&gt; 同时提供了内存拷贝函数：memcpy、memccpy、memmove。三者功能相同，参数上、对结束符处理、内存区域覆盖的处理有所区别。memcpy()函数原型：\nextern void *memcpy(void *dest, void *src, unsigned int count)\n参数说明：dest 为目的字符串，src 为源字符串，count 为要拷贝的字节数。函数功能：将字符串 src 中的前 n 个字节拷贝到 dest 中。返回说明：src 和 dest 所指内存区域不能重叠，函数返回 void* 指针。\nmemccpy()函数原型：\nextern void *memccpy(void *dest, void *src, unsigned char ch, unsigned int count)\n参数说明：dest 为目的字符串，src 为源字符串，ch 为终止复制的字符(即复制过程中遇到 ch 就停止复制)，count 为要拷贝的字节数。函数功能：将字符串 src 中的前 n 个字节拷贝到 dest 中，直到遇到字符 ch 便停止复制。返回说明：src 和 dest 所指内存区域不能重叠，函数返回 void* 类型指针。\nmemmove()函数原型：\nextern void *memmove(void *dest, const void *src, unsigned int count)\n参数说明：dest 为目的字符串，src 为源字符串，count 为要拷贝的字节数。函数功能：将字符串 src 中的前 n 个字节拷贝到 dest 中。返回说明：src 和 dest 所指内存区域可以重叠，重叠可能导致 src 内容发生变化。函数返回 void* 类型指针。\n","categories":["cpp"],"tags":["cpp"]},{"title":"OOP","url":"/2018/06/20/CS/OOP/","content":"","categories":["CS"],"tags":["CS"]},{"title":"数据结构","url":"/2018/06/20/CS/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/","content":"[toc]\nTree几种树结构优缺点比较BSTBST 的性能取决于其平衡情况，当出现极端的不平衡时，查找性能会回落到线性。时间复杂度\n\n查找：树高为 logN 时，为 O(logN)，随着树不平衡加剧，恶化到线性；\n插入：与查找一个不存在的数据代价相同；\n删除：定位+考虑删除情况，不超过当前树形态下查找时间复杂度。\n\nAVL 树严格平衡二叉搜索树，就是为了解决 BST 在最坏情况下查找性能为线性的情况，通过旋转保持自平衡。适用于 查询多，增删少 的情况。时间复杂度\n\n查找：O(logN)；\n插入：每一次插入数据使得某些结点的平衡因子超过 1，要进行旋转操作，总体上代价在 O(logN) 级别；\n删除：删除之后必须检查从删除结点开始到根结点路径上的所有结点的平衡因子。每一次删除操作最多需要 O(logN) 次旋转。因此，删除操作的时间复杂度为 O(logN) + O(logN) &#x3D; O(2logN)。\n\nRBT非严格平衡，最长路径长度不超过最短路径长度的 2 倍，只要求部分地达到平衡，减少了旋转次数（任何不平衡都会在三次旋转之内解决），从而提高了性能。时间复杂度\n\n查找：最好情况下为 O(logN)，最坏情况下比 AVL 要差一些，但也远远好于 BST；\n插入：旋转+变色，基本上为 2 次旋转+O(logN)变色，还是在 O(logN) 级别；\n删除：最多只需要 3 次旋转操作。\n\nB-Tree（平衡多路查找树）WHY即 B 树，这里的 B 是平衡的意思。当数据量维持在内存查找的量级时，RBT 无疑已经是很好的选择（实际上很多实现还有进一步优化），但数据量突破内存极限，不得不进行磁盘查找情况下，比如 OS 文件目录存储，数据库中的文件索引结构的存储，这些情况不可能在内存中建立查找结构，必须在磁盘中建好这样的结构。这种情况下，RBT 并不是一个好的选择：因为在磁盘中组织查找结构，那么从任何一个节点指向其他节点都可能需要执行一次磁盘读取数据到内存再比较的操作，而磁盘 I&#x2F;O 操作，相比于内存操作效率是相当低下的，这就导致 RBT 效率很不稳定。所以需要新的数据结构来适应这种场景，而 B-Tree 就是这一背景下的产物。B 树中的每个结点根据实际情况可以包含大量的关键字信息和分支(当然是不能超过磁盘块的大小，根据磁盘驱动(disk drives)的不同，一般块的大小在1k~4k左右)；这样树的深度降低了，这就意味着查找一个元素只要很少结点从外存磁盘中读入内存，很快访问到要查找的数据。意即，通过降低树的高度，来减少磁盘操作，从而提高性能。\n时间复杂度\n\n查找： 作为一个平衡多路查找树 (m-叉)，查找分成两种：一种是从一个结点查找另一结点的地址的时候，需要定位磁盘地址(查找地址)，查找代价极高。另一种是将结点中的有序关键字序列放入内存，进行优化查找(可以用折半)，相比查找代价极低。而B树的高度很小，因此在这一背景下，B树比任何二叉结构查找树的效率都要高很多。\n插入： 插入会发生结点的分裂操作。当插入操作引起了 s 个节点的分裂时，磁盘访问的次数为 h(读取搜索路径上的节点)＋2s(回写两个分裂出的新节点)＋1（回写新的根节点或插入后没有导致分裂的节点）。因此，所需要的磁盘访问次数是 h+2s+1，最多可达到 3h+1。因此插入的代价是很大的。\n删除：删除会发生结点合并操作。最坏情况下磁盘访问次数是 3h＝（找到包含被删除元素需要h次读访问）+（获取第 2 至 h 层的最相邻兄弟需要 h-1 次读访问）+（在第 3 至 h 层的合并需要 h-2 次写访问）+（对修改过的根节点和第 2 层的两个节点进行 3 次写访问）。\n\nB+-TreeB 树的一种变种，应文件系统所需而产生。一棵 m 阶的 B+ 树和 m 阶的 B 树的差异在于：\n\n有 n 棵子树的结点中含有 n 个关键字； (而B 树是 n 棵子树有 n-1个 关键字)\n所有的叶子结点中包含了全部关键字的信息，及指向含有这些关键字记录的指针，且叶子结点本身依关键字的大小自小而大的顺序链接。 (而 B 树的叶子节点并没有包括全部需要查找的信息)\n所有的非终端结点可以看成是索引部分，结点中仅含有其子树根结点中最大（或最小）关键字。 (而 B 树的非终节点也包含需要查找的有效信息)。\n\nB*-TreeB+ 树的变体，在 B+ 树非根和非叶子结点再增加指向兄弟的指针；B* 树定义了非叶子结点关键字个数至少为(2&#x2F;3)M，即块的最低使用率为 2&#x2F;3（代替 B+ 树的 1&#x2F;2）。B* 树分配新结点的概率比 B+ 树要低，空间使用率更高。\n对比B 树：有序数组+平衡多叉树；数据存在于非叶子节点上。B+ 树：有序数组链表+平衡多叉树；数据只存在于叶子上。B* 树：一棵丰满的 B+ 树。\n[参考]https://blog.csdn.net/u010025211/article/details/47979209https://blog.csdn.net/wl044090432/article/details/54585765https://blog.csdn.net/sup_heaven/article/details/39313731http://kongchen.github.io/why-b-tree/https://blog.csdn.net/v_JULY_v/article/details/6530142\n排序排序（xx+插入排序？）一般是混合实现，为什么选择插入排序作为到达阈值后的转换？一般的混合排序是以快排&#x2F;归并为主，这在排序到一定程度，即到达阈值后，子序列处于一种“几近排序”的状态，也就是几乎已经完成排序的状态，该情况下，插入排序的效果比之其他如冒泡、选择排序等有更好的表现，这来源于理论和实践的检验。\n","categories":["CS"],"tags":["CS"]},{"title":"数据结构","url":"/2018/06/20/CS/O/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84/","content":"[toc]\nTree几种树结构优缺点比较BSTBST 的性能取决于其平衡情况，当出现极端的不平衡时，查找性能会回落到线性。时间复杂度\n\n查找：树高为 logN 时，为 O(logN)，随着树不平衡加剧，恶化到线性；\n插入：与查找一个不存在的数据代价相同；\n删除：定位+考虑删除情况，不超过当前树形态下查找时间复杂度。\n\nAVL 树严格平衡二叉搜索树，就是为了解决 BST 在最坏情况下查找性能为线性的情况，通过旋转保持自平衡。适用于 查询多，增删少 的情况。时间复杂度\n\n查找：O(logN)；\n插入：每一次插入数据使得某些结点的平衡因子超过 1，要进行旋转操作，总体上代价在 O(logN) 级别；\n删除：删除之后必须检查从删除结点开始到根结点路径上的所有结点的平衡因子。每一次删除操作最多需要 O(logN) 次旋转。因此，删除操作的时间复杂度为 O(logN) + O(logN) &#x3D; O(2logN)。\n\nRBT非严格平衡，最长路径长度不超过最短路径长度的 2 倍，只要求部分地达到平衡，减少了旋转次数（任何不平衡都会在三次旋转之内解决），从而提高了性能。时间复杂度\n\n查找：最好情况下为 O(logN)，最坏情况下比 AVL 要差一些，但也远远好于 BST；\n插入：旋转+变色，基本上为 2 次旋转+O(logN)变色，还是在 O(logN) 级别；\n删除：最多只需要 3 次旋转操作。\n\nB-Tree（平衡多路查找树）WHY即 B 树，这里的 B 是平衡的意思。当数据量维持在内存查找的量级时，RBT 无疑已经是很好的选择（实际上很多实现还有进一步优化），但数据量突破内存极限，不得不进行磁盘查找情况下，比如 OS 文件目录存储，数据库中的文件索引结构的存储，这些情况不可能在内存中建立查找结构，必须在磁盘中建好这样的结构。这种情况下，RBT 并不是一个好的选择：因为在磁盘中组织查找结构，那么从任何一个节点指向其他节点都可能需要执行一次磁盘读取数据到内存再比较的操作，而磁盘 I&#x2F;O 操作，相比于内存操作效率是相当低下的，这就导致 RBT 效率很不稳定。所以需要新的数据结构来适应这种场景，而 B-Tree 就是这一背景下的产物。B 树中的每个结点根据实际情况可以包含大量的关键字信息和分支(当然是不能超过磁盘块的大小，根据磁盘驱动(disk drives)的不同，一般块的大小在1k~4k左右)；这样树的深度降低了，这就意味着查找一个元素只要很少结点从外存磁盘中读入内存，很快访问到要查找的数据。意即，通过降低树的高度，来减少磁盘操作，从而提高性能。\n时间复杂度\n\n查找： 作为一个平衡多路查找树 (m-叉)，查找分成两种：一种是从一个结点查找另一结点的地址的时候，需要定位磁盘地址(查找地址)，查找代价极高。另一种是将结点中的有序关键字序列放入内存，进行优化查找(可以用折半)，相比查找代价极低。而B树的高度很小，因此在这一背景下，B树比任何二叉结构查找树的效率都要高很多。\n插入： 插入会发生结点的分裂操作。当插入操作引起了 s 个节点的分裂时，磁盘访问的次数为 h(读取搜索路径上的节点)＋2s(回写两个分裂出的新节点)＋1（回写新的根节点或插入后没有导致分裂的节点）。因此，所需要的磁盘访问次数是 h+2s+1，最多可达到 3h+1。因此插入的代价是很大的。\n删除：删除会发生结点合并操作。最坏情况下磁盘访问次数是 3h＝（找到包含被删除元素需要h次读访问）+（获取第 2 至 h 层的最相邻兄弟需要 h-1 次读访问）+（在第 3 至 h 层的合并需要 h-2 次写访问）+（对修改过的根节点和第 2 层的两个节点进行 3 次写访问）。\n\nB+-TreeB 树的一种变种，应文件系统所需而产生。一棵 m 阶的 B+ 树和 m 阶的 B 树的差异在于：\n\n有 n 棵子树的结点中含有 n 个关键字； (而B 树是 n 棵子树有 n-1个 关键字)\n所有的叶子结点中包含了全部关键字的信息，及指向含有这些关键字记录的指针，且叶子结点本身依关键字的大小自小而大的顺序链接。 (而 B 树的叶子节点并没有包括全部需要查找的信息)\n所有的非终端结点可以看成是索引部分，结点中仅含有其子树根结点中最大（或最小）关键字。 (而 B 树的非终节点也包含需要查找的有效信息)。\n\nB*-TreeB+ 树的变体，在 B+ 树非根和非叶子结点再增加指向兄弟的指针；B* 树定义了非叶子结点关键字个数至少为(2&#x2F;3)M，即块的最低使用率为 2&#x2F;3（代替 B+ 树的 1&#x2F;2）。B* 树分配新结点的概率比 B+ 树要低，空间使用率更高。\n对比B 树：有序数组+平衡多叉树；数据存在于非叶子节点上。B+ 树：有序数组链表+平衡多叉树；数据只存在于叶子上。B* 树：一棵丰满的 B+ 树。\n[参考]https://blog.csdn.net/u010025211/article/details/47979209https://blog.csdn.net/wl044090432/article/details/54585765https://blog.csdn.net/sup_heaven/article/details/39313731http://kongchen.github.io/why-b-tree/https://blog.csdn.net/v_JULY_v/article/details/6530142\n排序排序（xx+插入排序？）一般是混合实现，为什么选择插入排序作为到达阈值后的转换？一般的混合排序是以快排&#x2F;归并为主，这在排序到一定程度，即到达阈值后，子序列处于一种“几近排序”的状态，也就是几乎已经完成排序的状态，该情况下，插入排序的效果比之其他如冒泡、选择排序等有更好的表现，这来源于理论和实践的检验。\n","categories":["CS"],"tags":["CS"]},{"title":"IPC","url":"/2018/06/18/OS/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B/IPC/","content":"[toc]\n进程间通信如果 OS 中一个进程能影响其他进程或被其他进程所影响，那么它们是协作的。共享数据的进程之间互称为协作进程。协作进程需要一种进程之间通信的机制（IPC，InterProcess Communication），即进程间通信。需要 IPC 的理由有：信息共享、提高运算速度、模块化等。进程同步与互斥可以看作低级通信。需要考虑的问题：\n\n一个进程如何把信息传递给另一个；\n如何确保两个&#x2F;多个进程在关键活动中不会出现交叉；\n信息传递的顺序问题。\n\n两种基本模式：\n\n共享内存：建立一块供协作进程共享的内存区域，进程通过向此共享区域读&#x2F;写数据来交换信息；\n消息传递：通过在协作进程间交换信息来实现通信。\n消息传递对于交换较少数据量的数据很有用，因为不需要避免冲突，实现也比共享内存容易，通常需要系统调用来实现，因此需要更多的内核介入的时间消耗。共享内存允许以最快的速度（可以达到内存的速度）进行方便的通信，仅在建立共享内存区域时需要系统调用，一旦建立了共享内存，所有的访问都被处理为常规的内存访问，不需要来自内核的帮助，因而比消息传递快。\n\n共享内存(shared memory)共享内存就是映射一段能被其他进程所访问的内存，这段共享内存由一个进程创建，但多个进程都可以访问，这些进程通过在共享区域内读写来交换信息。共享内存是最快的 IPC 方式，它是针对其他进程间通信方式运行效率低而专门设计的。它往往与其他通信机制（如信号量）配合使用，来实现进程间的同步和通信。\n消息传递消息传递提供一种机制，使得进程不必通过共享地址空间来实现通信和同步。消息传递工具至少提供两种操作：发送消息和接收消息。一般有管道、信号量、信号、消息队列、套接字等。\n管道最基本的 IPC 机制。管道只能在本机上完成数据传递。特征：\n\n本质上是一个伪文件（内核缓冲区）；\n由两个文件描述符引用：一个标识读端，一个标识写端；\n\n匿名管道（）在本地机器上可以使用匿名管道来实现父进程和子进程之间的通信。\n命名管道能够在不相关（不具有血缘关系）的进程之间传递消息。命名管道也被称为 FIFO 文件，它是一种特殊类型的文件，它在文件系统中以文件名的形式存在，但是它的行为却和之前所讲的没有名字的管道（匿名管道）类似。\n信号量(semophore) ：信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步和通信的手段。\n信号 (sinal) ：信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。\n消息队列(message queue) ：消息队列是由消息的链表，存放在内核中并由消息队列标识符标识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。\n套接字( socket ) ：网络间进程通信，与以上通信机制不同的是，它可用于不同机器间的进程通信。\nhttps://blog.csdn.net/gatieme/article/details/50908749\n","categories":["OS"],"tags":["OS"]},{"title":"进程同步","url":"/2018/06/18/OS/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B/%E8%BF%9B%E7%A8%8B%E5%90%8C%E6%AD%A5/","content":"[toc]\n进程同步进程间同步是指进程间的 协作关系。进程同步，Synchronization，指系统中多个进程中发生的事件存在 某种时序关系，需要相互合作，共同完成一项任务。具体来说，一个进程运行到某一个点时，需要另一个进程为它提供消息，在未获得该消息之前，该进程进入阻塞状态，获得消息之后被唤醒进入就绪状态。进程互斥是一种特殊的进程同步关系，即逐次使用互斥共享资源，也是对进程使用资源次序上的一种协调。进程同步机制的实现方法主要有：信号量、管程、互斥、事件。\n信号量信号量能够实现互斥，提供同步功能。要求忙等待。它允许多个线程在同一时刻访问同一资源，但是需要限制在同一时刻访问此资源的最大线程数目。\n管程在程序设计语言中引入的一种成分，作为一种高级同步原语，是语言概念。定义：\n\n是一个特殊的模块\n有一个名字\n由关于共享资源的数据结构及在其上操作的一组过程组成\n\n保证\n互斥管程有一个重要特性：任一时刻管程中只有一个活跃进程。这使得管程能有效完成互斥，保证管程中数据结构的数据完整性。其互斥性是由 编译器 负责保证的（管程本身是语言概念）。\n同步管程中设置 条件变量及等待&#x2F;唤醒操作 来解决同步问题。让进程在条件变量上等待或者通过发送信号将等待在条件变量上的进程&#x2F;线程唤醒。\n\n与进程的关系进程只能通过调用管程提供的各种过程，间接地使用管程中的数据结构。\n互斥进程间互斥是指进程间的 竞争关系。进程间需要共享一些资源（变量、文件等），而这些资源需要 排他性使用，所以进程间对这些资源由竞争关系，这种竞争即称为“进程互斥”，这些被竞争的资源即称为临界资源&#x2F;互斥资源&#x2F;共享变量。在讨论进程互斥时，一般可以理解为这些进程间并不需要协作，即彼此无关，它们并不知道其它进程的存在，并且也不受其它进程执行的影响。\n软件互斥方案使用信号量（semaphore）作为同步工具。信号量 S 是个整数变量，除初始化外，它只能通过两个标准原子操作：wait()、signal() 来访问。这些操作原来成为 P （荷兰语 proberen，测试）和 V （荷兰语 verhogen，增加）。信号量的主要缺点是都要求忙等待,忙等待浪费了 CPU 时钟，这本来可以有效地为其他进程所使用。这种类型的信号量也称为自旋锁。\n硬件互斥方案：使用硬件支持的特殊指令，来达到互斥的目的。\n\n开&#x2F;关中断\n测试并加锁（Test and Set Lock, TSL)\n\n","categories":["OS"],"tags":["OS"]},{"title":"Proxy","url":"/2018/06/15/java/into/Proxy/","content":"[toc]\nProxy或称 Surrogate，中文“代理”，也作为一种设计模式，其解释为：为其他对象提供一种代理以控制对该对象的访问。可以简单理解成“中介”。代理模式可以在不修改被代理对象的基础上，通过扩展代理类，控制被代理对象的访问，也可以为代理类添加新的操作&#x2F;行为。这在 AOP 中经常见到。主要分为静态代理和动态代理两种，但二者在功能上没有区别。一般使用工厂模式实现代理，这样可以将代理包装等操作实现封装在工厂的实现中。要和“装饰者模式”区别开，装饰者模式是 为对象增加行为，代理模式是 控制对象的访问；同时和“适配器模式”的区别是：适配器会改变对象的接口，而代理使用相同的接口（业务接口不变）。\n静态代理一般是代理对象包装被代理对象。\n动态代理是接口代理，被代理类 A 需要实现业务接口，业务代理类 B 需要实现 InvocationHandler 接口。\nhttps://blog.csdn.net/briblue/article/details/73928350https://juejin.im/post/5a3284a75188252970793195https://www.cnblogs.com/dooor/p/5326759.htmlhttps://www.cnblogs.com/fillPv/p/5939277.html\n","categories":["java"],"tags":["java"]},{"title":"一些接口","url":"/2018/06/15/java/into/%E4%B8%80%E4%BA%9B%E6%8E%A5%E5%8F%A3/","content":"[toc]容器类中已经涉及到 Collection 及其相关接口。\nIterablepublic interface Iterable&lt;T> &#123;\n  Iterator&lt;T> iterator();\n&#125;\n可见，Iterable 接口返回一个 Iterator 接口的实例。实现了 Iterable 接口的类可以使用 foreach 遍历。集合类中 Collection 接口的实例类都实现了该接口。\nIterator显然，一个实现了 Iterable 接口的类必然实现了 Iterator 接口——作为 Iterable 的一个方法。反之则不成立。Iterator接口提供的三种方法： \n\nboolean hasNext(): 返回集合里的下一个元素；\nObject next(): 返回集合里下一个元素；\nvoid remove(): 删除集合里上一次next方法返回的元素。\n\n为什么不合为一个？实现了 Iterable 的类可以实现多个 Iterator 内部类，例如 LinkedList 中的 ListItr 和 DescendingIterator 两个内部类，就分别实现了双向遍历和逆序遍历。通过返回不同的 Iterator 实现不同的遍历方式，这样更加灵活。如果把两个接口合并，就没法返回不同的 Iterator 实现类了。\nCloneablepublic interface Cloneable &#123;&#125;\n是的，该接口没有定义任何方法，它的作用是为了标明哪些对象可以实现拷贝。实现了该接口的对象才能通过 JVM 执行克隆操作时的检查，没有实现该接口的会被抛出 CloneNotSupportedException 异常而无法进行克隆操作。并且，约定实现了 Cloneable 接口的类需要重写 Object 类的 clone 方法，重写该方法最简单的方式就是直接通过 super.clone() 调用 Object 的 clone方法，惯例是以 public 方式实现。\n实现该接口的类，可以：\n\n使用 clone() 方法合法地对该类实例进行按字段复制；\n如果在没有实现该接口的实例上调用 Object 的 clone() 方法，会抛出 CloneNotSupporteddException；\n按照惯例，实现该接口的类应该使用公共方法重写 Object 的 clone() 方法。而 Object 的 clone() 方法是一个受保护的方法。\n\nObject 的 clone()创建并返回此对象的一个副本。对于任何对象 x，表达式：\n\nx.clone() !&#x3D; x 为 true;\nx.clone().getClass() &#x3D;&#x3D; x.getClass() 为 true;\nx.clone().equals(x) 一般情况下为 true，但这并不是必须要满足的要求；\n克隆一个对象并不会调用被克隆对象的构造方法。\n\n为什么需要克隆对象？Java 中所有的对象都是保存在堆中，而堆是供全局共享的。也就是说，如果同一个 Java 程序的不同方法，只要能拿到某个对象的引用，引用者就可以随意地修改对象的内部数据（前提时该数据的 get&#x2F;set 方法可用）。而有时需要让调用者只获得该对象的一个拷贝（也就是一个内容完全相同的对象，但是在内存中存在两个这样的对象），比如想操作一个对象，但又需要保留该对象的当前状态。此时克隆就是解决方案（之一），它允许在堆中克隆出一个和原对象一样的对象（但它们不是同一个对象，也不在同一块地址上，只是各个数据段相同），并将这个对象的地址赋予新的引用。\nOOP 中的克隆对象都会涉及到这样的概念：浅拷贝、深拷贝。它们反映的是，当（支持拷贝的）对象中有其它对象实例时的不同实现机制。\n浅拷贝表层拷贝，对基本数据类型的字段值直接复制一份新值，而字段如果为对象的引用类型，那么只会复制该引用，即克隆出来的对象的属性和原来对象的属性指向同一个对象实例。如，Person 对象包含 age、name 和 birDate 属性。name 为 String 类型的对象，而 birDate 为 Date 类型对象，那么通过默认的克隆策略克隆出来后为右边的 P_Copy 对象，name 和 birDate 属性都是指向原来 Person 对象属性指向的对象实例。\n\n浅拷贝不是真的完全拷贝，它们可以各自修改自己的 age 属性而不会影响到彼此，但如果改动了 name 或 birDate 引用对象的值将会互相影响。其优点是节省内存空间。\n深拷贝与浅拷贝对应地，拷贝包括基本数据类型和所包含的对象实例。上述例子的深拷贝结果：\n\n\n\n参考：从JDK角度看对象克隆\n","categories":["java"],"tags":["java"]},{"title":"MQ","url":"/2018/06/14/db/MQ/","content":"[toc]\nMQMessage Queue，消息队列：是分布式系统中重要组件，主要用于解决 应用耦合、异步消息、流量削峰 等问题。生产环境中如抢购、秒杀等需要控制并发量的场景中都需要用到 MQ。常用 MQ 有：RabbitMQ（Rabbit）、RocketMQ（Ali -&gt; Apache）、ActiveMQ（Apache）、Kafka（Linkedin -&gt; Apache）、MetaMQ 等，部分数据库如 Redis、MySQL 等也可以实现消息队列功能。\n应用场景应用耦合多应用之间通过 MQ 对同一消息进行处理，避免调用接口失败导致整个过程失败。如，用户使用 QQ 相册上传图片，人脸识别系统会对图片进行人脸识别，一般做法是：服务器收到图片后，图片上传系统立即调用人脸识别系统，调用完成后返回结果：https://cloud.tencent.com/developer/article/1006035\n异步处理多应用对 MQ 中同一消息进行处理，应用间并发处理消息，相比于串行处理，能够减少处理时间。如，\n限流削峰如，购物网站经常举行秒杀活动，会导致瞬时访问量过大，流量激增，可能导致服务器宕机。加入 MQ 后，服务器以可接受的数量从 MQ 中拉取数据进行处理，相当于 MQ 作为中间缓冲。\n消息驱动的系统两种模式p2p点对点模式包括 3 个据角色：\n\n消息队列；\n发送者（生产者）；\n接收者（消费者）\n消息发送者生产消息发送到 queue 中，然后消息接收者从 queue 中取出并消费消息。特点：\n每个消息只有一个接收者，即一旦被消费，该消息就从 MQ 中取出；\n发送者和接收者之间没有依赖性，发送者发送消息之后，不管有没有接收者在运行，都不会影响到发送者下次发送消息；\n接收者在成功接收到消息之后需要向队列应答，以便 MQ 删除当前接收的消息。\n\n发布&#x2F;订阅发布&#x2F;订阅模式包括 3 个据角色：\n\n角色主题（Topic）\n发布者（Publisher）\n订阅者（Subscriber）\n发布者将消息发送到 Topic，系统将这些消息传递给多个订阅者。特点：\n每个消息可以有多个订阅者；\n发布者和订阅者之间有时间上的依赖性：针对某个 Topic 的订阅者，必须创建一个订阅者之后，才能消费发布者的消息；\n为了消费消息，订阅者需要提前订阅该 Topic，并保持在线运行。\n\n常用 MQ 简介RabbitMQ基于 AMQP（高级消息队列协议）完成的、可复用的企业消息系统。\nhttps://www.zhihu.com/question/43557507https://www.jianshu.com/p/689ce4205021\n","categories":["backend"],"tags":["backend"]},{"title":"Annotation","url":"/2018/06/13/java/into/Annotation/","content":"[toc]\nAnnotation注解（元数据）是 JDK5 引入的新特性，提供用来完整地描述程序所需的信息，而这些信息是无法用 java 来表达的。使用上，除了“@”符号外，它与普通的修饰符如 public、static、void 等没有什么区别。它们的出现代表某种 配置语义，使得源代码中不但可以包含功能性的实现代码，还可以添加元数据。注解已经在很多框架中得到了广泛的使用，用来简化程序中的配置。注解也将编译成 class 文件。\n内置注解目前 JDK10 内置了以下注解。标准注解：\n\n@Override：表示当前的方法将覆盖父类中相同签名的方法。如果不慎拼写错误或者方法签名不一致，编译器会发出错误提示。方法。\n@Deprecated：表示不再被推荐使用，继续使用的话编译器会发出警告，未来版本中可能移除。全部。\n@SuppressWarnings：关闭不当的编译器警告。除了包和注解之外。\n@SafeVarargs：参数安全类型注解。提醒用户不要用参数做一些不安全的操作，会阻止编译器产生 unchecked 警告。JDK1.7。\n@PostConstruct @PreDestroy：被标记的方法应该在构造之后或移除之前立即被调用。方法。\n@Resource：在类或接口上，标记为在其他地方要用到的资源。在方法或域上，为“注入”而标记。类、接口，方法、域。\n@Resources：一个资源数组。类、接口。\n@Generated：供代码生成工具使用。全部。\n@FunctionalInterface：函数式接口注解，鉴于函数式编程的兴起而添加，只起到文档作用，表明这是个函数式接口——可以很容易地转成 Lambda 表达式。比如线程开发中常用的 Runnable 接口就是一个典型的函数式接口。接口。JDK1.8。\n\n元注解：\n\n@Target：定义注解将应用于什么地方：如方法&#x2F;域。\n@Retention：定义注解应用于什么级别，可选参数：SOURCE（源代码）：将被编译器丢弃、CLASS（类文件）：在 class 文件中可用，但会被 VM 丢弃、RUNTIME（运行时）：VM 在运行期也会保留该注解，因此可以通过反射机制读取注解的信息。\n@Documented：将此注解包含在 javadoc 中。\n@Inherited：允许子类继承父类中的注解。\n@Repeatable：可重复使用在某个对象上。JDK1.8。\n\n使用实例解释：\n注解的简单使用public class AnnotationDemo &#123;\n    // @Test注 解修饰方法 A\n    @Test\n    public static void A()&#123;\n        System.out.println(\"Test.....\");\n    &#125;\n    // 一个方法上可以拥有多个不同的注解\n    @Deprecated\n    @SuppressWarnings(&#123;\"uncheck\", \"unused\"&#125;)\n    public static void B()&#123;\n    &#125;\n&#125;\n通过在方法上使用 @Test 注解，在运行该方法时，测试框架会自动识别该方法并单独调用。@Test 实际上是一种标记注解，起到标记的作用，运行时告诉测试框架该方法为测试方法。对于 @Deprecated 和 @SuppressWarnings，则是 java 内置的注解，前者表明该方法&#x2F;类已经过期或不建议再使用，后者表示忽略指定警告，括号里表示该注解可供配置的值，用花括号表示数组，配置参数值必须是编译时常量。\n应用场景注解应用场景很多，主要给编译器及工具类型软件使用，如很多框架（Spring、Junit 等）。\n定义注解使用 @interface 关键字定义：\npublic @interface AnnotationName &#123;&#125;\n定义注解时，需要用到一些元注解（meta-annotation），如 @Traget（定义注解将应用于什么地方：如方法&#x2F;域）、@Retention（定义注解应用于什么级别，如 SOURCE 即源代码、CLASS 即类文件、RUNTIME 即运行时）等。一般还会包含一些值，就像接口的方法，并且可以提供默认值，而没有元素的注解称为 标记注解。\n元注解基本注解，能够应用到其他注解上，可以理解为注解到注解上的注解。\n注解的属性也称成员变量。注解只有成员变量，没有方法。注解的成员变量在注解的定义中以“无形参的方法”形式来声明，其方法名定义了该成员变量的名字，其返回值定义了该成员变量的类型：\n@Target(ElementType.TYPE)\n@Retention(RetentionPolicy.RUNTIME)\npublic @interface AnnotationName &#123;\n    int id();\n    String msg() default \"No message.\";\n&#125;\n该注解有两个属性：id、msg，并且 msg 定义了默认值，如果没有默认值则需要显式给出。特别地，如果注解只有 1 个属性，那么在给出值时可以不指明属性名；没有属性时，可以直接给出注解名，不需要括号。\n架构\n可见，\n\n1 个 Annotation 和 1 个 RetentionPolicy 关联。i.e. 每个 Annotation 对象，都会有唯一的 RetentionPolicy 属性；\n1 个 Annotation 和 1~n 个 ElementType 关联。i.e. 对于每个 Annotation 对象，可以有若干个 ElementType 属性；\nAnnotation 有许多实现类，包括：Deprecated, Documented, Inherited, Override 等。每个实现类，都“和 1 个 RetentionPolicy 关联”并且“和 1~n 个 ElementType 关联”。\n\n组成Annotation 组成中有 3 个主干类：\nAnnotation.java它是一个接口：\npublic interface Annotation &#123;\n    boolean equals(Object obj);\n    int hashCode();\n    String toString();\n    Class&lt;? extends Annotation> annotationType();\n&#125;\n\n\n\nhttp://www.infoq.com/cn/articles/cf-java-annotationhttps://blog.csdn.net/javazejian/article/details/71860633https://www.cnblogs.com/skywang12345/p/3344137.htmlhttps://blog.csdn.net/briblue/article/details/73824058\n","categories":["java"],"tags":["java"]},{"title":"java编程思想5","url":"/2018/06/13/java/into/on-java-8/","content":"[toc]\n在 Java 中，对象的创建与初始化是统一的概念，二者不可分割。  c6.1GC 只知道如何释放用 new 创建的对象的内存，为了处理“不是 new 分配的内存”的情况，Java 允许在类中定义一个名为 finalize() 的方法。  c6.4在类中变量定义的顺序决定了它们初始化的顺序。即使变量定义散布在方法定义之间，它们仍会在任何方法（包括构造器）被调用之前得到初始化。初始化的顺序先是静态对象（如果它们之前没有被初始化的话），然后是非静态对象。静态初始化只有在必要时刻才会进行：当首次创建这个类的对象或首次访问这个类的静态成员（甚至不需要创建该类的对象）时。  c6.7\n对于没有垃圾回收和析构函数自动调用机制的语言来说，finally 非常重要。它能使程序员保证：无论 try 块里发生了什么，内存总能得到释放。但 Java 有垃圾回收机制，所以内存释放不再是问题。而且，Java 也没有析构函数可供调用。那么，Java 中 finally 的作用为：当要把除内存之外的资源恢复到它们的初始状态时，就要用到 finally 子句。这种需要清理的资源包括：已经打开的文件或网络连接，在屏幕上画的图形，甚至可以是外部世界的某个开关。  c15.8\n资源操作尽可能使用&#x2F;推荐使用 try-with-resources，可以避免处理资源关闭的冗余代码，也更加安全、清晰、易于理解。 c15\n","categories":["java"],"tags":["java"]},{"title":"内部类","url":"/2018/06/13/java/into/%E5%86%85%E9%83%A8%E7%B1%BB/","content":"[toc]\n","categories":["java"],"tags":["java"]},{"title":"Reflection","url":"/2018/06/13/java/into/Reflection/","content":"[toc]\nReflection反射，是 java 语言的特征之一，它允许运行中的 java 程序获取自身的信息，并且可以操作类对象或类的内部属性。反射的核心是 JVM 在运行时才动态加载类或调用方法&#x2F;访问属性，它不需要事先（写代码的时候或编译期）知道运行对象是谁。Oracle 官方解释：Reflection enables Java code to discover information about the fields, methods and constructors of loaded classes, and to use reflected fields, methods, and constructors to operate on their underlying counterparts, within security restrictions.The API accommodates applications that need access to either the public members of a target object (based on its runtime class) or the members declared by a given class. It also allows programs to suppress default reflective access control.即，通过反射，可以在运行时获得程序或程序集中每一个类型的成员和成员的信息。一般，程序中对象的类型都是在编译期就确定下来的，而 Java 反射机制可以动态地创建对象并调用其属性，这样的对象的类型在编译期是未知的。所以可以通过反射机制直接创建对象，即使这个对象的类型在编译期是未知的。\n“反射”获取类对象一般，用户使用某个类，应该从这个类定义出发，通过这个类产生实例化对象，这是类对象的使用方式；而“反射”，则是“相反”：通过对象找到这个类。具体就是，通过 instance.getClass() 方法，得到对象所在的“package.class”名称，getClass() 作为发起一切反射操作的开端（Object 的一个方法）：\n// 泛型都定义为 ?，返回值都是Object。\npublic final native Class&lt;?> getClass();\n除了使用 getClass() 方法（事实上一般不使用这个方法）获取类的实例化对象，还有：class.class：\nClass&lt;?> cls = Person.class; // 取得Class对象\nSystem.out.println(cls.getName()); // 获取打印 package.class\n以及，使用 Class 类内部定义的一个 static 方法：forName()\nClass&lt;?> cls = Class.forName(\"package.class\") ; // 取得Class对象\nSystem.out.println(cls.getName()); // 获取打印 package.class\n\n实例化public T newInstance() throws InstantiationException, IllegalAccessException &#123;&#125;\n\n功能反射框架主要提供以下功能（主要强调是在运行时，而非编译期间）：\n\n在运行时判断任意一个对象所属的类；\n在运行时构造任意一个类的对象；\n在运行时判断任意一个类所具有的成员变量和方法（甚至包括 private 方法）；\n在运行时调用任意一个对象的方法。\n\n获取 class 对象常用以下 3 种方式获取。\n使用 class 类的 forName 静态方法public static Class&lt;?> forName(String className)\nJDBC 开发中，通常使用这种方式加载数据库驱动：\nClass.forName(driver);\n\n直接获取某一个对象的 classClass&lt;?> klass = int.class;\nClass&lt;?> classInt = Integer.TYPE;\n\n调用某个对象的 getClass() 方法StringBuilder str = new StringBuilder(\"123\");\nClass&lt;?> klass = str.getClass();\n\n判断是否为某个类的实例一般，用 instanceof 关键字来判断是否为某个类的实例。同时也可以使用 isInstance() 方法判断是否为某个类的实例，这是一个 Native 方法：    \nmyClass instanceof Object;\npublic native boolean isInstance(Object obj);\n\n创建实例通过反射生成对象。\n获取构造器信息通过 Class 类的 getConstructor 方法得到 Constructor 类的一个实例，而 Constructor 类有一个 newInstance 方法可以创建一个对象实例。\n\ngetConstructor(Class… parameterTypes)获得指定的构造方法，注意只能获得 public 权限的构造方法，其他访问权限的获取不到；\ngetDeclaredConstructor(Class… parameterTypes)获得指定的构造方法，可以获取到任何访问权限的构造方法；\ngetConstructors()获得所有 public 访问权限的构造方法；\ngetDeclaredConstructors()获得所有的构造方法，所有权限的构造方法。\n\n获取方法\ngetDeclaredMethods()返回类或接口声明的所有方法，包括公共、保护、默认（包）访问和私有方法，但不包括继承的方法；\ngetDeclaredMethod()返回一个特定的共有方法，包括公共、保护、默认（包）访问和私有方法，但不包括继承的方法；\ngetMethods()返回某个类的所有公用（public）方法，包括其继承类的公用方法；\ngetMethod()返回一个特定的共有方法，其中第一个参数为方法名称，后面的参数为方法的参数对应 Class 的对象；\n\n获取类的成员变量（字段）信息主要是这几个方法，和获取方法类似：\n\ngetFiled: 访问公有的成员变量；\ngetDeclaredField：所有已声明的成员变量。但不能得到其父类的成员变量；\ngetFileds 和 getDeclaredFields。\n\n调用方法从类中获取了一个方法后，就可以用 invoke() 来调用这个方法。invoke() 原型为:\npublic Object invoke(Object obj, Object... args)\n    throws IllegalAccessException, IllegalArgumentException,\n       InvocationTargetException &#123;&#125;\n\n修改 private 属性&#x2F;方法通过以上方法可以获取实例的任何域&#x2F;方法，然后通过相应的方法设置语言访问检查权限，即可修改属性值&#x2F;调用方法\n// 修改域值，非 public 需要修改访问权限\nfield.setAccessible(true);\nfield.set(instanceOfClass, newVvalue);\n\n// 调用方法(实例名后是参数列表的实参值)\n// 非 public 需要修改访问权限\nmethod.setAccessible(true);\nmethod.invoke(instanceOfClass, newValue);\n\n应用场景java 中很重要的两个概念：注解和动态代理，都是使用反射技术有着很紧密的联系。\n反射最重要的用途是开发各种通用框架。比如使用动态代理的 Spring、MyBatis 等框架都是配置化的，为了保证框架的通用性它们可以根据配置文件加载不同的类&#x2F;对象，调用不同的方法，此时就必须使用反射——运行时动态加载需要加载的对象。\nhttps://www.sczyh30.com/posts/Java/java-reflection-1https://blog.csdn.net/gdutxiaoxu/article/details/68947735https://www.cnblogs.com/rollenholt/archive/2011/09/02/2163758.htmlhttps://www.zhihu.com/question/24304289/answer/38218810\n","categories":["java"],"tags":["java"]},{"title":"Executor框架","url":"/2018/06/08/java/Thread/Executor%E6%A1%86%E6%9E%B6/","content":"[toc]\n组成\n框架主要由 3 大部分组成：\n\n任务：被执行任务需要实现 Runnable&#x2F;Callable 接口；\n任务的执行：任务执行机制的核心接口就是 Executor，ExecutorService 接口继承了 Executor 接口，拥有两个具体实现类：ThreadPoolExecutor、ScheduledThreadPoolExecutor；\n异步计算的结果：包括接口 Future 和 其实现类 FutureTask\n\n执行流程\n\nExecutor 接口整个框架的基础，它 将任务的提交和任务的执行解耦。该接口用 Runnable&#x2F;Callable 来表示任务，提供了一种标准的方法将任务的提交过程与执行过程分离开，并提供对生命周期的支持和统计信息收集、性能监视等机制。\npublic interface Executor &#123;\n    void execute(Runnable command);\n&#125;\nExecutor 接口只有一个 execute 方法，用来替代通常创建或启动线程的方法，如，使用 Thread 来创建并启动线程：\nThread t = new Thread();\nt.start();\n而使用 Executor 来启动线程执行任务的代码如下：\nThread t = new Thread();\nexecutor.execute(t);\n对于不同的 Executor 实现，execute() 方法可能是创建一个新线程并立即启动，也有可能是使用已有的工作线程来运行传入的任务，也可能是根据设置线程池的容量或者阻塞队列的容量来决定是否要将传入的线程放入阻塞队列中或者拒绝接收传入的线程。\nExecutorService 接口继承了 Executor 接口，提供了管理终止的方法，以及可以为跟踪一个或多个异步任务执行状况而生成 Future 的方法，增加了 shutDown()、shutDownNow()、invokeAll()、invokeAny()、submit() 等方法。如果需要支持即时关闭，即 shutDownNow() 方法，则任务需要正确处理中断。\nScheduledExecutorService 接口继承了 ExecutorService 接口并增加了 schedule 方法。调用 schedule 方法可以在指定的延时后执行一个 Runnable 或者 Callable 任务。ScheduledExecutorService 接口还定义了按照指定时间间隔定期执行任务的 scheduleAtFixedRate() 方法和 scheduleWithFixedDelay() 方法。\nThreadPoolExecutor 类继承自 AbstractExecutorService 虚类，后者实现了 ExecutorService 接口。ThreadPoolExecutor 通常使用工厂类 Executors 来创建，主要创建 3 种类型的 ThreadPoolExecutor：SingleThreadExecutor、FixedThreadPool和CachedThreadPool。具体又包含以下 5 种：\n5 种线程池newSingleThreadExecutor创建一个单线程化的线程池，即它只会使用一个线程来执行所有任务（相当于串行操作），保证所有任务按照指定顺序（FIFO、LIFO、优先级等）顺序执行。适用于需要顺序执行各个任务的场景，它保证在任意时间点，不会有多个活动线程。\nnewCachedThreadPool创建一个可缓存线程池，如果线程池长度超过处理需求，可灵活回收空闲线程，若没有可回收，则为任务新建线程。此种线程池（理论上）可无限扩张，然而当执行下一个任务时如果探测到前一个任务已经完成，那么就会复用（而非新建）线程。适用于执行很多短期异步任务的小程序、负载较轻的服务器等场景。\nnewFixedThreadPool创建一个固定长度的线程池。也就是可根据系统资源情况，控制线程的最大并发数，超出的线程会在队列中等待。适用于需要控制资源管理的场景，能够限制线程数量，如重量级服务器。\nnewScheduledThreadPool创建一个固定长度的线程池。支持定时&#x2F;延迟和周期执行任务等功能。适用于需要多个后台线程执行周期任务，同时能够提供资源管理需求、限制后台线程数量的场景。\nnewSingleThreadScheduledExecutor创建一个单线程“池”，支持定时&#x2F;延迟和周期执行任务等。可以看作上面两个的结合。适用于需要单个后台线程执行周期任务，同时需要保证顺序地执行各个任务的场景。\n重要字段private final AtomicInteger ctl = new AtomicInteger(ctlOf(RUNNING, 0));\nprivate static final int COUNT_BITS = Integer.SIZE - 3;\nprivate static final int COUNT_MASK = (1 &lt;&lt; COUNT_BITS) - 1;\n\n// runState is stored in the high-order bits\nprivate static final int RUNNING    = -1 &lt;&lt; COUNT_BITS;\nprivate static final int SHUTDOWN   =  0 &lt;&lt; COUNT_BITS;\nprivate static final int STOP       =  1 &lt;&lt; COUNT_BITS;\nprivate static final int TIDYING    =  2 &lt;&lt; COUNT_BITS;\nprivate static final int TERMINATED =  3 &lt;&lt; COUNT_BITS;\nctl 是对线程池的运行状态和线程池中有效线程数量进行控制的一个字段：包含两部分信息：\n\n线程池的运行状态（runState）；\n线程池内有效线程的数量（workerCount）。可见，使用 int 的高 3 位保存 runState，低 29 位保存 workerCount：COUNT_BITS &#x3D; 29。COUNT_MASK 用来计算最大线程数，位 2^29-1，约 5 亿。\n\n构造方法public ThreadPoolExecutor(\n    int corePoolSize,\n    int maximumPoolSize,\n    long keepAliveTime,\n    TimeUnit unit,\n    BlockingQueue&lt;Runnable> workQueue,\n    ThreadFactory threadFactory,\n    RejectedExecutionHandler handler) \n    &#123;&#125;\n参数解释：\ncorePoolSize：核心线程数量，当有新任务在 execute() 方法提交时，会执行以下判断：\n\n如果运行的线程少于 corePoolSize，则创建新线程来处理任务，即使线程池中的其他线程是空闲的；如果线程池中的线程数量大于等于 corePoolSize 且小于 maximumPoolSize，则只有当 workQueue 满时才创建新的线程去处理任务；如果设置的 corePoolSize 和 maximumPoolSize 相同，则创建的线程池的大小是固定的，这时如果有新任务提交，若 workQueue 未满，则将请求放入 workQueue 中，等待有空闲的线程去从 workQueue 中取任务并处理；如果运行的线程数量大于等于 maximumPoolSize，这时如果 workQueue 已经满了，则通过 handler 所指定的策略来处理任务；所以，任务提交时，判断的顺序为 corePoolSize –&gt; workQueue –&gt; maximumPoolSize。\n\n\nmaximumPoolSize：最大线程数量；\n\nworkQueue：保存等待执行的任务的阻塞队列，当提交一个新的任务到线程池以后, 线程池会根据当前线程池中正在运行着的线程的数量来决定对该任务的处理方式，主要有以下几种处理方式:\n\n直接切换：这种方式常用的队列是 SynchronousQueue，但现在还没有研究过该队列，这里暂时还没法介绍；使用无界队列：一般使用基于链表的阻塞队列 LinkedBlockingQueue。如果使用这种方式，那么线程池中能够创建的最大线程数就是 corePoolSize，而maximumPoolSize 就不会起作用了（后面也会说到）。当线程池中所有的核心线程都是 RUNNING 状态时，这时一个新的任务提交就会放入等待队列中;使用有界队列：一般使用 ArrayBlockingQueue。使用该方式可以将线程池的最大线程数量限制为 maximumPoolSize，这样能够降低资源的消耗，但同时这种方式也使得线程池对线程的调度变得更困难，因为线程池和队列的容量都是有限的值，所以要想使线程池处理任务的吞吐率达到一个相对合理的范围，又想使线程调度相对简单，并且还要尽可能的降低线程池对资源的消耗，就需要合理的设置这两个数量。\n\n\nkeepAliveTime：线程池维护线程所允许的空闲时间。当线程池中的线程数量大于 corePoolSize 的时候，如果这时没有新的任务提交，核心线程外的线程不会立即销毁，而是会等待，直到等待的时间超过了keepAliveTime；\n\nthreadFactory：ThreadFactory 类型的变量，用来创建新线程。默认使用 Executors.defaultThreadFactory() 来创建线程。使用默认的 ThreadFactory 来创建线程时，会使新创建的线程具有相同的 NORM_PRIORITY 优先级并且是非守护线程，同时也设置了线程的名称;\n\nhandler：RejectedExecutionHandler 类型的变量，表示线程池的饱和策略，及达到 maximumPoolSize。如果阻塞队列满了并且没有空闲的线程，这时如果继续提交任务，就需要采取一种策略处理该任务。线程池提供了4种策略：\n\nAbortPolicy：直接抛出异常，这是默认策略；CallerRunsPolicy：用调用者所在的线程来执行任务；DiscardOldestPolicy：丢弃阻塞队列中靠最前的任务，并执行当前任务；DiscardPolicy：直接丢弃任务；\n\n\n\nFuture 接口Future 接口和其实现类 FutureTask 用来表示异步计算的结果：把 Runnable&#x2F;Callable 接口的实现类提交（submit）给 ThreadPoolExecutor&#x2F;ScheduledThreadPoolExecutor 时，ThreadPoolExecutor&#x2F;ScheduledThreadPoolExecutor 会返回一个 FutureTask 对象：\n&lt;T> Future&lt;T> submit(Callable&lt;T> task)\n&lt;T> Future&lt;T> submit(Runnable task, T result)\nFuture&lt;> submit(Runnable task)\nFutureTask.get() 方法等待（也就是会阻塞在任务执行线程上）线程执行完任务，然后返回执行结果。\nRunnable &amp; Callable 接口二者的实现类都可以被 ThreadPoolExecutor&#x2F;ScheduledThreadPoolExecutor 执行，区别在于：Runnable 不会返回结果，Callable 可以返回结果。可以通过工厂类 Executors 把一个 Runnable 包装成一个 Callable：\n// 把一个 Runnable 包装成一个 Callable\npublic static Callable&lt;Object> callable(Runnable task)\n// ，把一个 Runnable 和一个待返回的结果包装成一个 Callable\npublic static &lt;T> Callable&lt;T> callable(Runnable task, T result)\n\n\nhttps://blog.csdn.net/bluetjs/article/details/52935594https://www.cnblogs.com/dolphin0520/p/3932921.htmlhttps://juejin.im/entry/58fada5d570c350058d3aaadhttps://blog.csdn.net/u011974987/article/details/51027795\n","categories":["java"],"tags":["java","线程","并发"]},{"title":"线程池","url":"/2018/06/08/java/Thread/%E7%BA%BF%E7%A8%8B%E6%B1%A0/","content":"[toc]\n线程池线程能够很好地提升进程执行速度和提高资源利用。而仅仅在需要一个线程的时候才去创建的话，在某些情况下就会带来问题：如果并发的线程数量众多，并且每个线程都是执行很短的时间就结束了，这种场景下，频繁创建&#x2F;销毁线程就会浪费很多时间，在很大程度上降低系统效率。此时，一个可行的方案就是，能否对线程进行复用——执行完一个任务后，委派其他任务给它继续执行，而不是将其销毁，即，将 Runnable 对象交给线程池，线程池负责委派一个线程执行调用对象的 run 方法，当 run 方法退出后，线程并不随之终结，而是返回线程池，由线程池管理。java 中称之为线程池技术。\n为什么线程池可以提升性能？上面提到了频繁创建&#x2F;销毁线程会降低性能。具体而言，new Thread 的弊端有：\n\n每次 new Thread 新建对象性能差；\n线程缺乏统一管理，可能无限制创建新线程，相互之间竞争，以及可能占用过多系统资源导致 OOM（每个线程需要大约 1MB 内存）；\n缺乏更多功能，如定时执行、定期执行、线程中断等。\n\n而相对的，线程池的好处有：\n\n复用已存在的线程，减少线程对象的创建、销毁的开销；\n可有效控制最大并发线程数量，提高系统资源的使用率，同时避免过多资源竞争，导致阻塞；\n提供定时执行、定期执行、单线程、并发数控制等。\n\n线程池中线程初始化默认情况下，创建线程池之后，线程池中是没有线程的，需要提交任务之后才会创建线程。在实际中如果需要线程池创建之后立即创建线程，可以通过以下两个方法办到：\n\nprestartCoreThread()：初始化一个核心线程；\nprestartAllCoreThreads()：初始化所有核心线程。\n\n线程池状态共有 5 种状态：\n\nRUNNING：能接受新提交的任务，并且也能处理阻塞队列中的任务；\nSHUTDOWN：关闭状态，不再接受新提交的任务，但却可以继续处理阻塞队列中已保存的任务。在线程池处于 RUNNING 状态时，调用 shutdown() 方法会使线程池进入到该状态。（finalize() 方法在执行过程中也会调用 shutdown() 方法进入该状态）；\nSTOP：不能接受新任务，也不处理队列中的任务，会中断正在处理任务的线程。在线程池处于 RUNNING 或 SHUTDOWN 状态时，调用 shutdownNow() 方法会使线程池进入到该状态；\nTIDYING：如果所有的任务都已终止了，workerCount (有效线程数) 为0，线程池进入该状态后会调用 terminated() 方法进入TERMINATED 状态。\nTERMINATED：在 terminated() 方法执行完后进入该状态，默认 terminated() 方法中什么也没有做。　　进入 TERMINATED 的条件如下：　　线程池不是 RUNNING 状态；　　线程池状态不是 TIDYING 状态或 TERMINATED 状态；　　如果线程池状态是 SHUTDOWN 并且 workerQueue 为空；　　workerCount 为 0；　　设置 TIDYING 状态成功。\n\n线程池大小配置具体的设置需要根据实际情况进行调整，比如可以先将线程池大小设置为参考值，再观察任务运行情况和系统负载、资源利用率来进行适当调整。一般需要根据任务的类型来配置线程池大小：\n\nCPU 密集型任务，就需要尽量压榨 CPU，参考值可以设为 CPUs + 1；\nIO 密集型任务，参考值可以设置为 2 * CPUs\n\n","categories":["java"],"tags":["java","线程","并发"]},{"title":"数据存储","url":"/2018/06/08/CS/%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/","content":"[toc]\n原码&#x2F;反码&#x2F;补码在计算机中，负数以其正值的补码形式表达。补码：正数的补码是其自身，负数的补码是其反码 + 1。为什么要用补码？为方便计算：负数补码与绝对值的补码（或者说原码）之和等于 0。\n数据对齐（CSAPP）如 C、C++ 里有数据对齐的概念。许多计算机系统对基本数据类型的合法地址做出了一些限制，要求某种类型对象的地址必须是某个值 K（通常是 2、4、8）的倍数。这种对齐限制 简化了处理器和内存系统之间接口的设计。而无论对齐与否，都不会影响硬件正常工作，但考虑到比如 double 数据，如果不对齐，那么可能需要两次内存才能读取一个完整的 double（因没有对齐而导致每次取读它的一半）。所以对齐操作的主要考虑是对性能上的影响。\n","categories":["CS"],"tags":["CS"]},{"title":"数据存储","url":"/2018/06/08/CS/O/%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/","content":"[toc]\n原码&#x2F;反码&#x2F;补码在计算机中，负数以其正值的补码形式表达。补码：正数的补码是其自身，负数的补码是其反码 + 1。为什么要用补码？为方便计算：负数补码与绝对值的补码（或者说原码）之和等于 0。\n数据对齐（CSAPP）如 C、C++ 里有数据对齐的概念。许多计算机系统对基本数据类型的合法地址做出了一些限制，要求某种类型对象的地址必须是某个值 K（通常是 2、4、8）的倍数。这种对齐限制 简化了处理器和内存系统之间接口的设计。而无论对齐与否，都不会影响硬件正常工作，但考虑到比如 double 数据，如果不对齐，那么可能需要两次内存才能读取一个完整的 double（因没有对齐而导致每次取读它的一半）。所以对齐操作的主要考虑是对性能上的影响。\n","categories":["CS"],"tags":["CS"]},{"title":"java-ThreadLocal","url":"/2018/06/07/java/Thread/ThreadLocal/","content":"[toc]\nThreadLocal线程本地变量&#x2F;线程本地存储，是一个关于 创建线程局部变量的类。通常情况下创建的变量是可以被任何一个线程访问并修改的。而使用 ThreadLocal 创建的变量只能 被当前线程访问，其他线程则无法访问和修改。其基本原理是，同一个 ThreadLocal 所包含的对象（如 ThreadLocal&lt; String &gt;就是 String 类型变量），在不同的 Thread 中有不同的副本（实际是不同的实例）。当线程结束时，它所使用的所有 ThreadLocal 相对应的实例副本都可被回收。要注意：\n\n因为每个 Thread 内有自己的实例副本，且该副本只能由当前 Thread 使用。这是也是 ThreadLocal 命名的由来\n每个 Thread 有自己的实例副本，且其它 Thread 不可访问，也就不存在多线程间共享的问题，也即不存在同步问题。\n\n原理ThreadLocal 有一个内部类：ThreadLocalMap，用来维护线程与实例的映射。\nThreadLocal 维护线程与实例的映射作为一个可能的解决方案。既然每个访问 ThreadLocal 变量的线程都有自己的一个“本地”实例副本。一个可能的方案是 ThreadLocal 维护一个 Map，键是 Thread，值是它在该 Thread 内的实例。线程通过该 ThreadLocal 的 get() 方案获取实例时，只需要以线程为键，从 Map 中找出对应的实例即可：\n\n该方案可满足上文提到的每个线程内一个独立备份的要求。每个新线程访问该 ThreadLocal 时，需要向 Map 中添加一个映射，而每个线程结束时，应该清除该映射。这里就有两个问题：\n\n增加线程与减少线程均需要写 Map，故需保证该 Map 线程安全。虽然从ConcurrentHashMap的演进看Java多线程核心技术一文介绍了几种实现线程安全 Map 的方式，但它或多或少都需要锁来保证线程的安全性\n线程结束时，需要保证它所访问的所有 ThreadLocal 中对应的映射均删除，否则可能会引起内存泄漏。（后文会介绍避免内存泄漏的方法）其中锁的问题，是 JDK 未采用该方案的一个原因。\n\nThread 维护 ThreadLocal 与实例的映射实际的解决方案。上一个方案中，出现锁的问题，原因在于多线程访问同一个 Map。转而，如果该 Map 由 Thread 维护，从而使得每个 Thread 只访问自己的 Map，那就不存在多线程写的问题，也就不需要锁：\n\n该方案虽然没有锁的问题，但由于每个线程访问某 ThreadLocal 变量后，都会在自己的 Map 内维护该 ThreadLocal 变量与具体实例的映射，如果不删除这些引用（映射），则这些 ThreadLocal 不能被回收，可能会造成内存泄漏。该方案中的 Map 由 ThreadLocal 类的静态内部类 ThreadLocalMap 提供。该类的实例维护某个 ThreadLocal 与具体实例的映射。与 HashMap 不同的是，ThreadLocalMap 的每个 Entry 都是一个对键的弱引用。另外，每个 Entry 都包含了一个对值的强引用：\nstatic class Entry extends WeakReference&lt;ThreadLocal&lt;?>> &#123;\n    /** The value associated with this ThreadLocal. */\n    Object value;\n\n    Entry(ThreadLocal&lt;?> k, Object v) &#123;\n        super(k);\n        value = v;\n    &#125;\n&#125;\n使用弱引用的原因在于，当没有强引用指向 ThreadLocal 变量时，它可被回收，从而避免上文所述 ThreadLocal 不能被回收而造成的内存泄漏的问题。但是，这里又可能出现另外一种内存泄漏的问题。ThreadLocalMap 维护 ThreadLocal 变量与具体实例的映射，当 ThreadLocal 变量被回收后，该映射的键变为 null，该 Entry 无法被移除。从而使得实例被该 Entry 引用而无法被回收造成内存泄漏。_Entry 虽然是弱引用，但它是 ThreadLocal 类型的弱引用（也即上述它是对键的弱引用），而非具体实例的的弱引用，所以无法避免具体实例相关的内存泄漏_。\n方法get()读取实例时，线程首先通过 getMap(t) 方法获取自身的 ThreadLocalMap。从如下该方法的定义可见，该 ThreadLocalMap 的实例是 Thread 类的一个字段，即由 Thread 维护 ThreadLocal 对象与具体实例的映射：\npublic T get() &#123;\n    Thread t = Thread.currentThread();\n    ThreadLocalMap map = getMap(t);\n    if (map != null) &#123;\n        ThreadLocalMap.Entry e = map.getEntry(this);\n        if (e != null) &#123;\n            @SuppressWarnings(\"unchecked\")\n            T result = (T)e.value;\n            return result;\n        &#125;\n    &#125;\n    return setInitialValue();\n&#125;\n\nThreadLocalMap getMap(Thread t) &#123;\n  return t.threadLocals;\n&#125;\n获取到 ThreadLocalMap 后，通过 map.getEntry(this) 方法获取该 ThreadLocal 在当前线程的 ThreadLocalMap 中对应的 Entry。该方法中的 this 即当前访问的 ThreadLocal 对象。如果获取到的 Entry 不为 null，从 Entry 中取出值即为所需访问的本线程对应的实例。如果获取到的 Entry 为 null，则通过 setInitialValue() 法设置该 ThreadLocal 变量在该线程中对应的具体实例的初始值。\nsetInitialValue()该方法为 private 方法，无法被重载。首先，通过 initialValue() 获取初始值。该方法为 public 方法，且默认返回 null。所以典型用法中常常重载该方法。上例中即在内部匿名类中将其重载。然后拿到该线程对应的 ThreadLocalMap 对象，若该对象不为 null，则直接将该 ThreadLocal 对象与对应实例初始值的映射添加进该线程的  ThreadLocalMap 中。若为 null，则先创建该 ThreadLocalMap 对象再将映射添加其中。这里并不需要考虑 ThreadLocalMap 的线程安全问题。因为每个线程有且只有一个 ThreadLocalMap 对象，并且只有该线程自己可以访问它，其它线程不会访问该 ThreadLocalMap，也即该对象不会在多个线程中共享，也就不存在线程安全的问题。\nprivate T setInitialValue() &#123;\n    T value = initialValue();\n    Thread t = Thread.currentThread();\n    ThreadLocalMap map = getMap(t);\n    if (map != null)\n        map.set(this, value);\n    else\n        createMap(t, value);\n    return value;\n&#125;\n\nset()该方法先获取该线程的 ThreadLocalMap 对象，然后直接将 ThreadLocal 对象（即代码中的 this）与目标实例的映射添加进 ThreadLocalMap 中。当然，如果映射已经存在，就直接覆盖。另外，如果获取到的 ThreadLocalMap 为 null，则先创建该 ThreadLocalMap 对象。\npublic void set(T value) &#123;\n    Thread t = Thread.currentThread();\n    ThreadLocalMap map = getMap(t);\n    if (map != null)\n        map.set(this, value);\n    else\n        createMap(t, value);\n&#125;\n\n适用场景根据以上对 ThreadLocal 的描述可见，其适用于：\n\n每个线程需要有自己单独的实例；\n实例需要在多个方法中共享，但不希望被多线程共享；\n承载一些线程相关的数据，避免在方法中来回传递参数。\n\n最常见的使用场景为 用来解决 数据库连接、Session管理等。\n内存泄漏问题ThreadLocal 并不会产生内存泄露，因为 ThreadLocalMap在 选择 key 的时候，并不是直接选择 ThreadLocal 实例，而是 ThreadLocal 实例的弱引用。\n理解ThreadLocal理解Java中的ThreadLocal\n","categories":["java"],"tags":["java","线程","并发"]},{"title":"java-volatile","url":"/2018/06/07/java/Thread/volatile/","content":"[toc]线程安全的实现方式之一。\nvolatile见 java 内存模型\nsynchronized vs volatile\nvolatile 是线程同步的轻量级实现，所以 volatile 性能比 synchronized 要好，并且 volatile 只能用于修饰变量，而 synchronized 可以修饰方法、代码块。目前 synchronized 在执行效率上提升明显，使用频率在增大；\n多线程访问 volatile 不会发生阻塞，而 synchronized 会发生阻塞；\nvolatile 能保证数据的可见性，但不保证原子性；synchronized 可以保证原子性，也可以间接保证可见性，因为它会将私有内存和公共内存中的数据做同步；\nvolatile 解决的是变量在多个线程之间的可见性，synchronized 解决的是多个线程之间访问资源的同步性。\n\n","categories":["java"],"tags":["java","并发"]},{"title":"java-JUCL","url":"/2018/06/07/java/Thread/JUCL/","content":"[toc]java.util.concurrent.locks，和线程安全相关的包。该包内的类&#x2F;接口大多都实现了 Serializable 接口，以下图示略去。\nLock 接口\n\n最初的 JDK 只支持 synchronized 关键字提供的锁同步。后续到 JDK1.5 加入了 JUCL（java.utils.concurrent.locks）包，提供了可重入锁（ReentrantLock）、读写锁（ReadWriteLock）、信号量、Condition 等。都是基于一个 基本的等待队列抽象完成的，JDK 文档中将这个抽象队列框架称为 AQS 同步框架。Lock 比传统线程模型中的 synchronized 方式更加 OO，锁本身也是对象。两个线程执行的代码片段要实现同步互斥的效果，它们必须用同一个 Lock 对象。\n接口实现接口完全用 java 写成，在 java 语言层面是无关 JVM 的。提供了一种无条件的、可轮询的、定时的、可中断的锁获取操作，所有加锁和解锁的方法都是显式的。其实现提供与内部锁相同的行为和内存可见性语义，但在加锁语义、调度算法、顺序保证、性能特性等方面可以有所不同。接口方法：\n\n\n显式锁 ReentrantLock加锁和解锁都是显式实现的，乐观锁机制。实现了 Lock 接口，并提供了与 synchronized 相同的 互斥性、内存可见性、可重入的加锁语义。而 ReentrantLock 的锁功能是由其成员变量 Sync 类型的 sync 实现的。Sync 继承了 AQS（AbstractQueuedSynchronizer）。从图中可以看出，Sync 在 ReentrantLock 中有两种实现类：NonfairSync、FairSync，对应非公平锁、公平锁两大类型。\n公平锁与非公平锁ReentrantLock 提供了两种锁的构造方法：创建非公平锁（默认）和公平锁：\npublic ReentrantLock() &#123;\n    sync = new NonfairSync();\n&#125;\npublic ReentrantLock(boolean fair) &#123;\n    sync = fair ? new FairSync() : new NonfairSync();\n&#125;\n在公平锁上，线程按照它们发出请求的顺序获取锁；而在非公平锁上，允许线程请求插队：当一个线程请求非公平锁时，如果在发出请求的同时该锁变为可用状态，那么这个线程可以马上获得这个锁（跳过队列中所有等待线程）。非公平锁不提倡插队行为，但无法（不主动）防止某个线程在某个适合的时机进行插队。i.e. 公平锁中，如果锁被某一线程占有，那么所有后续请求该锁的线程都将按到达顺序排队；非公平锁中，如果请求该锁的线程到达的同时该锁恰好被另一线程释放，那么请求线程无需等待而直接获得锁，否则，即当前该锁处于被占有状态时，请求线程同样进入等待队列。\n非公平锁性能更好因为 在恢复一个被挂起的线程与该线程真正运行之间存在着严重的延迟。显然，非公平锁没有选择（如果此时恰好有一个线程请求了该锁）在前一个线程释放锁后去恢复一个等待该锁的线程，而是将锁直接分配给请求线程，这样就避免了该延迟：假设线程 A 有一个锁，并且线程 B 请求这个锁（被挂起），当 A 释放锁时，B 将被唤醒，因此 B 将再次尝试获取该锁。与此同时，如果 线程 C 也请求这个锁，那么 C 很可能会在 B 被完全唤醒之前获得、使用以及释放该锁。这是一种双赢的局面，B 并没有因为 C 的插队而延迟（B 在唤醒过程中，C 就已经完成了对该锁的操作），C 也在快速地获取锁并执行了自己的操作，吞吐量也随之提高。当持有锁的时间相对较长或者请求锁的平均时间间隔较长，应该使用公平锁：这些情况下，插队带来的吞吐量提升可能不会出现。\n局限性如果没有使用 finally 来释放 try-catch 块中的 Lock，将很难追踪到最初发生错误的位置，因为没有记录应该释放锁的位置和时间。这就是 ReentrantLock 不能完全替代 synchronized 的原因：它更加危险，在程序的执行控制离开被保护的代码块时，不会自动清除锁——finally 是解决办法，但可能被忘记。在使用某种形式的加锁时，都要考虑出现异常时的情况。\nReadWriteLock 接口\n\n读写锁 ReentrantReadWriteLock读写分离思想。维护了一对锁，分为读锁和写锁，多个读锁不互斥，读锁和写锁互斥，由 JVM 控制实现，语言层面无需考虑。可见，ReentrantReadWriteLock 也是通过 Sync 同步器类来实现锁机制的，且同样有公平&#x2F;非公平之分。内部有 ReadLock、WriteLock 两个类，对应读锁、写锁。\n读锁如果确定一段临界值代码段只有读操作，那么可以上读锁：可以并发读，但不能写。线程进入读锁的条件：\n\n没有其他线程的写锁；\n没有写请求 | 有写请求，但调用线程和持有锁的线程是同一个。\n\n读锁可重入的情况是：读线程在获得读锁后，可以再次获得读锁，但不可以获得写锁。读锁不可升级为写锁，因为获得读锁后不释放前，无法再获取写锁。\n写锁如果临界区有写操作，需要上写锁。写锁是排他锁，只能单线程访问。进入写锁的条件：\n\n没有其他线程的读锁（如果有读锁正在访问，则无法进入）；\n没有其他线程的写锁。\n\n写锁也是可重入锁：写线程在获得写锁或，可以再次获得写锁和读锁。写锁可以降级为读锁：先获取写锁，再获取读锁，随后释放写锁，此时为读锁。\nvs\n重入性方面见上；\nReadLock 可以被多个线程持有并且在作用时排斥任何的 WriteLock，而 WriteLock 则是完全的互斥。这一特性最为重要（也是实现它的缘由）：对于高读取频率而相对较低写入的数据结构，使用此类锁同步机制则可以提高并发量；\n不管是 ReadLock 还是 WriteLock 都支持 Interrupt，语义与 ReentrantLock 一致。 \nWriteLock 支持 Condition 并且与 ReentrantLock 语义一致，而 ReadLock 则不能使用 Condition，否则抛出 UnsupportedOperationException。\n\nCondition 接口\nLock 可以很好地解决线程同步问题，但线程间不仅仅有互斥，还有通信问题，而 JUCL 包中的 Condition 接口，就是用来处理线程间通信问题的。很大程度上，Condition 能够解决 Object 监视器方法（wait&#x2F;notify&#x2F;notifyAll）难以使用的问题。即，Condition 是多线程间协调通信的工具类。条件（也称为条件队列或条件变量）为线程提供了一个含义，以便在某个状态条件现在可能为 true 的另一个线程通知它之前，一直挂起该线程（即让其“等待”）。因为访问此共享状态信息发生在不同的线程中，所以它必须受保护，因此要将某种形式的锁与该条件相关联。等待提供一个条件的主要属性是：以原子方式释放相关的锁，并挂起当前线程，就像 Object.wait 做的那样。\n\n这些接口方法中，\n\nawait* 对应于 Object.wait()；\nsignal() 对应于 Object.notify()；\nsignalAll() 对应于 Object.notifyAll()。\n\n每个 Lock 可以有任意数量的 Condition 对象，Condition 是与 Lock 绑定的，所以就有 Lock 的公平性特性：如果是公平锁，线程为按照 FIFO 的顺序从 Condition.await 中释放，如果是非公平锁，那么后续的锁竞争就不保证 FIFO 顺序。\n","categories":["java"],"tags":["java","并发"]},{"title":"Queue-线程安全","url":"/2018/06/06/java/Container/Queue-%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8/","content":"[toc]这里介绍 Queue 容器中实现了同步方法的 LinkedBlockingQueue、ConcurrentLinkedQueue、LinkedBlockingDeque、ConcurrentLinkedDeque\nLinkedBlockingQueue &amp; ConcurrentLinkedQueue二者都是线程安全的队列实现。从命名可知，前者是使用锁（ReentrantLock）实现的阻塞队列（BlockingQueue），会遇到锁本身的所有可能的问题：死锁、阻塞等（名称由来），而后者是采用 CAS 实现的线程安全，不存在阻塞情况。\nLinkedBlockingQueuepublic class LinkedBlockingDeque&lt;E>\n    extends AbstractQueue&lt;E>\n    implements BlockingDeque&lt;E>, java.io.Serializable &#123;&#125;\n\nConcurrentLinkedQueue 并发队列public class ConcurrentLinkedQueue&lt;E> extends AbstractQueue&lt;E>\n        implements Queue&lt;E>, java.io.Serializable &#123;&#125;\n\n对比\n对于 LinkedBlockingQueue，take 方法虽然在内部实现了加锁 wait()，但是由于其他的开销，导致性能相比于 poll + wait() 有所下降。但是如果采用 poll 方法，那么由于大量的线程存在空转的情况，导致争用处理机，导致性能急剧下降。\n对于 ConcurrentLinkedQueue，由于内部采用 CAS 保证并发安全，在采用 poll + wait() 时相比前者有所提升，但是不是很明显，但是对于 poll 方式，由于去除了锁的开销，同时虽然相比于其自身的 poll + wait() 方式性能下降不少，但是相对于 LinkedBlockingQueue，性能提升相当明显。\n\nLinkedBlockingDeque &amp; ConcurrentLinkedDeque线程安全的双向队列，具体情况类似上面的两个。\n阻塞队列BlockingQueue，使用锁机制实现（ReentrantLock），支持两个附加操作的队列：\n\n队列空时，获取元素的线程会等待队列变为非空；\n队列满时，存储元素的线程会等待队列可用。\n\n\n\n抛出异常：当阻塞队列满时，尝试继续往队列里插入元素，会抛出 IllegalStateException(Queue full)异常。当队列为空时，尝试继续从队列里获取元素时会抛出 NoSuchElementException 异常；\n返回特殊值：插入方法会返回是否成功，成功则返回 true。移除方法则是从队列里拿出一个元素，如果没有则返回 null；\n一直阻塞：当阻塞队列满时，如果生产者线程往队列里 put 元素，队列会一直阻塞生产者线程，直到拿到数据，或者响应中断退出。当队列空时，消费者线程试图从队列里 take 元素，队列也会阻塞消费者线程，直到队列可用；\n超时退出：当阻塞队列满时，队列会阻塞生产者线程一段时间，如果超过一定的时间，生产者线程就会退出。\n\n\n阻塞队列常用于生产者和消费者的场景。\n阻塞队列实现截至 JDK1.8，包括上面的两个（LinkedBlockingQueue 和 LinkedBlockingDeque）阻塞队列实现，共有以下 7 个阻塞队列实现。\nArrayBlockingQueue用数组实现的有界阻塞队列。此队列按照先进先出（FIFO）的原则对元素进行排序。默认情况下不保证访问者公平的访问队列，所谓公平访问队列是指阻塞的所有生产者线程或消费者线程，当队列可用时，可以按照阻塞的先后顺序访问队列，即先阻塞的生产者线程，可以先往队列里插入元素，先阻塞的消费者线程，可以先从队列里获取元素。通常情况下为了保证公平性会降低吞吐量。可通过以下方式创建公平的阻塞队列（第二个参数 fair &#x3D; true 即表明创建为公平队列）：\nArrayBlockingQueue&lt;Object> arrayBlockingQueue = new ArrayBlockingQueue&lt;>(100, true);\n\nLinkedBlockingQueue用链表实现的有界阻塞队列。此队列按照先进先出的原则对元素进行排序。\nLinkedBlockingDeque由链表结构组成的双向阻塞队列。双端队列因为多了一个操作队列的入口，在多线程同时入队时，也就减少了一半的竞争。相比其他的阻塞队列，LinkedBlockingDeque 多出了双向队列的操作方法，在初始化 LinkedBlockingDeque 时可以设置容量防止其过渡膨胀。另外双向阻塞队列可以运用在“工作窃取”模式中。\nPriorityBlockingQueue支持优先级的无界阻塞队列。默认情况下元素采取自然顺序排列，也可以通过比较器 comparator 来指定元素的排序规则。\nDelayQueue使用优先级队列实现的、支持延时获取元素的无界阻塞队列。队列使用 PriorityQueue 来实现。队列中的元素必须实现 Delayed 接口，在创建元素时可以指定多久才能从队列中获取当前元素，只有在延迟期满时才能从队列中提取元素。必须实现 compareTo来 指定元素的顺序。应用场景：\n\n缓存系统的设计：可以用 DelayQueue 保存缓存元素的有效期，使用一个线程循环查询 DelayQueue，一旦能从 DelayQueue 中获取元素时，表示缓存有效期到了；\n定时任务调度。使用 DelayQueue 保存当天将会执行的任务和执行时间，一旦从 DelayQueue 中获取到任务就开始执行，如TimerQueue 就是使用 DelayQueue 实现的。\n\nSynchronousQueue不存储元素的阻塞队列。每一个 put 操作必须等待一个 take 操作，否则不能继续添加元素。可以看成是一个传球手，负责把生产者线程处理的数据直接传递给消费者线程。队列本身并不存储任何元素，非常适合于传递性场景，比如在一个线程中使用的数据，传递给另外一个线程使用，吞吐量高于 LinkedBlockingQueue 和 ArrayBlockingQueue。\nLinkedTransferQueue由链表结构组成的无界阻塞 TransferQueue 队列。相对于其他阻塞队列，多了 tryTransfer 和 transfer 方法：\n\ntransfer方法：如果当前有消费者正在等待接收元素（消费者使用 take 方法或带时间限制的 poll 方法时），transfer 方法可以把生产者传入的元素立刻 transfer（传输）给消费者。如果没有消费者在等待接收元素，transfer 方法会将元素存放在队列的 tail 节点，并等到该元素被消费者消费了才返回。transfer 方法的关键代码如下：// 试图把存放当前元素的 s 节点作为 tail 节点：\nNode pred = tryAppend(s, haveData);\n\n// 让 CPU 自旋等待消费者消费元素。因为自旋会消耗 CPU，\n// 所以自旋一定的次数后使用 Thread.yield() 来暂停当前正在执行的线程，并执行其他线程：\nreturn awaitMatch(s, pred, e, (how == TIMED), nanos);\ntryTransfer方法：试探下生产者传入的元素是否能直接传给消费者。如果没有消费者等待接收元素，则返回 false。和 transfer方法的区别是 tryTransfer 方法无论消费者是否接收，方法都立即返回。而 transfer 方法是必须等到消费者消费了才返回。对于带有时间限制的 tryTransfer(E e, long timeout, TimeUnit unit) 方法，则是试图把生产者传入的元素直接传给消费者，但是如果没有消费者消费该元素则等待指定的时间再返回，如果超时还没消费元素，则返回 false，如果在超时时间内消费了元素，则返回 true。\n\n阻塞队列\n","categories":["java"],"tags":["java","容器"]},{"title":"Queue","url":"/2018/06/06/java/Container/Queue/","content":"[toc]\nQueue 接口 &amp; Deque 接口Queue 接口，提供队列操作的典型方法：\npublic interface Queue&lt;E> extends Collection&lt;E> &#123;\n    boolean add(E e);\n    boolean offer(E e);\n    E remove();\n    E poll();\n    E element();\n    E peek(); &#125;\n\nDeque 接口，提供双向队列操作的典型方法（去除和 Queue 重合的部分）：\npublic interface Deque&lt;E> extends Queue&lt;E> &#123;\n    void addFirst(E e);\n    void addLast(E e);\n    boolean offerFirst(E e);\n    boolean offerLast(E e);\n    E removeFirst();\n    E removeLast();\n    E pollFirst();\n    E pollLast();\n    E getFirst();\n    E getLast();\n    E peekFirst();\n    E peekLast();\n    boolean removeFirstOccurrence(Object o);\n    boolean removeLastOccurrence(Object o);\n    boolean contains(Object o);\n    int size();\n    Iterator&lt;E> iterator();\n    Iterator&lt;E> descendingIterator(); &#125;\n\n这里介绍 Queue 容器中没有同步方法的实现：ArrayDeque、PriorityQueue、LinkedList。\nArrayDequepublic class ArrayDeque&lt;E> extends AbstractCollection&lt;E>\n    implements Deque&lt;E>, Cloneable, Serializable &#123;\n        transient Object[] elements;\n    &#125;\n从命名可知，底层是使用数组实现的。ArrayDeque 和LinkedList 是 Deque 的两个通用实现，官方更推荐使用 AarryDeque 用作栈和队列。ArrayDeque 使用循环数组实现：\n\n\n\nPriorityQueuepublic class PriorityQueue&lt;E> extends AbstractQueue&lt;E>\n    implements java.io.Serializable &#123;\n        transient Object[] queue; \n    ... &#125;\n优先队列，不允许 null，对象必须实现了 Comparator 接口，即可比较的，排序方式为自然排序（默认）或用户指定的 Comparator 排序方法实现，可以指定初始大小（Object 数组）。\n堆排PriorityQueue 通过数组表示的二叉小顶堆实现排序，可以用一棵完全二叉树表示，父节点和子节点的编号是有联系的：leftNo &#x3D; parentNo2+1rightNo &#x3D; parentNo2+2parentNo &#x3D; (nodeNo-1)&#x2F;2通过上浮、下沉（参见 Algs4: Priority Queues中的堆排序实现），维持二叉堆的有序性。\n扩容既然底层是使用数组实现的，那么就存在容量耗尽的情况，此时的扩容策略和一般的实现无异：先申请新数组，再拷贝旧数据，完成新数组指向。\nLinkedList除 Deque，它也实现了 List 接口，在此不再重复。\n","categories":["java"],"tags":["java","容器"]},{"title":"Set-线程安全","url":"/2018/06/06/java/Container/Set-%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8/","content":"[toc]这里介绍 Set 容器中实现了同步方法的 CopyOnWriteArraySet、ConcurrentSkipListSet。\nCopyOnWriteArraySetpublic class CopyOnWriteArraySet&lt;E> extends AbstractSet&lt;E>\n        implements java.io.Serializable &#123;\n            private final CopyOnWriteArrayList&lt;E> al;\n    ... &#125;\n看到这个内部 CopyOnWriteArrayList，显然，它的底层数据结构使用了基于 COW 技术的 ArrayList。不再展开。\nConcurrentSkipListSetpublic class ConcurrentSkipListSet&lt;E> extends AbstractSet&lt;E>\n    implements NavigableSet&lt;E>, Cloneable, java.io.Serializable &#123;\n        private final ConcurrentNavigableMap&lt;E,Object> m;\n    ... &#125;\n显然，底层是一个 ConcurrentSkipListMap，跳表 + CAS，提供简洁高效的线程安全实现。\n","categories":["java"],"tags":["java","容器"]},{"title":"Set","url":"/2018/06/06/java/Container/Set/","content":"[toc]\nSet 接口这里介绍 Set 容器中没有同步方法的实现：HashSet、LinkedHashSet、TreeSet\nHashSetpublic class HashSet&lt;E> extends AbstractSet&lt;E>\n    implements Set&lt;E>, Cloneable, java.io.Serializable &#123;\n        private transient HashMap&lt;E,Object> map;\n        ... &#125;\n从源码可见，HashSet 是基于 HashMap 实现的，即其底层是一个 HashMap，HashSet 在执行构造方法时就会初始化一个 HashMap，用以保存元素。这使得 HashSet 的实现变得非常简单，很多方法的实现只需要借助 HashMap 的相应方法加以修改即可。\nLinkedHashSetpublic class LinkedHashSet&lt;E> extends HashSet&lt;E>\n    implements Set&lt;E>, Cloneable, java.io.Serializable &#123;&#125;\n继承自 HashSet，基于 HashMap 和 双向链表实现，其内部使用一个 LinkedHashMap，额外提供重要的功能就是有序遍历——按照插入顺序遍历元素。可以类比 HashMap 和 LinkedHashMap。构造方法（该方法定义在 HashSet，供 LinkedHashSet 子类构造方法调用，并设置 dummy 为 true :\nHashSet(int initialCapacity, float loadFactor, boolean dummy) &#123;\n    map = new LinkedHashMap&lt;>(initialCapacity, loadFactor); &#125;\n\nTreeSetpublic class TreeSet&lt;E> extends AbstractSet&lt;E>\n    implements NavigableSet&lt;E>, Cloneable, java.io.Serializable &#123;\n        private transient NavigableMap&lt;E,Object> m;\n    ... &#125;\n即使不看源码，从以上两个 Set 集合的实现，也可以推导出：TreeSet，底层应该是使用了 TreeMap 实现的。事实上也是如此，红黑树的结构在不考虑多线程的情况下表现良好，JDK1.8 中没有对该数据结构实现作修改。\n","categories":["java"],"tags":["java","容器"]},{"title":"java-底层技术","url":"/2018/06/06/java/into/java-%E5%BA%95%E5%B1%82%E6%8A%80%E6%9C%AF/","content":"[toc]一些语言技术实现。\nCOW 优化策略COW（Copy-On-Write，写时复制）是一种用于程序设计中的优化策略：一开始大家都在共享同一个内容，当某个人（线程）想要修改这个内容的时候，才会真正把内容拷贝并形成一个新的内容然后再修改。这是一种延时懒惰策略，主要应用于多并发场景。\nCOW 容器i.e. 写时复制容器。JDK1.5 引入了两个 COW 机制的实现类容器：CopyOnWriteArrayList、CopyOnWriteArraySet。简单理解就是：当需要往容器添加元素时，不直接往当前容器添加，而是将当前容器进行拷贝，复制出一个新的容器，然后将待添加元素加入到新的容器中，添加完成后，再将原容器的引用指向新容器。这样做的好处是，可以 对容器进行并发读而不需要加锁，因为当前容器不会添加容器，也就不会改变。整体上是一种读写分离的思想，读和写在不同的容器进行。\n\n整个 add 操作在锁保护下进行，避免多线程并发造成副本混乱：\npublic boolean add(E e) &#123;\n    synchronized (lock) &#123;\n        Object[] elements = getArray();\n        int len = elements.length;\n        Object[] newElements = Arrays.copyOf(elements, len + 1);\n        newElements[len] = e;\n        setArray(newElements);\n        return true;\n    &#125;\n由于所有的写操作都是在新数组进行，如果有并发写，则通过锁来控制；如果并发读，则：\n\n如果写操作未完成，那么直接读取原数组的数据；\n如果写操作已完成，但引用还未指向新数组，那么也是直接读取原数组的数据；\n如果写操作已完成，并且引用已指向新数组，那么直接读取新数组的数据；可见，读操作可以不加锁。\n\n应用场景适用于 读多写少的并发场景。比如白名单，黑名单，商品类目的访问和更新场景等。\n问题和解决\n内存占用：根据实现原理，当可变操作频繁发生时，会导致效率低下，也会造成内存占用过多的问题。实用场景，根据实际需要，初始化 COW 容器大小，减少扩容开销；使用批量添加，减少容器复制次数。\n数据一致性问题：COW 只能保证数据的最终一致性，不能保证数据的实时一致性。如果希望写入的数据马上能读取到，此时不适合适用 COW 容器。\n\n一些泛型数据结构。\n跳表（SkipList）从红黑树到跳表目前常用的 key-value 数据结构有三种：Hash 表、红黑树、SkipList。各自优缺点（不考虑删除操作）：\n\nHash表：插入、查找最快，为 O(1)；如使用链表实现则可实现无锁；数据有序化需要显式的排序操作。\n红黑树：插入、查找为 O(logn)，但常数项较小；无锁实现的复杂性很高，一般需要加锁；数据天然有序。\nSkipList：插入、查找为 O(logn)，但常数项比红黑树要大；底层结构为链表，可无锁实现（CAS）；数据天然有序。\n\n如果要实现一个 key-value 结构，需求的功能有插入、查找、迭代、修改，那么首先 Hash 表就不是很适合了：因为迭代的时间复杂度比较高；而红黑树的插入很可能会涉及多个结点的旋转、变色操作，因此需要在外层加锁，这无形中降低了它可能的并发度；而 SkipList 底层是用链表实现的，可以实现为 lock free，同时它还有着不错的性能（单线程下只比红黑树略慢），非常适合用来实现 key-value 结构。\nJDK 中提供的基于红黑树的 TreeMap 保证内部元素有序，但非线程安全的，而且红黑树的实现中维持二叉树的平衡是个非常复杂的实现，并且（如果实现并发安全的话）并发环境下保持平衡的操作会使性能受到一定影响。跳表（SkipList）是一种随机化的数据结构，是一种 空间换取时间 的算法：建立多级索引，以（近似）二分查找的方式遍历一个有序链表。\n跳表所实现的功能和红黑树类似。基于排序的索引结构，其效率和红黑树相近，但实现难度和编程难度更简单，且在并发环境下表现良好（这也是选择它作为一些容器类的线程安全版本底层数据结构的原因）。相应地，以空间换时间本就意味着空间效率的降低，这种折中在数据结构实现中经常遇到。性质：\n\n由很多层结构组成\n每一层都是一个有序的链表\n底层(Level 1)的链表包含所有元素\n如果一个元素出现在 Level i 的链表中，则它在 Level i 之下的链表也都会出现。\n每个节点包含两个指针，一个指向同一链表中的下一个元素，一个指向下面一层的元素。\n\n数据结构首先，从命名可见它是基于链表的数据结构，其次它又是一种多层次的链表结构。使用概率均衡技术（而不是强制性均衡），使得增&#x2F;删操作比传统平衡树更为简洁高效。\n\n\n如图，类比传统链表的操作时间复杂度，跳表（一层）可以将查询降低到 O(n&#x2F;2)——查询种会跳过部分节点，而 通过随机函数生成链表内每个节点包含多少个指向后续元素的指针 的方式（含有概率事件的意味），构造出多层次链表结构，从而理论上降低至二叉查找级别：\n\n\n操作查找以下为查找 19 的过程。\n\n\n插入执行以下步骤：\n\n通过查找定位到需要插入的位置；\n申请新的节点；\n调整指针。以插入 17 为例：\n\n删除类似于插入：\n\n通过查找定位到需要删除的节点；\n删除节点；\n调整指针。\n\n实现原理实现原理\nCAS几乎所有现代处理器都包含了某种形式的原子读-改-写的特殊指令，如 CAS、关联加载&#x2F;条件存储（Load-Linked&#x2F;Store-Conditional），可以自动更新共享数据，而且能够检测到其他线程的干扰。Compare and Swap：比较并交换，就是借助了 CPU 的这些特殊指令实现的，是 java.util.concurrent（JUC）包中实现的区别于 synchronized 同步锁的一种乐观锁，非阻塞算法（一个线程的失败或挂起不应该影响其他线程的失败或挂起）。CAS 有 3 个操作数，内存值 V，旧的预期值 A，要修改的新值 B。当且仅当预期值 A 和内存值 V 相同时，将内存值 V 修改为 B，否则什么都不做：首先读取内存位置 V 的值 A，计算是否符合修改条件，是，则以原子方式将 V 中的值由 A 变成 B，期间会检测是否有其他线程干扰（修改 V 值），有干扰则进入失败重试阶段；否，则不进行任何操作，并返回 V 中的值。程序内部执行 CAS 并不需要执行 JVM 代码、系统调用或线程调度操作。而 CAS 的缺点主要是：它将使调用者处理竞争问题（重试、回退、放弃等），而在锁中竞争问题是自动处理的（不需要应用开发者再处理）：线程在获得锁之前一直阻塞。java 的 CAS 同时具有 volatile 的读和写的内存语义。\nJNI 调用 和 CPU 锁java 中，CAS 通过调用 JNI（Java Native Interface，java 本地调用，允许 java 调用其他语言）代码实现。一般借助 C 来调用 CPU 底层指令实现。这属于硬件实现细节，涉及到 CPU 硬件设计中的锁概念。CPU 有 3 种类型的锁：\n\n自动保证基本内存操作的原子性首先处理器会自动保证基本的内存操作的原子性。处理器保证从系统内存当中读取或者写入一个字节是原子的，意思是当一个处理器读取一个字节时，其他处理器不能访问这个字节的内存地址。处理器能自动保证单处理器对同一个缓存行里进行 16&#x2F;32&#x2F;64 位的操作是原子的，但是复杂的内存操作处理器不能自动保证其原子性，比如跨总线宽度，跨多个缓存行，跨页表的访问。但是处理器提供总线锁定和缓存锁定两个机制来保证复杂内存操作的原子性：\n总线锁保证原子性第一个机制是通过总线锁保证原子性。如果多个处理器同时对共享变量进行读改写（i++就是经典的读改写操作）操作，那么共享变量就会被多个处理器同时进行操作，这样读改写操作就不是原子的，操作完之后共享变量的值会和期望的不一致，举个例子：如果i&#x3D;1,我们进行两次i++操作，我们期望的结果是3，但是有可能结果是2。如下图：\n原因是有可能多个处理器同时从各自的缓存中读取变量 i，分别进行加一操作，然后分别写入系统内存当中。那么想要保证读改写共享变量的操作是原子的，就必须保证 CPU1 读改写共享变量的时候，CPU2 不能操作缓存了该共享变量内存地址的缓存。处理器使用总线锁就是来解决这个问题的。所谓总线锁就是使用处理器提供的一个 LOCK＃ 信号，当一个处理器在总线上输出此信号时，其他处理器的请求将被阻塞住，那么该处理器可以独占使用共享内存。\n缓存锁保证原子性第二个机制是通过缓存锁定保证原子性。在同一时刻我们只需保证对某个内存地址的操作是原子性即可，但总线锁定把 CPU 和内存之间通信锁住了，这使得锁定期间，其他处理器不能操作其他内存地址的数据，所以总线锁定的开销比较大，最近的处理器在某些场合下使用缓存锁定代替总线锁定来进行优化。频繁使用的内存会缓存在处理器的 L1、L2 和 L3 高速缓存里，那么原子操作就可以直接在处理器内部缓存中进行，并不需要声明总线锁，在奔腾6和最近的处理器中可以使用“缓存锁定”的方式来实现复杂的原子性。所谓“缓存锁定”就是如果缓存在处理器缓存行中内存区域在LOCK操作期间被锁定，当它执行锁操作回写内存时，处理器不在总线上声言 LOCK＃ 信号，而是修改内部的内存地址，并允许它的缓存一致性机制来保证操作的原子性，因为缓存一致性机制会阻止同时修改被两个以上处理器缓存的内存区域数据，当其他处理器回写已被锁定的缓存行的数据时会起缓存行无效，在例1中，当 CPU1 修改缓存行中的i时使用缓存锁定，那么 CPU2 就不能同时缓存了 i 的缓存行。但是有两种情况下处理器不会使用缓存锁定:\n\n当操作的数据不能被缓存在处理器内部，或操作的数据跨多个缓存行（cache line），此时处理器会调用总线锁定；\n有些处理器不支持缓存锁定。对于 Intel486 和奔腾处理器，就算锁定的内存区域在处理器的缓存行中也会调用总线锁定。\n\n\n\n\nCAS 缺陷CAS 虽然很高效地实现了原子操作，但是 CAS 仍然存在 3 个问题：\n\nABA问题。因为 CAS 需要在操作值的时候检查下值有没有发生变化，如果没有发生变化则更新，但是如果一个值原来是 A，变成了 B，又变成了 A，那么使用 CAS 进行检查时会发现它的值没有发生变化，但是实际上却变化了。ABA 问题的解决思路就是使用版本号。在变量前面追加上版本号，每次变量更新的时候把版本号 +1，那么 A-B-A 就会变成 1A-2B-3A。从 Java1.5 开始 JDK 的 atomic 包里提供了一个类 AtomicStampedReference 来解决 ABA 问题。这个类的 compareAndSet 方法作用是首先检查当前引用是否等于预期引用，并且当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更新值；\n循环时间长、开销大。自旋 CAS 如果长时间不成功，会给 CPU 带来非常大的执行开销。如果 JVM 能支持处理器提供的 pause 指令那么效率会有一定的提升，pause 指令有两个作用，第一它可以延迟流水线执行指令（de-pipeline）,使 CPU 不会消耗过多的执行资源，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零。第二它可以避免在退出循环的时候因内存顺序冲突（memory order violation）而引起 CPU 流水线被清空（CPU pipeline flush），从而提高 CPU 的执行效率；\n只能保证一个共享变量的原子操作。当对一个共享变量执行操作时，我们可以使用循环 CAS 的方式来保证原子操作，但是对多个共享变量操作时，循环 CAS 就无法保证操作的原子性，这个时候就可以用锁，或者有一个取巧的办法，就是把多个共享变量合并成一个共享变量来操作。比如有两个共享变量 i＝2,j&#x3D;a，合并一下 ij&#x3D;2a，然后用 CAS 来操作 ij。从 Java1.5 开始 JDK 提供了 AtomicReference 类来保证引用对象之间的原子性，可以把多个变量放在一个对象里来进行 CAS 操作。\n\nCAS 分析\nAQSAQS：AbstractQueuedSynchronizer，抽象队列同步器，定义了一套多线程访问共享资源的同步器框架。\n\n它维护了一个 volatile int state（代表共享资源，用来维护同步状态）和一个 FIFO 线程等待队列（多线程争用资源被阻塞时会进入此队列）。state 的访问方式有三种:\n\ngetState()\nsetState()\ncompareAndSetState()\n\nAQS 定义两种资源共享方式：Exclusive（独占，只有一个线程能执行，如 ReentrantLock）和 Share（共享，多个线程可同时执行，如 Semaphore&#x2F;CountDownLatch）。通过 state 字段描述有多少线程持有锁和锁的种类，用标志位标示独占锁&#x2F;共享锁以及（如果共享）锁被持有的数量、锁的可重入性以及（如果可重入）重入次数等。不同的自定义同步器争用共享资源的方式也不同。自定义同步器在实现时只需要实现共享资源 state 的获取与释放方式即可，至于具体线程等待队列的维护（如获取资源失败入队&#x2F;唤醒出队等），AQS 已经在顶层实现。基于 AQS 实现的同步器有：ReentrantLock、Semaphore、ReentrantReadWriteLock、CountDownLatch、FutureTask 等。\nAQS\nCLH MCSCLH 锁Craig, Landin, and Hagersten  locks: 一个自旋锁，能确保无饥饿性，提供先来先服务的公平性。基于链表的可扩展、高性能、公平的自旋锁，申请线程只在本地变量上自旋，它不断轮询前驱的状态，如果发现前驱释放了锁就结束自旋。\nMCS 锁MCS Spinlock 是一种基于链表的可扩展、高性能、公平的自旋锁，申请线程只在本地变量上自旋，直接前驱负责通知其结束自旋，从而极大地减少了不必要的处理器缓存同步的次数，降低了总线和内存的开销。\nvs\n从代码实现来看，CLH比MCS要简单得多。\n从自旋的条件来看，CLH是在前驱节点的属性上自旋，而MCS是在本地属性变量上自旋\n从链表队列来看，CLH的队列是隐式的，CLHNode并不实际持有下一个节点；MCS的队列是物理存在的。\nCLH锁释放时只需要改变自己的属性，MCS锁释放则需要改变后继节点的属性。注意：这里实现的锁都是独占的，且不能重入的。\n\n","categories":["java"],"tags":["java"]},{"title":"java-关键字","url":"/2018/06/06/java/into/java-%E5%85%B3%E9%94%AE%E5%AD%97/","content":"[toc]一些关键字概况。\ntransient大多数容器类都实现了 Serializable 接口，这意味着，该类对象实例可以被序列化——只要实现了该接口，该类的所有属性和方法都会自动序列化，而不必关心具体序列化的过程。然而在开发中常常会遇到类似这样的问题：这个类的有些属性字段需要序列化，但有些不需要甚至不应该被序列化，如用户敏感的账号密码银行卡等信息，这些信息并不希望在网络操作&#x2F;本地序列化缓存中传输、保存，此时，使用 transient 关键字修饰，即可使得 字段的生命周期仅存在于调用者的内存中而不会被序列化到磁盘或其他持久化位置中去，即，被序列化的对象不会包含 transient 修饰的字段数据。\n注意事项\n只能修饰变量，而不能修饰方法和类。本地变量也不能被 transient 修饰，如果是用户自定义类变量，则该类需要实现 Serializable 接口；\n一旦变量被 transient 修饰，将不再是对象持久化的一部分。静态变量不管是否被 transient 修饰，均不能被序列化。\n\n被 transient 修饰的变量真的不能被序列化吗？并不是：序列化的实现有两种途径：一是通过 Serializable 接口，此时所有的序列化都是自动进行的，使用 transient 可以排除不想序列化的部分；而另一种方式是实现 Externalizable 接口，此时所有的序列化动作都要在其 writeExternal() 方法中手动指定，即指定想要序列化的内容，这与该内容字段是否被 transient 修饰无关。\n","categories":["java"],"tags":["java"]},{"title":"内存模型","url":"/2018/06/04/java/JVM/JMM/","content":"[toc]内存模型：为了保证共享内存的正确性（可见性、有序性、原子性），内存模型定义了共享内存系统中多线程程序读写操作行为的规范。其解决并发问题主要采用两种方式：限制处理器优化和使用内存屏障。\nJMM 定义了 JVM 在计算机内存中的工作方式，主要涉及到 多线程之间共享变量的可见性以及如何在需要的时候对共享变量进行同步。JVM 是整个计算机虚拟模型，所以 JMM 是隶属于 JVM 的。\n相关问题。高速缓存机制目前，CPU 的运算速度比计算机存储设备有几个数量级的差距，所以现代计算机都有一层（三层）读写速度尽可能接近处理器的高速缓存来作为内存与处理器之间的缓冲：将运算需要使用到的数据复制到缓存中，让运算能快速进行，当运算结束后再从缓存同步回内存之中，这样处理器就无须等待缓慢的内存读写了。基于高速缓存的存储交互很好地解决了处理器与内存之间的矛盾，但也为计算机体系架构设计带来了更高的复杂度，因为引入了一个新的问题：缓存一致性（Cache Coherence）：在多处理器系统中，每个处理器都有自己的高速缓存，而它们又共享同一主存（Main Memory），当多个处理器的运算任务都涉及到同一块主内存区域时，将可能导致各自的缓存数据不一致，此时，同步回主存的数据以谁为准呢？为解决这种不一致，需要各个处理器访问缓存时都遵循一些协议来保证读写操作的正确性。这类协议有 MSI、MESI、MOSI、Synapse、Firefly、Dragon Protocol 等。而 内存模型，即可以理解为在特定的操作协议下，对特定的内存&#x2F;高速缓存进行读写访问的过程抽象。不同架构的物理机器可以有不同的内存模型，jvm 拥有自己的内存模型。\n\n\n重排序问题为使得处理器内部运算单元尽量被充分利用，处理器可能会对输入代码进行乱序执行（Out-of-Order Execution）优化，处理器会在计算之后将乱序执行的结果重组，保证该结果与顺序执行的结果是一致的，但 不保证程序中各个语句计算的先后顺序与输入代码中的顺序一致。因此，如果存在一个计算任务依赖另外一个计算任务的中间结果，那么其顺序性并不能靠代码的先后顺序来保证。与处理器的乱序执行优化类似，jvm 的即时编译器也有类似的指令重排（Instruction Reorder）优化。\njvm 内存模型jvms 定义的 java 内存模型（Java Memory Model，JMM），试图屏蔽掉各种硬件和 OS 的内存访问差异，以实现让 java 程序在各种平台下都能达到一致的内存访问效果。目前已臻至成熟。JMM 规定了所有的变量都存储在主内存（Main Memory）中（此处的主内存与上述物理硬件的主内存名字一样，两者也可以互相类比，但此处仅是 jvm 内存的一部分）。每条线程还有自己的工作内存（Working Memory，可与前面讲的处理器高速缓存类比），线程的工作内存中保存了被该线程使用到的变量的主内存副本拷贝，线程对变量的所有操作（读取、赋值等）都必须在工作内存中进行，而不能直接读写主内存中的变量。不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量值的传递均需要通过主内存来完成。\n\n这里所讲的主内存、工作内存，和 Java 内存区域中的 Java 堆、栈、方法区等并不是同一个层次的内存划分，这两者基本上是没有关系的，如果两者一定要勉强对应起来，那从变量、主内存、工作内存的定义来看，主内存主要对应于 Java 堆中的对象实例数据部分，而工作内存则对应于虚拟机栈中的部分区域。从更低层次上说，主内存就直接对应于物理硬件的内存，而为了获取更好的运行速度，虚拟机（甚至是硬件系统本身的优化措施）可能会让工作内存优先存储于寄存器和高速缓存中，因为程序运行时主要访问读写的是工作内存。\n内存间交互操作JMM 规定了以下 8 种操作，来完成主内存和工作内存之间具体的交互协议——即一个变量如何从主内存拷贝到工作内存、如何从工作内存同步回主内存之类的实现细节：\n\nlock（锁定）：作用于主内存变量，它把一个变量标识为仅能被一条线程独占的状态；\nunlock（解锁）：作用于主内存变量，它把一个处于锁定状态的变量释放出来，释放后的变量可以被其他线程访问&#x2F;锁定；\nread（读取）：作用于主内存的变量，它把一个变量的值从主内存传输到线程的工作内存中，以便后续的 load 操作使用；\nload（载入）：作用于工作内存的变量，它把 read 操作从主内存得到的变量值放入工作内存的变量副本中；\nuse（使用）：作用于工作内存的变量，它把工作内存中一个变量的值传递给执行引擎，每当虚拟机遇到一个需要使用到变量的值的字节码指令时将会执行这个操作；\nassgin（赋值）：作用于工作内存的变量，它把一个从执行引擎接收到的值赋给工作内存的变量，每当虚拟机遇到一个给变量赋值的字节码指令时将会执行这个操作；\nstore（存储）：作用于工作内存的变量，它把工作内存中一个变量的值传回到主内存中，以便后续的 write 操作使用；\nwrite（写入）：作用于主内存变量，它把 store 操作从工作内存中得到的变量的值放入到主内存的变量中。如果要把一个变量从主内存复制到工作内存，那就要顺序地执行 read 和 load 操作，如果要把变量从工作内存同步回主内存，就要顺序地执行 store 和 write 操作。注意，JMM 只要求上述两个操作必须按顺序执行，而没有保证是连续执行。也就是说，read 与 load 之间、store 与 write 之间是可插入其他指令的。\n\n此外，JMM 还规定了在执行上述 8 种基本操作时必须满足如下规则：\n\n不允许 read 和 load、store 和 write 操作之一单独出现，即不允许一个变量从主内存读取了但工作内存不接受，或者从工作内存发起回写了但主内存不接受的情况出现；\n不允许一个线程丢弃它的最近的 assign 操作，即变量在工作内存中改变了之后必须把该变化同步回主内存；\n不允许一个线程无原因地（没有发生过任何 assign 操作）把数据从线程的工作内存同步回主内存中；\n一个新的变量只能在主内存中“诞生”，不允许在工作内存中直接使用一个未被初始化（load 或 assign）的变量。换句话说，就是对一个变量实施 use、store 操作之前，必须先执行过了 assign 和 load 操作。\n一个变量在同一个时刻只允许一条线程对其进行 lock 操作，但 lock 操作可以被同一条线程重复执行多次，多次执行 lock 后，只有执行相同次数的 unlock 操作，变量才会被解锁；\n如果对一个变量执行 lock 操作，那将会清空工作内存中此变量的值，在执行引擎使用这个变量前，需要重新执行 load 或 assign 操作初始化变量的值；\n如果一个变量事先没有被 lock 操作锁定，那就不允许对它执行 unlock 操作，也不允许去 unlock 一个被其他线程锁定住的变量；\n对一个变量执行 unlock 操作之前，必须先把此变量同步回主内存中（执行 store、write 操作）。\n\n8 种内存访问操作和上述规则限定，再加上对 volatile 关键字的一些特殊规定，就已经完全确定了 Java 程序中哪些内存访问操作在并发下是安全的。以上定义严谨但繁琐，其有一个等效判断原则——先行发生原则，也同样能够确定一个访问在并发环境下是否安全。\nvolatile 规则关键字 volatile 可以被认为是 jvm 提供的最轻量级的同步机制。volatile 变量在各个线程的工作内存中不存在一致性问题：在各个线程的工作内存中，volatile 变量也可以存在不一致的情况，但由于每次使用之前都要先刷新，执行引擎看不到不一致的情况，因此可以认为不存在一致性问题。当一个变量被定义为 volatile 后，它具备两个特性：\n\n保证此变量对所有线程的可见性这里的“可见性”是指当一条线程修改了这个变量的值，新值对于其他线程来说是可以立即得知的。（回想普通变量，其值在线程间传递均需要通过主内存来完成，例如，线程 A 修改一个普通变量的值，然后向主内存进行回写，另外一条线程 B 在线程 A 回写完成了之后再从主内存进行读取操作，新变量值才会对线程 B 可见）。但可见性并不意味着线程安全，事实上，volatile 并不是线程安全的，它并不能保证操作符合原子性。所以在一些有依赖的运算中，仍然要通过加锁（使用 synchronized 或 java.util.concurrent 中的原子类）来保证原子性。\n禁止指令重排序优化普通变量仅保证在该方法的执行过程中所有依赖赋值结果的地方都能获取到正确的结果，而不保证变量赋值操作的顺序与程序代码中的执行顺序一致。而在一个线程的方法执行过程中无法感知到这点，这也就是 JMM 描述的所谓“线程内表现为串行的语义”（Within-Thread As-If-Serial Semantics）。从硬件上讲，指令重排不是以指令顺序任意执行，而是 CPU 在正确处理 依赖情况 的前提下，可能会将没有依赖关系的指令（来自于代码汇编的字节码）不按程序中代码顺序分开发送给相应电路单元进行处理，并且保证在后续有对之前的操作结果有依赖的地方能够取到正确的值，这样从最终结果上看依然是像有序执行的结果；而有依赖关系的代码指令之间不能重排。volatile 能够禁止指令的重排优化，通过汇编代码可见，有 volatile 修饰的变量在执行操作后，会多执行一句 “lock addl$0x0，(%esp)”指令（把 ESP 寄存器的值加 0，显然是一个空操作），这相当于一道内存屏障使得指令重排序无法逾越，关键就在于其 lock 前缀，它的作用是使得本 CPU 的 Cache 写入内存，同时该写入动作会引起别的 CPU 或者别的内核无效化（Invalidate）其 Cache，即相当于对 Cache 中的变量做了一次 JMM 中的“store和write”操作。所以通过这样一个空操作，可让 volatile 变量的修改对其他 CPU 立即可见。\n\nvolatile vs 锁显然，volatile 并不等同于安全的锁，它也无法在多线程中保证安全性，但在特定场景下依然能够提供“足够的安全性”且比锁（synchronized 关键字或 java.util.concurrent 包里面的锁）效率更高。但随着 jvm 对锁的各种优化策略的进步——锁消除、锁粗化等，已无法简单定量分析究竟孰优孰劣。而如果让 volatile 自身对比，那可以确定一个原则：volatile 变量读操作的性能消耗与普通变量几乎没有什么差别，但是写操作则可能会慢一些，因为它需要在本地代码中插入许多内存屏障指令来保证处理器不发生乱序执行。不过即便如此，大多数场景下volatile 的总开销仍然要比锁低，我们在 volatile 与锁之中选择的唯一依据应该是 volatile 的语义能否满足使用场景的需求。使用场景（满足以下条件时使用）\n\n对变量的写操作不依赖变量的当前值或其他的变量，或者能确保只有单个线程更新变量值；\n该变量不会与其他状态变量一起纳入不变性条件中；\n在访问变量时不需要加锁。\n\nlong 和 double对于 64 位的数据类型（long 和 double），JMM 规定：允许虚拟机将没有被 volatile 修饰的 64 位数据的读写操作划分为两次 32 位的操作来进行，即允许虚拟机实现不保证 64 位数据类型的 load、store、read、write 这 4 个操作的原子性——但同时强烈建议 jvm 保证其操作的原子性，所以目前多数商用 jvm 都选择把 64 位数据的读写操作作为原子操作对待来实现。\n原子性 可见性 有序性JMM 是围绕在并发过程中如何处理原子性、可见性和有序性这 3 个特性而建立起来的。\n原子性 AtomicityJMM 直接保证基本数据类型（64 位的姑且也可以包含在内）的读写访问（read、load、assign、use、store、write）具备原子性。如果场景需要更大范围的原子性保证（经常发生），JMM 提供 lock、unlock 操作来满足这种需求。jvm 并没有把这两个操作直接暴露给用户，而是提供了更高层次的字节码指令：monitorenter 和 monitorexit 来隐式使用这两个操作。这两个字节码指令反映到 java 代码中就是同步块——synchronized 关键字，因此在 synchronized 块之间的操作也具备原子性。\n可见性 Visibility当一个线程修改了共享变量的值，其他线程能够立即得知这个修改。JMM 通过在变量修改后将新值同步回主内存，在变量读取前从主内存刷新变量值这种依赖主内存作为传递媒介的方式来实现可见性。无论普通变量还是 volatile 变量都是如此，不同在于：volatile 的特殊规则保证了新值能够立即同步到主内存并且每次使用前立即从主内存刷新，从而保证了多线程操作中变量的可见性。除了 volatile 之外，synchronized 和 final也能保证可见性。同步块的可见性由“对一个变量执行 unlock 操作之前，必须把它同步回主内存中（执行 store、write 操作）”这条规则获得的；而 final 关键字的可见性是指：被 final 修饰的字段在构造器中一旦初始化完成，并且构造器没有把“this”的引用传递出去（this 引用逃逸是危险操作，其他线程有可能通过这个引用访问到”初始化了一半”的对象），那么在其他线程中就能看见 final 字段的值，并且无须同步就能被线程正确访问。\n有序性 Ordering如果在本线程观察，所有的操作都是有序的；如果在一个线程中观察另一个线程，所有的操作都是无序的。前半句是指“线程内表现为串行的语义（Within-Thread As-If-Serial Semantics）”，后半句是指“指令重排序”现象和“工作内存与主内存同步延迟”现象。这是 java 程序中天然的有序性。java 语言提供了 volatile 和 synchronized 关键字来保证线程之间操作的有序性，volatile 本身就包含了禁止对指令重排序的语义，而 synchronized 由“一个变量在同一个时刻只允许一条线程对其进行 lock 操作”这条规则获得有序性保证——该规则决定了持有同一个锁的两个同步块只能串行地进入。\n可见，synchronized 关键字在需要以上 3 种特性的时候都可以作为一种解决方案，事实上也是如此：大部分并发控制操作都可以使用它来完成。但滥用以及本可以考虑其他更优的方式而仍然选择使用 synchronized，也将导致性能和效率的不同程度降低。\nHappen-Before 原则先行发生原则，JMM 定义的两项操作之间的偏序关系，是判断数据是否存在竞争、线程是否安全的主要依据：如果操作 A 先行发生于操作 B，i.e. 操作 A 发生在操作 B 之前，那么操作 A 产生的影响（应该保证）能被操作 B 观察到，“影响”包括修改了共享内存中变量的值、发送了消息、调用了方法等。以下为 JMM 天然存在的 Happen-Before 关系，这些先行发生关系无须任何同步器协助就能正常执行，即在编码过程中直接使用，并且如果两个操作之间的关系不在下述范围之列，或者无法从下述条目推导得出，那么它们就没有顺序性保证，jvm 就可以对它们进行重排序：\n\n程序次序规则（Program Order Rule）：在一个线程内，按照程序代码顺序，书写在前面的操作先行发生于书写在后面的操作（更准确的说法是控制流顺序而不是代码顺序，因为有分支、循环等结构）；\n监视器锁规则（Monitor Lock Rule）：一个 unlock 操作先行发生于后面对同一个锁的 lock 操作。这里强调同一个锁，而“后面”是指时间上的先后顺序；\nvolatile 变量规则（Volatile Variable Rule）：对一个 volatile 变量的写操作先行发生于后面对这个变量的读操作。这里的“后面”同样是指时间上的先后顺序；\n传递性（Transitivity）：如果操作 A 先行发生于操作 B，操作 B 先行发生于操作 C，那么可以得出结论：操作 A 先行发生于 操作 C。\n线程启动规则（Thread Start Rule）：Thread 对象的 start() 方法先行于此线程的每一个动作；\n线程终止规则（Thread Termination Rule）：线程中的所有操作都先行发生于对此线程的终止检测，可以通过 Thread.join()方法的结束、Thread.isAlive()的返回值等手段检测到线程是否已经终止；\n线程中断规则（Thread Interruption Rule）：对线程 interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生，可以通过 Thread.interrupted()方法检测到线程是否有中断发生；\n对象终结规则（Finalizer Rule）：一个对象的初始化完成（构造函数执行结束）先行发生于它的 finalize()方法的开始；可以根据以上规则判定一端代码是否可以保持线程安全，即是否需要采取线程安全的措施。\n\n“时间上的先发生”和“先行发生”之间并没有推导关系，见书上关于 setter() &amp; getter() 和 重排序的例子。\nref：Java内存模型是什么\n","categories":["java"],"tags":["java","JVM"]},{"title":"JVM","url":"/2018/06/04/java/JVM/JVM/","content":"[toc]\n逃逸分析一种有效减少 java 程序中同步负载和内存堆分配压力的跨函数全局数据流分析算法。通过逃逸分析，HotSpot 编译器能够分析出一个新建对象的引用的使用范围，从而决定是否在堆上分配该对象。\n原理在计算机语言编译器优化原理中，逃逸分析是指分析指针动态范围的方法，它同编译器优化原理的指针分析和外形分析相关联。当变量（对象）在方法中分配后，其指针有可能被返回或者被全局引用，这样就会被其他过程或者线程所引用，这种现象称作指针（或者引用）的逃逸(Escape)。通俗点讲，如果一个对象的指针被多个方法或者线程引用时，那么我们就称这个对象的指针发生了逃逸。具体到 java 编译器中，我们知道对象总是在堆上分配的，因此对象的创建和回收对系统开销影响很大，不支持栈上分配对象也是 java 被批评的原因之一。考虑一种普遍场景：一般在方法体内，声明一个局部变量，该变量在方法执行生命周期内并非发生逃逸，但是按照 JVM 内存分配机制（未优化前），还是会首先在堆上创建该对象，然后将该对象的引用压入方法栈。而开启逃逸分析优化后（-XX:+DoEscapeAnalysis），JVM 会分析并找出未逃逸的变量，将该变量的实例化内存直接在栈上分配，无需进入堆，最后线程执行结束，栈空间被回收，栈上的局部对象也被回收，从而避免 GC 管理回收这部分对象。\nhttp://www.importnew.com/27262.html\n","categories":["java"],"tags":["java","JVM"]},{"title":"Collections","url":"/2018/06/03/java/Container/Collections/","content":"[toc]\nMap 接口Map 可以看作是一种符号表，使用键值对的数据结构存储数据。实现了 Map 接口的常用容器类：包括非线程安全的 HashMap、LinkedHashMap、TreeMap，线程安全的 ConcurrentHashMap、ConcurrentSkipListMap，线程安全但目前已不推荐使用的 HashTable。\nHashMappackage java.util;\npublic class HashMap&lt;K,V> extends AbstractMap&lt;K,V>\n    implements Map&lt;K,V>, Cloneable, Serializable &#123;&#125;\n其内部的 Node 结构：\nstatic class Node&lt;K,V> implements Map.Entry&lt;K,V> &#123;\n        final int hash;\n        final K key;\n        V value;\n        Node&lt;K,V> next;\n        ...\n&#125;\n初始大小 DEFAULT_INITIAL_CAPACITY &#x3D; 1 &lt;&lt; 4; &#x2F;&#x2F; aka 16。即初始大小为 16。\n树化&#x2F;退化为了提高哈希碰撞下的寻址性能，在链表长度超过树化阈值时将链表转换为一棵红黑树，即将寻址时间复杂度从 O(n) 降低到 O(logn)：\nstatic final int TREEIFY_THRESHOLD = 8;\nstatic final int UNTREEIFY_THRESHOLD = 6;\n...\nif (binCount >= TREEIFY_THRESHOLD)\n    // Conversion from/to TreeBins\n    treeifyBin(tab, i);\n同样地，当链表长度减小到退化阈值，原本红黑树化的链表会重新组织成一个链表，此时尽管是 O(n) 的查询时间，但由于链表较短，性能依然很好。基于 HashMap 实现的其他版本也有此演进（详见JDK1.7- 到 JDK1.8+ 源码变化）。\n寻址方式&#x2F;hash 值计算通过 Key 的哈希值与数组长度取模确定该 Key 在数组中的索引。JDK1.8+ HashMap 作者认为引入红黑树转化策略后，即使哈希冲突比较严重，寻址效率也足够高，所以并未在哈希值计算上做过多设计。具体做法只将 Key 的 hashCode 高 16 位保持不变，低 16 位与高 16 位进行异或操作，得到的值作为低 16 位的值，即得到 hash 值（即 hash()）：\nstatic final int hash(Object key) &#123;\n    int h;\n    return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16); &#125;\n关于该扰动函数的分析可以看这里：Java 8 HashMap 中 hash() 方法分析\n特点\n非线程安全的；\n根据键的 hashCode 值存储数据。大多数情况下可以直接定位键值对，因而具有很快的访问速度，理论上时间复杂度为 O(1)；\n遍历顺序是不确定的，也无法支持随机访问；\n不允许重复键，最多只允许一条记录的键为 null，允许多条记录的值为 null。\n\nhashCode 方法和加载因子HashMap 基于哈希函数来存储键值对，即，由一个哈希函数决定每个键值对的存放位置，存放位置所使用的数据结构为一个数组，其初始容量为 16，并且要求该值必须为 2 的幂，这与其底层数据结构有关。在不出现哈希碰撞（两个键值对的哈希结果相同）的情况下，即完美哈希时，访问时间复杂度即为 O(1)。HashMap 使用 开散列 方法来解决哈希冲突，即，对应一个特定 hash 值的位置存储的是一个链表头，指向 hash 到同一个位置的多个键值对组成的链表。这种实现的访问时间复杂度显然不是常数级，且随着键值对的增多，发生碰撞的情况会加剧。所以 HashMap 有一个加载因子（DEFAULT_LOAD_FACTOR &#x3D; 0.75f），用来控制当 HashMap 到达一定“装载程度”时执行 rehash（重哈希）操作，使得容量变为原来的约 2 倍。注意，重哈希是个非常耗时的操作，所以有必要采取一些措施（比如预估并在初始化时调用指定初始数组容量的构造方法）来避免&#x2F;减少。\n重写 hashCode() 和 equal()HashMap 的很多方法都是基于 hashCode() 和 equal() 的，前者用来定位，后者用来判断是否相等。很多情况下，equal 方法可能并不符合我们程序的逻辑——Object 的 equel 方法只是简单地判断是不是同一个实例，因此当我们认为判定 equals 应该是逻辑上的相等而不是仅仅判断是不是内存中中同一个东西的时候，就需要重写 equal()，此时，就必须重写 hashCode()。重写 equal() 要使得其依然满足：\n\n自反性\n对称性\n传递性\n一致性\n\n常用方法put()、get()：根据数据结构特点可知，先利用 hashCode 定位到具体的链表，再在链表中遍历是否已存在，然后操作。\nresize 死循环当 HashMap 的 size 超过 Capacity * loadFactor 时，即需要重哈希扩容时，将原来的数据重新计算哈希值并插入到新的数组中的过程，是非线程安全的，在多线程并发执行该操作的过程中，可能出现死循环，即在重新链接时出现环，导致失败。\nfast-fail在使用迭代器的过程中，如果 HashMap 被修改，那么将抛出 ConcurrentModificationException，即 Fast-fail 策略：在并发集合进行迭代操作时，若有其他线程对其进行结构性的修改，这时迭代器会立马感知到，并立即抛出 ConcurrentModificationException 异常，而不是等到迭代完成之后才告诉你（此时早已经出错了）。\n问题容量为什么必须是 2 的幂？HashMap 中的数据结构是数组 + 单链表的组合。我们希望元素存放的更均匀，理想情况是，Entry 数组中每个位置都只有一个元素，这样，查询的时候效率最高，不需要遍历单链表，也不需要通过 equals() 去比较 K，而且空间利用率最大，时间复杂度最优。而使得计算分布得更均匀，就是使用 % 运算，即取模：哈希值 % 容量 &#x3D; bucketIndex当容量为 2 的幂时，可以（也是源码方法）写成：h &amp; (length - 1) ，这与前式等价但不等效：后者位运算的效率更高（CPU 效率最慢的也就是除法和取余了）！ \n加载因子怎么选择，为什么默认 0.75？这是一种时间和空间的折中选择：加载因子过高虽然减少了空间开销，但同时也增加了查询成本；反之亦然。\n可以存储 null 吗？可以。jdk1.8 对 key&#x3D;null 的处理是：首先该 key 的 hash() 返回值为 0，此时 put() 方法按照（hash() &amp; (length-1)）确定该元素所在的桶位置，可见为 0。即，key&#x3D;null 时，元素存放在数组的起始位置（即第一个桶中）。\n参考博客\nLinkedHashMap实现package java.util;\npublic class LinkedHashMap&lt;K,V>\n    extends HashMap&lt;K,V>\n    implements Map&lt;K,V> &#123;&#125;\n其内部的 Entry 扩展了 HashMap 的 Node 并添加了两个指针：\nstatic class Entry&lt;K,V> extends HashMap.Node&lt;K,V> &#123;\n    Entry&lt;K,V> before, after;\n    Entry(int hash, K key, V value, Node&lt;K,V> next) &#123;\n        super(hash, key, value, next);\n    &#125;\n&#125;\n\n将所有节点链入一个双向链表的 HashMap。继承自 HashMap，所以拥有 HashMap 的所有特性。比如，LinkedHashMap 的元素存取过程基本与 HashMap 基本类似，只是在细节实现上稍有不同。这是由 LinkedHashMap 本身的特性所决定的，因为它额外维护了一个双向链表用于 保持迭代顺序，并重写了HashMap 的迭代器，使用其维护的双向链表进行迭代输出，可以以插入顺序遍历元素——这是和无序的 HashMap 最大的区别。\n存取LinkedHashMap 的存取过程与 HashMap 基本类似，只是在细节实现上稍有不同，这是由 LinkedHashMap 本身的特性所决定的，因为它要额外维护一个双向链表用于保持迭代顺序。put 操作上，虽然 LinkedHashMap 完全继承了 HashMap 的 put 操作，但是在细节上还是做了一定的调整，比如，在 LinkedHashMap 中向哈希表中插入新 Entry 的同时，还会通过 Entry 的 addBefore 方法将其链入到双向链表中。在扩容操作上，虽然 LinkedHashMap 完全继承了 HashMap的resize 操作，但是鉴于性能和 LinkedHashMap 自身特点的考量，LinkedHashMap 对其中的重哈希过程(transfer方法)进行了重写。get 操作上，LinkedHashMap 重写了 HashMap 的 get 方法，通过 HashMap 的 getEntry 方法获取 Entry 对象，在此基础上，进一步获取指定键对应的值。\nLinkedHashMap 与 LRU当使用 LinkedHashMap 实现 LRU 算法时，需要调用其第 5 个构造方法，将 accessOrder 置为 true，即，元素按访问顺序排序（默认 false 按插入顺序排序）。LinkedHashMap 重写了 HashMap 的 recordAccess 方法（HashMap中该方法为空），当调用父类的put 方法时，在发现 key 已经存在时，会调用该方法；当调用自己的 get 方法时，也会调用到该方法。该方法提供了 LRU 算法的实现，它将最近使用的 Entry 放到双向循环链表的尾部。即当 accessOrder 为 true 时，get 方法和 put 方法都会调用 recordAccess 方法使得最近使用的 Entry 移到双向链表的末尾；当 accessOrder 为默认值 false 时，从源码中可以看出 recordAccess 方法什么也不会做。可以用以上方法快速构建 LRU 算法实现。\n参考博客\nTreeMap 红黑树结构的 Mappackage java.util;\npublic class TreeMap&lt;K,V>\n    extends AbstractMap&lt;K,V>\n    implements NavigableMap&lt;K,V>, Cloneable, java.io.Serializable &#123;&#125;\n\n继承了 AbstractMap，而 AbstractMap 实现了 Map 接口，并实现了 Map 接口中定义的方法，减少了其子类继承的复杂度；\n实现了 Map 接口，成为 Map 框架中的一员，可以包含 key-value 形式的元素；\n实现了 NavigableMap 接口，拥有了更强的元素搜索能力；\n实现了 Cloneable 接口，实现了 clone() 方法，可以被克隆；\n实现了 Serializable 接口，支持序列化操作，可通过 Hessian 协议进行传输；\n\nNavigableMap &amp; SortedMap 接口\n其中，SortedMap 接口定义了 Comparator&lt;? super K&gt;，即比较器，这决定了 TreeMap 体系的走向，也是其有别于 HashMap 体系最关键的一个接口实现：用比较器对插入元素进行排序，从而决定其插入位置。NavigableMap 接口进一步扩展了 SortedMap 接口：主要用于 增强对元素的搜索获取操作，如返回集合中某一区间的元素、返回小于&#x2F;大于某一值的元素等。\n排序方式\n默认情况下，使用元素自然排序，需要元素实现 Comparable 接口；\n使用自定义比较器排序，需要在创建 TreeMap 对象时，将自定义比较器对象传入到其构造方法中。此时无需再实现 Comparable 接口。\n\nRB-treeTreeMap 底层使用红黑树实现，具有理论 O(logn) 的操作时间复杂度，增删操作通过旋转操作保持树的平衡性。Algs4 中关于红黑树的部分参考博客\n特点\n非线程安全\n不允许出现重复键；可以插入 null 键（最多一个），null 值（不限制）；\n可以对元素进行排序；\n无序集合：插入和遍历顺序不一致。\n\n主要方法\ngut：利用平衡树的快速查找，可以在 O(logn) 时间内定位要查找的元素；\nput：如果存在，old value 被替换；如果不存在，则新增节点，然后对红黑树通过旋转作平衡操作；\n遍历：类似于中序遍历的方式迭代输出所有元素；\n\n###以上 3 个是 Map 的基础实现，尤其是 HashMap，是 java 中最为常用的数据结构。它们都是非线程安全的，但可以通过 Collections 类的 synchronized 相关方法将它们转换为同步类。此外，java 实现了与之对应的线程安全的容器类。\n###","categories":["java"],"tags":["java","容器"]},{"title":"Map-线程安全","url":"/2018/06/03/java/Container/Map-%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8/","content":"[toc]实现了 Map 接口的常用容器类Map 可以看作是一种符号表，使用键值对的数据结构存储数据。包括非线程安全的 HashMap、LinkedHashMap、TreeMap，线程安全的 ConcurrentHashMap、ConcurrentSkipListMap，线程安全但目前已不推荐使用的 HashTable。\nHashTable线程安全的 HashMap。Hashtable 继承自 Dictionary 虚类，而非 AbstractMap：\npackage java.util;\npublic class Hashtable&lt;K,V>\n    extends Dictionary&lt;K,V>\n    implements Map&lt;K,V>, Cloneable, java.io.Serializable &#123;&#125;\n其使用方式上，除了支持多线程外，和 HashMap并没有明显区别。HashTable 使用“拉链法”实现哈希表。几个重要参数：\n\ntable：一个 Entry[] 数组类型，Entry 代表了“拉链”的节点，每一个 Entry 代表了一个键值对；\ncount：HashTable 的大小，包含 Entry 键值对的数量，而不是 HashTable 容器大小；\nthreshold：阈值，用于判断是否需要调整容量。threshold &#x3D;“容量 * 加载因子”；\nloadFactor：加载因子。\nmodCount：用来实现“fail-fast”机制（即快速失败）。所谓快速失败，就是在并发集合进行迭代操作时，若有其他线程对其进行结构性的修改，这时迭代器会立马感知到，并立即抛出 ConcurrentModificationException 异常，而不是等到迭代完成之后才告诉你（此时早已经出错了）。\n\n线程安全的保证很多方法使用了 synchronized 修饰，以锁的方式保证操作的同步和安全。这意味着，如果确定程序可以在单线程表现良好，那么不适合使用它（显然应该考虑 HashMap）：锁机制带来的效率降低是很显著的。\n为什么不再推荐使用？截止到 JDK10，HashTable（也包括 Vector、Satck）并没有被标注为 Deprecated，也就是它们仍然可以正常使用。问题在于，它对每一个操作都加了 synchronized 锁，这往往并非我们所希望的：通常，我们更希望同步整个序列，而非每个操作。并且同步每个操作也并不能保证安全性，仍然需要获取一个锁来避免并发操作，但性能和效率的降低却是显而易见的。而后续补充的相应线程同步容器类则从侧面验证了，它们不是好的选择。\nConcurrentHashMap线程安全的 HashMap。随着 JDK 的变迁，ConcurrentHashMap 从一开始的分段锁（JDK1.7 以及之前）技术转换到基于 CAS 实现（JDK1.8+）。以下以 CAS 实现为例：线程安全、支持高效并发版本的 HashMap。其源码具体实现依赖于 JMM，包括重排序、内存可见性（volatile 关键字）、happen-before（偏序关系）等。ConcurrentHashMap演进\npackage java.util.concurrent;\npublic class ConcurrentHashMap&lt;K,V> extends AbstractMap&lt;K,V>\n    implements ConcurrentMap&lt;K,V>, Serializable &#123;&#125;\n\n// ConcurrentMap 接口定义如下\npublic interface ConcurrentMap&lt;K,V> extends Map&lt;K,V> &#123;&#125;\n\n数据结构JDK1.7之前通过分段锁技术使得理论并发数量等于其 ConcurrentHashMap 类对象实例的 Segment（相当于一个小型哈希表） 个数。从 JDK1.8 开始为进一步提高并发性，摒弃了分段锁的解决方案，直接使用一个大的数组，同样考虑哈希碰撞将长度超过阈值的桶链表转换为红黑树：\n寻址方式同样（类比 HashMap、HashTable、旧版本的该类实现）是通过 Key 的哈希值与数组长度取模确定该 Key 在数组中的索引。同样为了避免不太好的 Key 的 hashCode 设计，它通过以下方法计算得到 Key 的最终哈希值。不同的是，JDK1.8+ 的 ConcurrentHashMap 作者认为引入红黑树转化策略后，即使哈希冲突比较严重，寻址效率也足够高，所以并未在哈希值计算上做过多设计，而只将 Key 的 hashCode 与其高 16 位作异或（XOR）并保证最高位为 0（从而保证最终结果为正整数）：\nstatic final int spread(int h) &#123;\n    return (h ^ (h >>> 16)) &amp; HASH_BITS; &#125;\n\n\n同步方式put 操作，如果 Key 对应的数组元素为 null，则通过 CAS 操作将其设置为当前值；否则，对该元素使用 synchronized 关键字申请锁，成功后再进行操作。操作完成后判断是否需要将该处的链表转换为红黑树。get 操作，由于数组是被 volatile 关键字修饰的（见上），因此无需担心数组的可见性问题。同时每个元素是一个 Node 实例（JDK1.7 每个元素是一个 hashEntry），它的 Key 值和 hash 值都由 final 修饰，不可修改，故也无需担心它们被修改的可见性问题。而 Value 及对下一个元素的引用由 volatile 修饰，也能保证可见性：\nstatic class Node&lt;K,V> implements Map.Entry&lt;K,V> &#123;\n    final int hash;\n    final K key;\n    volatile V val;\n    volatile Node&lt;K,V> next;\n    ... &#125;\n\nKey 对应的数组元素的可见性，由 Unsafe 的 getObjectVolatile 方法保证:\nstatic final &lt;K,V> Node&lt;K,V> tabAt(Node&lt;K,V>[] tab, int i) &#123;\n    return (Node&lt;K,V>)U.getObjectAcquire(tab, ((long)i &lt;&lt; ASHIFT) + ABASE); &#125;\n\nsize() 操作put 和 remove 方法都会通过 addCount 方法维护 Map 的 size。size 方法通过 sumCount 获取由 addCount 方法维护的 Map 的 size。\n分段锁技术（JDK1.7）采用分段锁技术实现的 ConcurrentHashMap 结构：\nConcurrentSkipListMap线程安全的 TreeMap。线程安全的有序的 Map。底层数据结构使用跳表——在并发场景下，它的性能优于红黑树，实现上也简单得多。\npackage java.util.concurrent;\npublic class ConcurrentSkipListMap&lt;K,V> extends AbstractMap&lt;K,V>\n    implements ConcurrentNavigableMap&lt;K,V>, Cloneable, Serializable &#123;&#125;\n\n\n\nref:HashMap 相关QA\n","categories":["java"],"tags":["java","容器"]},{"title":"Map","url":"/2018/06/03/java/Container/Map/","content":"[toc]\nMap 接口Map 可以看作是一种符号表，使用键值对的数据结构存储数据。实现了 Map 接口的常用容器类：包括非线程安全的 HashMap、LinkedHashMap、TreeMap，线程安全的 ConcurrentHashMap、ConcurrentSkipListMap，线程安全但目前已不推荐使用的 HashTable。\nHashMappackage java.util;\npublic class HashMap&lt;K,V> extends AbstractMap&lt;K,V>\n    implements Map&lt;K,V>, Cloneable, Serializable &#123;&#125;\n其内部的 Node 结构：\nstatic class Node&lt;K,V> implements Map.Entry&lt;K,V> &#123;\n        final int hash;\n        final K key;\n        V value;\n        Node&lt;K,V> next;\n        ...\n&#125;\n初始大小 DEFAULT_INITIAL_CAPACITY &#x3D; 1 &lt;&lt; 4; &#x2F;&#x2F; aka 16。即初始大小为 16。\n树化&#x2F;退化为了提高哈希碰撞下的寻址性能，在链表长度超过树化阈值时将链表转换为一棵红黑树，即将寻址时间复杂度从 O(n) 降低到 O(logn)：\nstatic final int TREEIFY_THRESHOLD = 8;\nstatic final int UNTREEIFY_THRESHOLD = 6;\n...\nif (binCount >= TREEIFY_THRESHOLD)\n    // Conversion from/to TreeBins\n    treeifyBin(tab, i);\n同样地，当链表长度减小到退化阈值，原本红黑树化的链表会重新组织成一个链表，此时尽管是 O(n) 的查询时间，但由于链表较短，性能依然很好。基于 HashMap 实现的其他版本也有此演进（详见JDK1.7- 到 JDK1.8+ 源码变化）。\n寻址方式&#x2F;hash 值计算通过 Key 的哈希值与数组长度取模确定该 Key 在数组中的索引。JDK1.8+ HashMap 作者认为引入红黑树转化策略后，即使哈希冲突比较严重，寻址效率也足够高，所以并未在哈希值计算上做过多设计。具体做法只将 Key 的 hashCode 高 16 位保持不变，低 16 位与高 16 位进行异或操作，得到的值作为低 16 位的值，即得到 hash 值（即 hash()）：\nstatic final int hash(Object key) &#123;\n    int h;\n    return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16); &#125;\n关于该扰动函数的分析可以看这里：Java 8 HashMap 中 hash() 方法分析\n特点\n非线程安全的；\n根据键的 hashCode 值存储数据。大多数情况下可以直接定位键值对，因而具有很快的访问速度，理论上时间复杂度为 O(1)；\n遍历顺序是不确定的，也无法支持随机访问；\n不允许重复键，最多只允许一条记录的键为 null，允许多条记录的值为 null。\n\nhashCode 方法和加载因子HashMap 基于哈希函数来存储键值对，即，由一个哈希函数决定每个键值对的存放位置，存放位置所使用的数据结构为一个数组，其初始容量为 16，并且要求该值必须为 2 的幂，这与其底层数据结构有关。在不出现哈希碰撞（两个键值对的哈希结果相同）的情况下，即完美哈希时，访问时间复杂度即为 O(1)。HashMap 使用 开散列 方法来解决哈希冲突，即，对应一个特定 hash 值的位置存储的是一个链表头，指向 hash 到同一个位置的多个键值对组成的链表。这种实现的访问时间复杂度显然不是常数级，且随着键值对的增多，发生碰撞的情况会加剧。所以 HashMap 有一个加载因子（DEFAULT_LOAD_FACTOR &#x3D; 0.75f），用来控制当 HashMap 到达一定“装载程度”时执行 rehash（重哈希）操作，使得容量变为原来的约 2 倍。注意，重哈希是个非常耗时的操作，所以有必要采取一些措施（比如预估并在初始化时调用指定初始数组容量的构造方法）来避免&#x2F;减少。\n重写 hashCode() 和 equal()HashMap 的很多方法都是基于 hashCode() 和 equal() 的，前者用来定位，后者用来判断是否相等。很多情况下，equal 方法可能并不符合我们程序的逻辑——Object 的 equel 方法只是简单地判断是不是同一个实例，因此当我们认为判定 equals 应该是逻辑上的相等而不是仅仅判断是不是内存中中同一个东西的时候，就需要重写 equal()，此时，就必须重写 hashCode()。重写 equal() 要使得其依然满足：\n\n自反性\n对称性\n传递性\n一致性\n\n常用方法put()、get()：根据数据结构特点可知，先利用 hashCode 定位到具体的链表，再在链表中遍历是否已存在，然后操作。\nresize 死循环当 HashMap 的 size 超过 Capacity * loadFactor 时，即需要重哈希扩容时，将原来的数据重新计算哈希值并插入到新的数组中的过程，是非线程安全的，在多线程并发执行该操作的过程中，可能出现死循环，即在重新链接时出现环，导致失败。\nfast-fail在使用迭代器的过程中，如果 HashMap 被修改，那么将抛出 ConcurrentModificationException，即 Fast-fail 策略：在并发集合进行迭代操作时，若有其他线程对其进行结构性的修改，这时迭代器会立马感知到，并立即抛出 ConcurrentModificationException 异常，而不是等到迭代完成之后才告诉你（此时早已经出错了）。\n问题容量为什么必须是 2 的幂？HashMap 中的数据结构是数组 + 单链表的组合。我们希望元素存放的更均匀，理想情况是，Entry 数组中每个位置都只有一个元素，这样，查询的时候效率最高，不需要遍历单链表，也不需要通过 equals() 去比较 K，而且空间利用率最大，时间复杂度最优。而使得计算分布得更均匀，就是使用 % 运算，即取模：哈希值 % 容量 &#x3D; bucketIndex当容量为 2 的幂时，可以（也是源码方法）写成：h &amp; (length - 1) ，这与前式等价但不等效：后者位运算的效率更高（CPU 效率最慢的也就是除法和取余了）！\n加载因子怎么选择，为什么默认 0.75？这是一种时间和空间的折中选择：加载因子过高虽然减少了空间开销，但同时也增加了查询成本；反之亦然。\n可以存储 null 吗？可以。jdk1.8 对 key&#x3D;null 的处理是：首先该 key 的 hash() 返回值为 0，此时 put() 方法按照（hash() &amp; (length-1)）确定该元素所在的桶位置，可见为 0。即，key&#x3D;null 时，元素存放在数组的起始位置（即第一个桶中）。\n参考博客\nLinkedHashMap实现package java.util;\npublic class LinkedHashMap&lt;K,V>\n    extends HashMap&lt;K,V>\n    implements Map&lt;K,V> &#123;&#125;\n其内部的 Entry 扩展了 HashMap 的 Node 并添加了两个指针：\nstatic class Entry&lt;K,V> extends HashMap.Node&lt;K,V> &#123;\n    Entry&lt;K,V> before, after;\n    Entry(int hash, K key, V value, Node&lt;K,V> next) &#123;\n        super(hash, key, value, next);\n    &#125;\n&#125;\n\n将所有节点链入一个双向链表的 HashMap。继承自 HashMap，所以拥有 HashMap 的所有特性。比如，LinkedHashMap 的元素存取过程基本与 HashMap 基本类似，只是在细节实现上稍有不同。这是由 LinkedHashMap 本身的特性所决定的，因为它额外维护了一个双向链表用于 保持迭代顺序，并重写了HashMap 的迭代器，使用其维护的双向链表进行迭代输出，可以以插入顺序遍历元素——这是和无序的 HashMap 最大的区别。\n存取LinkedHashMap 的存取过程与 HashMap 基本类似，只是在细节实现上稍有不同，这是由 LinkedHashMap 本身的特性所决定的，因为它要额外维护一个双向链表用于保持迭代顺序。put 操作上，虽然 LinkedHashMap 完全继承了 HashMap 的 put 操作，但是在细节上还是做了一定的调整，比如，在 LinkedHashMap 中向哈希表中插入新 Entry 的同时，还会通过 Entry 的 addBefore 方法将其链入到双向链表中。在扩容操作上，虽然 LinkedHashMap 完全继承了 HashMap的resize 操作，但是鉴于性能和 LinkedHashMap 自身特点的考量，LinkedHashMap 对其中的重哈希过程(transfer方法)进行了重写。get 操作上，LinkedHashMap 重写了 HashMap 的 get 方法，通过 HashMap 的 getEntry 方法获取 Entry 对象，在此基础上，进一步获取指定键对应的值。\nLinkedHashMap 与 LRU当使用 LinkedHashMap 实现 LRU 算法时，需要调用其第 5 个构造方法，将 accessOrder 置为 true，即，元素按访问顺序排序（默认 false 按插入顺序排序）。LinkedHashMap 重写了 HashMap 的 recordAccess 方法（HashMap中该方法为空），当调用父类的put 方法时，在发现 key 已经存在时，会调用该方法；当调用自己的 get 方法时，也会调用到该方法。该方法提供了 LRU 算法的实现，它将最近使用的 Entry 放到双向循环链表的尾部。即当 accessOrder 为 true 时，get 方法和 put 方法都会调用 recordAccess 方法使得最近使用的 Entry 移到双向链表的末尾；当 accessOrder 为默认值 false 时，从源码中可以看出 recordAccess 方法什么也不会做。可以用以上方法快速构建 LRU 算法实现。\n参考博客\nTreeMap 红黑树结构的 Mappackage java.util;\npublic class TreeMap&lt;K,V>\n    extends AbstractMap&lt;K,V>\n    implements NavigableMap&lt;K,V>, Cloneable, java.io.Serializable &#123;&#125;\n\n继承了 AbstractMap，而 AbstractMap 实现了 Map 接口，并实现了 Map 接口中定义的方法，减少了其子类继承的复杂度；\n实现了 Map 接口，成为 Map 框架中的一员，可以包含 key-value 形式的元素；\n实现了 NavigableMap 接口，拥有了更强的元素搜索能力；\n实现了 Cloneable 接口，实现了 clone() 方法，可以被克隆；\n实现了 Serializable 接口，支持序列化操作，可通过 Hessian 协议进行传输；\n\nNavigableMap &amp; SortedMap 接口\n其中，SortedMap 接口定义了 Comparator&lt;? super K&gt;，即比较器，这决定了 TreeMap 体系的走向，也是其有别于 HashMap 体系最关键的一个接口实现：用比较器对插入元素进行排序，从而决定其插入位置。NavigableMap 接口进一步扩展了 SortedMap 接口：主要用于 增强对元素的搜索获取操作，如返回集合中某一区间的元素、返回小于&#x2F;大于某一值的元素等。\n排序方式\n默认情况下，使用元素自然排序，需要元素实现 Comparable 接口；\n使用自定义比较器排序，需要在创建 TreeMap 对象时，将自定义比较器对象传入到其构造方法中。此时无需再实现 Comparable 接口。\n\nRB-treeTreeMap 底层使用红黑树实现，具有理论 O(logn) 的操作时间复杂度，增删操作通过旋转操作保持树的平衡性。Algs4 中关于红黑树的部分参考博客\n特点\n非线程安全\n不允许出现重复键；可以插入 null 键（最多一个），null 值（不限制）；\n可以对元素进行排序；\n无序集合：插入和遍历顺序不一致。\n\n主要方法\ngut：利用平衡树的快速查找，可以在 O(logn) 时间内定位要查找的元素；\nput：如果存在，old value 被替换；如果不存在，则新增节点，然后对红黑树通过旋转作平衡操作；\n遍历：类似于中序遍历的方式迭代输出所有元素；\n\n###以上 3 个是 Map 的基础实现，尤其是 HashMap，是 java 中最为常用的数据结构。它们都是非线程安全的，但可以通过 Collections 类的 synchronized 相关方法将它们转换为同步类。此外，java 实现了与之对应的线程安全的容器类。\n###","categories":["java"],"tags":["java","容器"]},{"title":"Exception","url":"/2018/06/03/java/into/Exception/","content":"[toc]\nException","categories":["java"],"tags":["java","Q&A"]},{"title":"java","url":"/2018/06/03/java/into/java/","content":"[toc]\n位操作移位运算符&lt;&lt;：  左移运算符，num &lt;&lt; 1，相当于 num 乘以 2；&gt;&gt;： 右移运算符，num &gt;&gt; 1，相当于 num 除以 2；&gt;&gt;&gt;：无符号右移，忽略符号位，空位都以 0 补齐。\n数组拷贝方式for 遍历语言层面使用循环遍历的方式依次拷贝每个元素，如果没有编译器优化，它对应的就是遍历数组操作的字节码，执行引擎就根据这些字节码循环获取数组的每个元素再执行拷贝操作。\nSystem.arraycopy()这是一个本地方法：\n@HotSpotIntrinsicCandidate\npublic static native void arraycopy(Object src,  int  srcPos,\n                                    Object dest, int destPos, int length);\n如果数组比较大，那么使用 System.arraycopy() 会比较有优势，因为其使用的是 内存复制，省去了大量的数组寻址访问等时间。\nArrays.copyOf()该方法对不同数据类型都有相应的重载。观察它们的源码可见，其内部时通过调用 System.arraycopy() 实现的。所以单就效率上来说，差别不大。\nclone()实现了 Cloneable 接口的类，如 ArrayList、HashMap、Hashtable、HashSet、LinkedList、Calendar、Date 等，支持 clone() 方法。其底层也是使用 System.arraycopy() 或 Arrays.copyOf() 实现。\n","categories":["java"],"tags":["java","Q&A"]},{"title":"字节流 字符流","url":"/2018/06/03/java/into/%E5%AD%97%E8%8A%82%E6%B5%81%20%E5%AD%97%E7%AC%A6%E6%B5%81/","content":"[toc]\n字节流","categories":["java"],"tags":["java","Q&A"]},{"title":"Arrays","url":"/2018/06/01/java/Container/Arrays/","content":"[toc]\nArrays数组的操作类，定义在 java.util 中。不提供实例化接口（构造函数为 private 修饰的），所有的方法都是静态方法，主要实现对数组的排序、查找、填充等操作。主要方法：\n\nboolean equals(int[] a, int[] a2)：判断两个数组是否相等，此方法被重载多次，可以判断各种数组类型的数组；\nvoid fill(int[] a, int val)：将指定的内容填充到数组之中，此方法被重载多次，可以填充各种数据类型的数组；\nvoid sort(int[] a)：数组排序，此方法被重载多次，可以对各种类型的数组进行排序。要求对象所在的类必须实现 Comparable 接口；\nint binarySearch(int[] a, int key)：对排序后的数组进行二分法检索，此方法被重载多次，可以对各种数据类型的数组进行搜索；\nString toString(int[] a)：输出数组信息，此方法被重载多次，可以输出各种数据类型的数组。\n\nsort() 方法首先，Arrays 针对不同数据类型和数据量，重载了多个版本的 sort() 方法，以获得更优的效率。如针对 byte 类型的数组采用 计数排序；根据数据规模从快排&#x2F;归并排序转换为插入排序等。从 JDK1.7 开始，Arrays 的 sort() 方法采用 DualPivotQuicksort（双轴快排&#x2F;双主元）排序实现。从命名可见，它是一种双 pivot 的快排策略，比传统单 pivot 快排效率更高。具体流程：\n\n\n需要排序的数组为 a，判断数组的长度是否大于 286（实现类中定义的 QUICKSORT_THRESHOLD），大于使用归并排序（merge sort），否则执行2；\n判断数组长度是否小于 47（INSERTION_SORT_THRESHOLD），小于则采用插入排序，否则执行 3；\n采用近似算法计算数组长度的 1&#x2F;7：int seventh &#x3D; (length &gt;&gt; 3) + (length &gt;&gt; 6) + 1;\n取出5个点：int e3 &#x3D; (left + right) &gt;&gt;&gt; 1;  &#x2F;&#x2F; 中位数int e2 &#x3D; e3 - seventh;int e1 &#x3D; e2 - seventh;int e4 &#x3D; e3 + seventh;int e5 &#x3D; e4 + seventh;\n将这5个元素进行插入排序；\n选取 a[e2]、a[e4] 分别作为 pivot1、pivot2。由于步骤 5 进行了排序，所以必有 pivot1 &lt; pivot2；\n定义 3 个指针：分别是 less、k、great。ess 和 great 将数组分为 3 个部分，分别是小于 less 的、大于 less 小于 great 的元素和大于 great 的元素。 \n将 a[k] 分别与 pivot1、pivot2 比较。如果小于 pivot1，则将 a[k] 与a [less] 对调，同时 k++。如果大于 pivot2，则执行 9；否则执行 10；\n将 a[great] 分别与 pivot1、pivot2 比较。如果 a[great] 大于 pivot2，则 great–，直到大于 pivot2 的条件不满足或者 k&#x3D;&#x3D;great。如果 a[great] 小于 pivot1，则将 a[great] 换到小于 less 的区域。如果 a[great] 大于 pivot1，则说明位于中间区域，将 a[great] 与 a[k]对 调。great–；\nk++，如果 k &gt; great，说明处理完成，执行 11，否则继续执行 8；\n由于前面的操作，还未将 pivot1、pivot2 这 2 个元素放对位置，所以还需要将 a[less - 1] 移动到队头，pivot1 移动到（less - 1） 的位置，将 a[great +1] 移动到队尾，pivot2 移动到 （great +1） 的位置；\n至此，已经达到步骤7描述的最终结果，将数组分为了 3 个区域。对较小的区域和较大的区域递归执行步骤 2。判断中间的区域是否过大，如果是，则执行 13，否则递归执行步骤 2；\n将等于 pivot1 或者 pivot2 的元素移动到两边，然后递归执行步骤 2。\n\nparallelSort() 方法JDK1.8 新增的排序方法，这是一种并行排序，可以多线程进行排序。使用了 JDK1.7 的 Fork&#x2F;Join 框架使排序任务可以在线程池中的多个线程中进行。Fork&#x2F;Join 实现了一种任务窃取算法，一个闲置的线程可以窃取其他线程的闲置任务进行处理。\nbinarySearch() 方法对排序后的数组进行二分查找。\nfill()填充数组不是加在数组后面，而是将数组中的所有元素都重新赋值。\nasList()可以将数组转为 List 但是，这个数组类型必须是 引用类型 的。所以，该方法对基本数据类型的支持并不是很好：比如当要转换的数组为基本数据类型时：\nint[] a_int = new int[10];\nInteger[] a_integer = new Integer[10];\n\nList a_int_list = Arrays.asList(a_int);\nList a_integer_list = Arrays.asList(a_integer);\n\nSystem.out.println(a_int_list.size());\nSystem.out.println(a_integer_list.size());\n\n--------------------------------\noutput: \n1\n10\n\n而且，其返回的 List 实例为 Arrays 类定义的内部类类型 ArrayList&lt;E []&gt;——而非 java.util.ArrayList 类类型，并且 E 必须为对象类型，这也就解释了上述情况的原因，并且不支持 add、remove 等操作。\n","categories":["java"],"tags":["java","容器"]},{"title":"容器类","url":"/2018/05/31/java/Container/%E5%AE%B9%E5%99%A8%E7%B1%BB/","content":"[toc]\n容器类&#x2F;集合类java 集合类图谱：\n\n可以看出，java 的集合类主要由两个接口派生而出：Collection 和 Map，这两个接口又包含了一些接口或实现类。以下介绍的集合类还都实现了 java.io.Serializable 接口，即支持序列化，部分也实现了 RandomAccess、Cloneable 等接口。\n集合类简介\nArrays最简洁的数组实现，不提供实例化方法，所有的方法都是静态的。可以容纳基本类型和对象。\nCollection 接口一个 Collection 代表一组 Object，即 Collection 的元素（Elements）。一些 Collection 允许相同的元素而另一些不行，一些能排序而另一些不行。JDK 不提供 Collection 的直接实现，而是继承自 Collection “子接口”如 Set、List、Queue 的类。Collection 接口扩展了 Iterable 接口，后者的 Iterator() 方法返回一个迭代器 Iterator（一个接口），为集合框架提供 遍历所有元素 的方法。Iterator 模式把访问逻辑从不同的集合类中抽象出来，从而避免向客户端暴露集合的内部结构。每种集合类返回的 Iterator 具体类型可能不同，但它们都实现了 Iterator 接口，因此，不必关心到底是哪种 Iterator，它只需要获得这个 Iterator 接口即可。迭代器取代了 Java 集合框架中的 Enumeration（历史遗留类），Iterator 更加安全，因为当一个集合正在被遍历的时候，它会阻止其它线程去修改集合（以抛异常的方式）。要确保遍历过程顺利完成，必须保证遍历过程中不更改集合的内容（Iterator 的 remove() 方法除外）。所以，确保遍历可靠的原则是：只在一个线程中使用这个集合，或者在多线程中对遍历代码进行同步。\nCollections 类Collections 是一个集合框架的帮助类，里面包含一些对集合的排序，搜索以及序列化的操作。提供了一系列将 Collection 接口的实现类对象（非线程安全的容器）转换位线程安全对象的静态方法。原理就是在原有容器的类的方法内部实现逻辑中加入了同步关键字 syschronized。\nSet 接口Set 是一种不包含重复元素的 Collection，i.e. 任意两个元素都有 e1.equals(e2) &#x3D;&#x3D; false（也最多只有一个 null 元素）。这里就需要注意，必须要小心操作可变对象（Mutable Object）：如果一个 Set 中的可变元素改变了自身状态而导致 Object1.equals(Object2) &#x3D;&#x3D; true，将引发一些问题。Set 接口的实现不提供随机访问，一般通过迭代器访问。\n实现 Set 接口的常用类有：\n非线程安全版本 SetHashSet采用散列存储方式，为快速查找设计的 Set，无序——不保证元素插入的顺序和输出顺序一致。非线程安全\nLinkedHashSet：具有 HashSet 的查询速度优势，内部使用链表维护元素的顺序（插入次序），所以使用迭代器时会按照元素的插入顺序遍历。非线程安全\nTreeSet使用红黑树结构实现，维持集合中的元素有序，相应地时间复杂度损失：添加、删除、包含的算法复杂度为O(logn)。非线程安全\n线程安全版本 SetCopyOnWriteArraySetJDK 1.5 新增的 Set 接口实现，可以看作 HashSet 的线程安全版本，安全性保证来源于底层 CopyOnWriteArrayLis 的实现。通过源码中父类继承&#x2F;接口实现来看，相当于一个通过动态数组实现的“集合”。尽管二者都继承自共同的父类 AbstractSet，其实现却有不同：HashSet 是通过散列表即 HashMap 实现的，而 CopyOnWriteArraySet——从命名上也可以看出，是基于数组（通过源码可知，是基于动态数组 CopyOnWriteArrayList）实现的。CopyOnWriteArrayList 允许重复元素，但 CopyOnWriteArraySet 保持作为集合的属性，不允许重复元素。特点（基本等同 CopyOnWriteArrayList 特点）：\n\n线程安全。使用迭代器进行遍历的速度很快，并且不会与其他线程发生冲突。在构造迭代器时，迭代器依赖于不变的数组快照。迭代器支持hasNext()、next() 等不可变操作，但不支持可变 remove() 等操作；\n通常需要复制整个基础数组，所以可变操作（add()、set() 和 remove() 等等）的开销很大。\n适用于：Set 大小通常保持很小，只读操作远多于可变操作，需要在遍历期间防止线程间的冲突。\n\nList 接口List 是有序的 Collection，可以含有相同的元素，每个元素的插入位置是可控制的，能够使用检索（类似于数组的下标）访问元素。除了具有 Collection 接口必备的 Iterator() 方法外，List 还提供一个 listIterator() 方法，返回一个ListIterator 接口，和标准的 Iterator 接口相比，ListIterator 多了一些 add()、set() 之类的方法，允许添加、删除、设定元素，还能向前或向后遍历 previous()。\n实现 List 接口的常用类有：\n非线程安全版本 ListArrayList实现了可变大小数组，底层通过基础数组实现，非线程安全，支持随机访问。不同于 Arrays 的是，Arrays 可以容纳基本类型和对象，而 ArrayList 只能容纳对象。每个 ArrayList 实例都有一个容量（capacity)，即用于存储元素的数组的大小，该容量可以随着元素的不断添加而自动增长，但是增长算法并没有定义。当需要插入大量元素时，在插入前可以调用 arrayList.ensureCapacity(minCapacity) 来增加容量以提高插入效率。\nLinkedList擅长增删元素，非线程安全。同时扩展了 Queue 接口（准确说是 扩展了 Deque 接口，而 Deque 接口扩展了 Queue 接口），具有队列的性质和优势。\n线程安全版本 ListCopyOnWriteArrayListJDK 1.5 新增的 List 接口实现，可以看作 ArrayList 的线程安全版本，通过 增加写时复制语义来实现线程安全性。从源码可见，底层通过一个动态数组实现，并实现了 List、RandomAccess、Cloneable、Serializable 4 个接口。特点：\n\n线程安全。使用迭代器进行遍历的速度很快，并且不会与其他线程发生冲突。在构造迭代器时，迭代器依赖于不变的数组快照。迭代器支持hasNext()、next() 等不可变操作，但不支持可变 remove() 等操作；\n通常需要复制整个基础数组，所以可变操作（add()、set() 和 remove() 等等）的开销很大。\n适用于：Set 大小通常保持很小，只读操作远多于可变操作，需要在遍历期间防止线程间的冲突。\n\nVector _遗留类_：类似于 ArrayList，支持同步，线程安全。\nStack _遗留类_：继承自 Vector，也支持同步，提供了更多的的方法：\n\npush、pop；\npeek：得到栈顶元素；\nempty：判断是否为空；\nsearch：检测一个元素的位置。\n\nQueue 接口支持队列的一般性质：先进先出，头部出队，尾部入队，etc. \n实现 Queue 接口的常用类有：\n非线程安全版本 QueueLinkedList见上述。\nPriorityQueue保存队列元素的顺序并不是按照加入队列的顺序，而是 按照队列元素的大小进行重新排序。所以调用 peek() 或 poll() 的方法取出队列中的元素通常都是最小的元素。其扩展的是 AbstractQueue 接口，而 AbstractQueue 接口 扩展了 Queue 接口。一些方法：\n\npeek：取出队列头元素，但不删除之；\npull：取出并删除队列头元素。\n\n线程安全版本 QueueConcurrentLinkedQueueMap 接口用于存储键值对结构对象。\n实现 Map 接口的常用类有：\n非线程安全版本 MapHashMap基于散列表实现。非同步的，非线程安全；键值都允许有 null 值；\nLinkedHashMap继承自 HashMap。\nTreeMap基于红黑树实现。\n线程安全版本 MapConcurrentHashMapJDK 1.5 新增的 Map 接口实现，可以看作 HashMap 的线程安全版本，提供更好的扩展性，用以替代 HashTable。\nConcurrentSkipListMapJDK 1.6 新增的 Map 接口实现，基于跳表实现（Skip list，一种可以代替平衡树的数据结构）。可以看作 TreeMap 的线程安全版本。但实现上有所不同。\nHashTable 遗留类同步的，保证线程安全，其他入操作等几乎等同于 HashMap。由于同步的原因，单线程环境下效率不高，此时应使用 HashMap。\nString 相关String 也可以看作是容器的一种。StringBuilder 非线程安全，StringBuffer 线程安全。\n","categories":["java"],"tags":["java","容器"]},{"title":"Redis","url":"/2018/05/30/ING/Redis/","content":"[toc]remote dictionary server, redis, 是一个开源的内存中的数据结构存储系统，它可以用作：数据库、缓存和消息中间件。采用 单进程单线程 方式运行。Redis 支持多种类型的数据结构，如字符串（Strings），散列（Hash），列表（List），集合（Set），有序集合（Sorted Set或者是ZSet）与范围查询，Bitmaps，Hyperloglogs 和地理空间（Geospatial）索引半径查询。其中常见的数据结构类型有：String、List、Set、Hash、ZSet这5种。redis 教程\n查询速度Redis 采用基于内存的、单进程单线程模型的 KV 数据库，由 C 语言编写。官方提供的数据是可以达到 100000+ 的 QPS（每秒内查询次数）。\n高效查询的原因\n纯内存操作，绝大部分请求是纯粹的内存操作，非常快速。数据存在内存中，类似于 HashMap，HashMap 的优势就是查找和操作的时间复杂度都是O(1)；\n数据结构简单，对数据操作也简单，Redis 中的数据结构是专门进行设计的；\n采用单线程，避免了不必要的上下文切换和竞争条件，也不存在多进程或者多线程导致的切换而消耗 CPU，不用去考虑各种锁的问题，不存在加锁释放锁操作，没有因为可能出现死锁而导致的性能消耗；\n使用多路 I&#x2F;O 复用模型，非阻塞 IO；\n底层模型不同，Redis 直接构建了专用的 VM 机制，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求。\n\n单线程的问题首先要明确，这里单线程是指，Redis 只使用一个线程来处理网络请求，而一个 Redis Server 处于运行状态时还是有多个线程的，比如用于持久化的子线程&#x2F;子进程。此外，进入 4.0 版本后，某些操作上开始支持多线程执行，不排除后续版本将整个服务都采用多线程的可能。显然，单线程无法发挥多核的优势，通常在单机开启多个 Redis 实例以充分利用多核环境资源。为什么说Redis是单线程的\n基于 Key-Value 的 NoSQL 内存数据库也称数据结构服务器。特点和优势：\n\n支持数据的持久化，可以将内存中的数据持久化到磁盘中，重启时再次加载使用；\n不仅支持简单的 key-value 类型数据，同时还提供 list、set、zset、hash 等数据结构的存储；\n支持数据备份，即 master-slave 模式的数据备份；\n性能极高：读的速度是110000次&#x2F;s,写的速度是81000次&#x2F;s；\n丰富的数据类型，提供了5种数据结构：String、List、Hash、Set、Ordered Set（ZSet）；\n原子操作：Redis 的所有操作都是原子性的，同时还支持对几个操作全并后的原子性执行；\n丰富的特性：支持 publish&#x2F;subscribe、通知 key 过期等特性。\n\n数据结构\n\nstring类似于其他编程语言中字符串的概念。redis 中的 string 类型是二进制安全的，i.e. 可以包含任何数据，比如一张 .jpg 格式的图片。一个键最大存储量为 512 MB。\n\n\nlist按照插入顺序有序存储多个字符串，相同元素可重复，双向操作（LPHSH、LPOP、RPUSH、RPOP）。每个 list 最多存储元素数量：2^32 - 1。\n\n\nset集合和列表都可以存储多个字符串，不同之处在于：列表可以存储多个相同的字符串，集合通过 散列表来保证存储的每个字符串都是不相同的。redis 的集合使用无序（unordered）方式存储元素，不支持像列表一样将元素从某一端 push&#x2F;pop 的操作，相应地，使用 SADD&#x2F;SREM 添加&#x2F;移除元素。由于是通过哈希表实现的，所以添加&#x2F;移除&#x2F;查找的时间复杂度为 O(1)。每个 set 最多存储元素数量：2^32 - 1。\n\n\nhash可以存储多个键值对之间的映射。官方推荐：尽可能使用hash存储数据。每个 hash 最多存储键值对数量：2^32 - 1。\n\n\nzset有序集合（zset）和散列一样，都用于存储键值对，不支持重复元素。不同之处在于：有序集合的键被称为成员（member），每个成员都是各不相同的；值被称为分值（score），必须为浮点数（分值可重复）。zset 既可以根据成员访问元素（和散列一样），又可以根据分值以及分值的排列顺序来访问元素的结构。每个 zset 最多存储键值对数量：2^32 - 1。\nuse case作为分布式锁分布式锁至少要满足三个属性要求：  \n\n安全方面（Safety property）：互斥。在任一时刻，只有一个client可以获取锁；\n活性A（Liveness property）：无死锁。即便持有锁的client崩溃（crashed)或者网络被分裂（gets partitioned)，锁仍然可以被获取；\n活性B（Liveness property）：容错。只要多数Redis节点活着，client就可以获取和释放锁。\n\n参见 redlock\n作为LRU缓存redis提供多种key淘汰机制：  \n\nnoeviction: 不淘汰，当超过内存限制，抛出异常；\nallkeys-lru: 在所有键中，选取最近最少使用的数据抛弃；\nvolatile-lru: 在设置了过期时间的所有键中，选取最近最少使用的数据抛弃；\nallkeys-random: 在所有键中，随机抛弃；\nvolatile-random: 在设置了过期时间的所有键中，随机抛弃；\nvolatile-ttl: 在设置了过期时间的所有键中，抛弃存活时间最短的数据；4.0 新增：\nallkeys-lfu: 在所有键中，选取使用频率最少的数据抛弃；\nvolatile-lfu: 在设置了过期时间的所有键中，选取使用频率最少的数据抛弃；\n\nPersistenceredis提供不同的持久化选项：  \n\nRDB: 在指定的时间间隔内将内存中的数据集快照写入磁盘；\nAOF(append only file): 将server接收到的每个操作日志以追加的方式写入文件；\n\n多线程6.0版本开始支持多线程。\n","categories":["backend"],"tags":["backend","DB"]},{"title":"容器-vector","url":"/2018/05/29/cpp/STL/%E5%AE%B9%E5%99%A8-vector/","content":"vectorvector是STL序列式容器的一种，动态可变大小数组，基于数组实现，支持快速随机访问，但在尾部之外的位置插入&#x2F;删除元素可能很慢（C++ primer）。与array十分相似，差别在于空间运用的灵活性，vector使用动态空间，随着元素的加入，内部可以自行扩充空间以容纳新元素。实现中的技术在于 对大小的控制和重新配置时的数据移动效率。\n容量变化在C++ 标准中，并没有规定 vector::push_back() 要用哪一个增长因子。这是由标准库的实现者决定的。经测试发现，VS 环境下是1.5倍增长，而 Linux 下使用编译运行发现，是2倍率增长。可以用 reserve() 函数指定初始容量。增长包括重新分配内存空间、拷贝原空间、释放原空间三个过程，具体策略为当添加元素时，如果 vector 空间大小不足，则会以原大小的1.5倍另外配置一块较大的新空间，然后将原空间内容拷贝过来，在新空间的内容末尾添加元素，并释放原空间。也就是说 vector 的空间动态增加大小，并不是在原空间之后的相邻地址增加新空间，因为 vector 的空间是线性连续分配的，不能保证原空间之后有可供配置的空间。\n\n空的 vector 对象，size() 和 capacity() 都为0;\n当空间大小不足时，新分配的空间大小为原空间大小的2倍;\n使用 reserve() 预先分配一块内存后，在空间未满的情况下，不会引起重新分配，从而提升了效率;\n当 reserve() 分配的空间比原空间小时，是不会引起重新分配的;\nresize() 函数只改变容器的元素数目，未改变容器大小。\n\n为什么是成倍增长，而不是每次增长一个固定大小的容量？如果以成倍方式增长，假定有n个元素，倍增因子为m：完成n个元素的push_back操作需要重新分配内存的次数约为 logm(n)，第i次重新分配会导致 m^(i) 次复制，也就是当前的 vector.size() 大小，n 次 push_back 操作所花费的时间复杂度为 O(n)，如下：\n\n可知，每次 push_back 耗时均摊为 O(1) 的时间复杂度。相应地，如果以固定大小方式增长，假定有n个元素，每次增加k个，第i次增加复制的数量为为 ki；n 次 push_back  操作所花费的时间复杂度为 O(n^2)，均摊下来每次 push_back 操作的时间复杂度为 O(n)：\n\n\n对比可见采用采用成倍方式扩容，可以保证常数的时间复杂度，而增加指定大小的容量只能达到 O(n) 的时间复杂度，因此，使用成倍的方式扩容。\n为什么是以2倍或者1.5倍增长，其他行不行？《算法导论》中关于摊还分析显示，这是一种 空间和时间的权衡：空间分配的多，平摊时间复杂度低，但浪费空间也多。使用 k&#x3D;2 增长因子的问题在于，每次扩展的新尺寸必然刚好大于之前分配的总和：\n\n也就是说，之前分配的内存空间不可能被使用。这样对于缓存并不友好。最好把增长因子设为 1 &lt; k &lt; 2，例如 Folly 采用 1.5，RapidJSON 也是跟随采用 1.5：\n\n可以看到，k &#x3D; 1.5 在几次扩展之后，可以重用之前的内存空间。\n插入&#x2F;删除效率由于是顺序容器，其插入&#x2F;删除操作有移动元素的过程，故时间复杂度为 O(n)。\n","categories":["cpp"],"tags":["cpp","容器"]},{"title":"List","url":"/2018/05/28/java/Container/List/","content":"[toc]\nList 接口List 接口中的元素是有序的、可重复的、可以为 null 的集合（序列）。提供以下功能方法：\n\n位置相关：List 和 数组一样，都是从 0 开始，可以根据元素在 list 中的位置进行操作，比如说 get, set, add, addAll, remove;\n搜索：从 list 中查找某个对象的位置，比如 indexOf, lastIndexOf;\n迭代：使用 Iterator 的拓展版迭代器 ListIterator 进行迭代操作;\n范围性操作：使用 subList 方法对 list 进行任意范围的操作。\n\nList 相关类包括非线程安全的 ArrayList、LinkedList，线程安全的 CopyOnWriteArrayList，线程安全但目前已不推荐使用的 Vector 和其子类 Stack。\nArrayList 非线程安全的动态数组使用连续内存空间，容量动态增长。行为类似于 Arrays，但只能存放对象类型，而不能像 Arrays 可以支持基本数据类型。其类定义如下：\njava.lang.Object\n   ↳     java.util.AbstractCollection&lt;E>\n         ↳     java.util.AbstractList&lt;E>\n               ↳     java.util.ArrayList&lt;E>\npublic class ArrayList&lt;E> extends AbstractList&lt;E>\n        implements List&lt;E>, RandomAccess, Cloneable, java.io.Serializable &#123;&#125;\n可见，其继承了 AbstractList 虚类，扩展了 List、RandomAccess、Cloneable、Serializable 4 个接口。显然，首先它是一个队列，并且支持 随机访问元素 和 序列化。i.e. 擅长随机读取元素，但在中间插入&#x2F;移除元素比较慢。\n内存分配及扩容策略默认的初始容量（DEFAULT_CAPACITY）为 10，默认增长方式为 1.5 倍率扩容：\n\n申请新的连续内存空间；\n将数据拷贝到新内存区域。\n\nArrayList 在执行 remove 相关方法后，并不会收缩容量，即，容量只会扩增。最终不用时进入 GC。\n三种遍历元素的方式索引（for 循环）由于扩展了 RandomAccess 接口，有实例方法 arrayList.size()，可以获取元素数量，并且，list 接口的子类都按插入顺序排列元素，i.e. 可以以插入顺序取得所有元素，支持类似下标的索引操作：\nfor(int i = 0; i &lt; arrayList.size(); i++)\n   System.out.print(arrayList.get(i) + \" \");\n\n迭代器对于 List、String 等类型，由于实现了 Iterator 接口（事实上是实现了 Iterable 接口），需要保证要遍历的对象非空，判断是否还有下一个元素：\nIterator&lt;Integer> it = arrayList.iterator();\nwhile(it.hasNext()) \n    System.out.print(it.next() + \" \");\n\nforeach是的，它是一种语法糖实现：对于 List 类型，它们能使用 foreach 的基础是因为实现了 Iterator 接口。即，javac 会将这种遍历展开成迭代器遍历：\nfor(Integer number : arrayList)\n   System.out.print(number + \" \");\n\n注意，效率方面：索引（for 循环）遍历是最高的（也要根据元素的数据类型具体分析，并非绝对），而另外两种本质上是一样的，并不好作判断。至于 for 循环遍历的效率高，主要原因是 RandomAccess 接口的功劳，其描述文档中有：\n\n\n可以看出，RandomAccess 接口带来的优势：\n\n可以快速随机访问集合；\n使用快速随机访问（for 循环）效率可以高于 Iterator。\n\nLinkedList 双向链表public class LinkedList&lt;E> extends AbstractSequentialList&lt;E>\n    implements List&lt;E>, Deque&lt;E>, Cloneable, java.io.Serializable &#123;&#125;\nLinkedList 与 ArrayList 一样实现了 List 接口。不同在于 ArrayList 是 List 接口的大小可变数组的实现，LinkedList 是 List 接口链表的实现。基于链表实现的方式使得 LinkedList 在插入和删除时更优于 ArrayList，而随机访问则比 ArrayList 逊色些。同时实现了 Deque 接口，所以可以提供双向队列的典型方法：pop、peek、push 等。\n方法get、set既然实现了 List 接口，也就能够进行类似下标访问的 get、set 等方法。实际原理非常简单，它就是通过一个计数索引值来实现的。如，当调用 get(int location) 时，首先会比较“location”和“双向链表长度的1&#x2F;2”；若前者大，则从链表头开始往后查找，直到 location 位置；否则，从链表末尾开始先前查找，直到 location 位置。\nDeque 接口提供的方法包括 push()、peek*()、poll*()、pop() 等。\nCopyOnWriteArrayList 线程安全的 ArrayListJDK1.5 新增数据结构，使用 COW 实现的线程安全数组。doc 简介：A thread-safe variant of ArrayList in which all mutative operations (add, set, and so on) are implemented by making a fresh copy of the underlying array.i.e. 所有可变操作都是对底层数组进行一次新的复制实现的。其类定义如下：\npackage java.util.concurrent;\npublic class CopyOnWriteArrayList&lt;E>\n    implements List&lt;E>, RandomAccess, Cloneable, java.io.Serializable &#123;&#125;\n\n具体线程安全保证见 COW 技术实现。\nVector 线程安全的动态数组其类定义如下：\njava.lang.Object\n   ↳     java.util.AbstractCollection&lt;E>\n         ↳     java.util.AbstractList&lt;E>\n               ↳     java.util.Vector&lt;E>\npublic class Vector&lt;E> extends AbstractList&lt;E>\n    implements List&lt;E>, RandomAccess, Cloneable, java.io.Serializable &#123;&#125;\n\n整体上，Vector 可以看作线程安全版本的 ArrayList，但两者有些区别：\n\nVector 是同步访问的；\nVector 包含了许多传统的方法，这些方法不属于集合框架。\n\n线程安全保证大量方法使用 synchronized 关键字修饰，以加锁的方式确保线程安全。\n内存分配及扩容策略默认的初始容量（DEFAULT_CAPACITY）为 10， 默认增长方式为 2 倍率扩容：\n\n申请新的连续内存空间；\n将数据拷贝到新内存区域。\n\n四种遍历元素的方式相比于 ArrayList，多出了一种 Enumeration 遍历方式：这就是上述的“传统方法”之一，也是目前不再推荐使用 Vector 等一些老旧的类的原因。\nInteger value = null;\nEnumeration enu = vec.elements();\nwhile (enu.hasMoreElements()) &#123;\n    value = (Integer)enu.nextElement();\n&#125;\n四种遍历方式的效率也和 ArrayList 类似，for 循环最快。\n为什么不再推荐使用？根据以下的解释，通常我们是想同步整个序列，而提供的方法是同步单个操作，这并不安全，仍然需要获得一个锁来避免并发修改，并且其方法的效率较低。https://stackoverflow.com/questions/1386275/why-is-java-vector-and-stack-class-considered-obsolete-or-deprecated\nStack 继承自 Vector 的栈实现其源码实现比较简单，栈的几个典型方法通过对 Vector 的一些方法修改得到。也是线程安全的。\n","categories":["java"],"tags":["java","容器"]},{"title":"类文件结构","url":"/2018/05/27/java/JVM/%E7%B1%BB%E6%96%87%E4%BB%B6%E7%BB%93%E6%9E%84/","content":"[toc]\n类文件结构各种不同平台的 VM 与所有平台统一使用的程序存储格式——字节码（ByteCode）是构成平台无关性的基石。然而，VM 的目标显然不止于平台无关，其语言无关性也同样在发展：目前已经有 Groovy、Jython、JRuby、Scala 等语言同样能够运行在 JVM 上。而实现语言无关性的基础仍然是 VM 和字节码存储格式。JVM 不和包括 java 在内的任何语言绑定，它只和“class 文件”这种特定格式的二进制文件格式所关联，其中包含了 JVM 指令集和符号表以及若干其他辅助信息。任何其他语言同样可以使用合适的编译器将其代码编译为 class 文件从而在 JVM 上执行，JVM 本身不关心 class 文件来源于何种语言——只要该 class 文件符合 jvms 的语法和结构化约束即可。字节码所能提供的语义描述能力强于 java 语言。\nclass 类文件的结构&#x2F;字节码\n\n以 8-byte 为单位紧凑排列，大端字节序方式，不含任何分隔符，格式是严格定义的：数据项顺序、数量，字节序，哪个字节代表什么含义等等，都不允许改变。文件格式采用类似于 C 语言结构体的伪结构，只含有两种数据类型：无符号数和表。\n\n无符号数：基本数据类型，以 u1、u2、u4、u8 表示 1&#x2F;2&#x2F;4&#x2F;8 个字节的无符号数。可以用来描述数字、索引引用、数量值或按照 UTF-8 编码构成字符串值；\n表是由多个无符号数或其他表作为数据项构成的复合数据类型。所有表习惯性以“_info”结尾。用于描述有层次关系的复合结构的数据。整个 class 文件本质上就是一张表。数据项：\n无论是无符号数还是表，当需要描述同一类型但数量不定的多个数据时，经常使用一个前置的容量计数器加若干个连续的数据项的形式，这时称这一系列连续的某一类型的数据为某一类型的集合。\n\n魔数与 class 文件版本每个 class 文件前 4 个字节称为魔数（Magic Number），唯一作用是确定该文件是不是一个能被 JVM 接受的 class 文件。_很多文件存储标准中都是用魔数进行身份识别，如图片格式（gif、jpeg等都在头文件中存有魔数），魔数值可以由文件制定者自由选取，但要避免引起混淆_。使用魔数而非扩展名是基于安全性方面的考虑：扩展名可随意改动。class 文件的魔数值为：0xCAFEBABE（咖啡宝贝？），这个值在 java 还称作“Oak”语言的时候（1991年前后）就已经确定下来了。紧接着魔数的 4 个字节存储的是 class 文件的版本号：56 字节是次版本号（Minor Version），78 字节是主版本号（Major Version）。Java 的版本号是从 45 开始的（JDK 1.xxx 为 45.xxx，而 JDK 1.8 为 52.xxx），JDK 1.1 之后的每个 JDK 大版本发布时，主版本号向上 +1（JDK 1.01.1 使用了 45.045.3 的版本号），高版本的 JDK 能向下兼容以前版本的 class 文件，但不能运行以后版本的 class 文件，即使文件格式未发生任何变化，JVM 也必须拒绝执行超过其版本号的 class 文件。\n常量池（Constant Pool）紧接着主次版本号之后的是常量池入口，常量池可以理解为 class 文件中的资源仓库，是 class 文件结构中与其他项目关联最多的数据类型，也是占用 class 文件空间最大的数据项之一，也是 class 文件中第一个出现的表类型数据项目。与 java 语言习惯不一样的是，常量池的容量计数器是从 1 而不是 0 开始的：为了满足某些索引在特定情况下需要表达“不引用任何一个常量池项目”的含义时，可以将索引值置 0。故总数量为 计数器值 - 1。class 文件中只有常量池的容量计数器是从 1 开始的。常量池主要存放两大类常量：\n\n字面量（Literal）：接近于 java 语言层面的常量概念，如文本字符串、声明为 final 的常量值等；\n符号引用（Symbolic References）：属于编译原理方面的概念，包含以下 3 类常量：\n类和接口的全限定名（Fully Qualified Name）字段的名称和描述符（Descriptor）方法的名称和描述符\n\n\n\nclass 文件中不保存各个方法、字段的内存布局信息，当 JVM 运行时，需要从常量池获取对应的符号引用，再在类创建时或运行时解析、翻译到具体的内存地址中。\n常量池中每一项常量都是一个表。目前（JDK1.8)共有 14 种结构各异的表数据结构（有 3 种新增于 JDK1.7，为更好地支持动态语言调用）。\n\n这 14 种 表都有一个共同特点：起始位置的 u1 标志位，代表当前这个常量属于哪种常量类型。每种常量项目的结构表如下：\n\n\n访问标志（Access flags）常量池结束之后，紧接着的是 2 字节的访问标志，用于识别一些类或者接口层次的访问信息，包括：这个 Class 是类还是接口；是否定义为 public 类型；是否定义为 abstract 类型；如果是类的话，是否被声明为 final 等。当前已使用了 8 位，其余位置 0：\n\n\n类索引 父类索引 接口索引集合类索引（this_class）、父类索引（super_class）是 2 字节，各自指向一个类型为 CONSTANT_Class_info 的类描述符常量；接口索引集合（interfaces）是一组 2 字节类型的数据的集合，入口是 u2 类型的接口计数器，如果该类没有实现任何接口，则置 0，后面的接口索引表不再占用任何字节。这 3 项数据用来确定这个类的继承关系：\n\n类索引：确定该类的全限定名；\n父类索引：确定该类的父类的全限定名（java 不允许多继承，故只有一个，除了 Object 类，其余都有父类）；\n接口索引集合：描述该类实现了哪些接口，按 implements（如果这个类本身是接口，则是 extends）语句后的接口顺序排列。\n\n字段表（field_info）集合用于描述接口&#x2F;类中声明的变量。字段包括类级变量和实例级变量，但不包括在方法内部声明的局部变量。一个字段可以包括的信息有：字段的作用域（public、private、protected），实例变量还是类变量（static），可变性（final），并发可见性（volatile，是否强制从主内存读写），可否被序列化（transient），字段数据类型（基本类型、对象、数组）、字段名称。字段表结构如下：\n\n\n其中，字段访问标志（access_flags） 与类中的 access_flags 类似：\n\n\n跟随在 access_flags 的是两项索引值：name_index 和 descriptor_index，它们是对常量池的引用，分别代表着字段的简单名称、字段和方法的描述符。\nHelloWorld.javapackage io.neil.hust;\npublic class HelloWorld &#123;\n    private String str = \"Hello, World\";\n    public void sayHello(String str) &#123;\n        System.out.println(str);\n    &#125;\n&#125;\n\n全限定名：“io&#x2F;neil&#x2F;hust&#x2F;HelloWorld”是”HelloWorld”类的全限定名（仅仅是把类全名“io.neil.hust.HelloWorld”的“.”换成了“&#x2F;”）；\n简单名称：没有类型和参数修饰的方法或字段名称：sayHello()方法和 str 字段的简单名分别为“sayHello”和“str”；\n字段和方法的描述符：描述字段的数据类型、方法的参数列表（数量、类型、顺序）和返回值。其标识字符含义如下：\n\n字段表都包含的固定数据项目到descriptor_index为止，之后跟随一个 属性表(attribute_info)集合 用于存储一些额外的信息，字段都可以在属性表中描述零至多项的额外信息。\n字段表集合中不会列出从超类或者父接口中继承而来的字段，但有可能列出原本Java代码之中不存在的字段，譬如在内部类中为了保持对外部类的访问性，会自动添加指向外部类实例的字段。另外，在Java语言中字段是无法重载的，两个字段的数据类型、修饰符不管是否相同，都必须使用不一样的名称，但是对于字节码来讲，如果两个字段的描述符不一致，那字段重名就是合法的。\n方法表（method_info）集合class 文件格式对方法的描述和对字段的描述几乎完全一致，仅在访问标志和属性表集合的可选项中有所区别。方法表访问标志\n\n\n属性表（attribute_info）集合class 文件、字段表、方法表都可以携带自己的属性表集合，用以描述某些场景专有的信息。与 class 文件中其他数据项要求严格的顺序、长度和内容不同，属性表集合的限制稍微宽松：不要求各个属性表之间遵循严格顺序，只要不和已有属性名重复，任何自定义编译器都可以自定义属性信息。而 JVM 运行时会忽略它不认识的属性。为了能正确解析 class 文件，jvms 7 预定义了 21 项属性（目前的 jvms 10 为 26 项），这里以 jvms 10 为例。\n\n\n对每个属性，它的名称需要从常量池中引用一个 CONSTANT_uTF8_info 类型的常量来表示，而属性值的结构则完全是自定义的，只需要通过一个 u4 的长度属性说明所占用的位数即可：\n\n\n介绍几个重要的属性。Code 属性java 程序方法体中的代码经过 javac 编译器处理后，最终变为字节码指令存储在 Code 属性内，Code 属性出现在方法表的属性集合中，但并非所有方法都必须存在这个属性：接口&#x2F;抽象类的方法可能就不存在。{Code 属性表结构}详见《深入理解java虚拟机》\n字节码指令JVM 采用面向操作数栈而不是寄存器的架构。\nclass 文件格式所具备的平台独立特性和可动态扩展，是 java 技术体系实现平台无关、语言无关的重要支柱。\n","categories":["java"],"tags":["java","JVM"]},{"title":"java-synchronized","url":"/2018/05/26/java/Thread/synchronized/","content":"[toc]\n线程安全的实现方式之一。\n隐式锁synchronized 采用的是 CPU 悲观锁机制，即线程获得的是独占锁，是一种隐式锁实现：隐式地声明一个锁，所有线程必须获得该锁，才能进入该锁保护的代码段进行操作，只有在对象锁是共享且唯一时才会起到同步作用。一方面，该关键字实现原子性或者确定“临界区”，另一方面，保证状态修改的“内存可见性”。synchronized 关键字默认是不被继承的，即子类并不会继承父类的这种方式的同步声明。\n作用对象java 中每个对象都可以作为同步对象，Object 类中有 wait() 和 notify() 方法，它们必须用在被 synchronized 同步的 Object 的临界区内。通过 wait() 可以使得处于临界区内的线程进入阻塞状态，同时释放被同步对象的控制权，而 notify() 可以唤醒一个因调用了 wait() 而处于阻塞状态中的线程，使其进入就绪状态。被重新换醒的线程会试图重新获得临界区的控制权，并继续执行临界区内 wait() 之后面的代码。如果发出 notify() 时没有处于阻塞状态中的线程,那么该信号会被忽略。\n\n对于普通同步方法，锁是当前实例对象；\n对于静态同步方法，锁是当前类的 Class 对象；\n对于同步方法块，锁是 Synchronized 括号中配置的对象。\n\n使用方式当一个线程试图访问同步代码块时，它首先必须得到锁，退出或抛出异常时必须释放锁。有两种使用方式：\n\n同步方法：// 如下形式，获取 this 对象的内置锁：\n// public synchronized methodName (参数)&#123;临界区&#125;\npublic synchronized void myMethod()&#123;\n    try &#123;\n        // todo sth.\n    &#125; catch (InterruptedException e) &#123;\n        e.printStackTrace();\n    &#125;\n&#125;\n同步语句块:// 如下形式，获取“对象名”对象的内置锁：\n// synchronized (对象名)&#123;临界区&#125;\npublic void myMethod()&#123;\n    try &#123;\n        // todo sth.\n    &#125; catch (InterruptedException e) &#123;\n        e.printStackTrace();\n    &#125;\n    synchronized (object) &#123;\n        // todo sth.\n    &#125;\n&#125;\n作用效果\n当一个线程正在访问一个对象的 synchronized 方法，那么其他线程不能访问该对象的所有 synchronized 方法：一个对象只有一把锁，当一个线程获取了该对象的锁之后，其他线程无法获取该对象的锁，所以无法访问该对象的 synchronized 方法；\n当一个线程正在访问一个对象的 synchronized 方法，那么其他线程能访问该对象的非 synchronized 方法：也很好理解，访问非 synchronized 方法不需要获得该对象的锁，假如一个方法没用 synchronized 关键字修饰，说明它不会使用到临界资源，即不存在线程安全性问题，那么其他线程是可以访问这个方法的。\n\n二者区别首先要明确的是：无论 synchronized 加在方法上还是语句块上，它取得的都是对象的内置锁，即锁住的都是对象，而不是把一个方法或者一段代码当做锁。其次如上描述，同步方法是对当前对象进行加锁（获取其内置锁），而同步语句块是对某一个对象（synchronized (对象)）进行加锁。使用同步方法在某些情况下是有弊端的：如果一个线程调用该方法执行一个长时间任务，那么其他线程要想调用这个方法就必须等待较长时间，此时可以考虑将同步缩小范围，放在方法中的具体语句块中。此外，同步是一种高开销的操作，因此应该尽量减少同步的内容。通常没有必要同步整个方法，使用同步语句块锁定关键代码即可。更具体的解释：synchronized 同步方法：\n\n对其他 synchronized 同步方法或 synchronized(this)同步代码块调用呈阻塞状态；\n同一时间只有一个线程可以执行 synchronized 同步方法中的代码；synchronized(this) 同步代码块\n对其他 synchronized 同步方法或 synchronized(this)同步代码块调用呈阻塞状态；\n同一时间只有一个线程可以执行 synchronized(this)同步代码块中的代码；synchronized(非 this 对象 x)\n在多个线程持有”对象监视器”为同一对象的前提下，同一时间只有一个线程可以执行 synchronized(非 this 对象 x)同步代码块中的代码；\n当持有”对象监视器”为同一对象的前提下，同一时间只有一个线程可以执行 synchronized(非 this 对象 x)同步代码块中的代码。可以理解为，当不同的对象 x 被传入到同步语句块时，线程可以同步进行而不会相互干扰。\n\n类锁 对象锁我们知道，每个类对象和实例对象，都会逻辑上和一个监视器相关联，实例对象的监视器保护对象的实例变量（非静态那些变量、方法），而这里的“类对象”，是说，jvm 在加载一个 .class 文件到（方法去）内存中之后，就会针对该文件生成一个 java.lang.Class 对象，也就是所谓的类对象，即，类被加载后，也被当做一个对象来看待，所以，对类加锁（也就是对静态字段），实际上锁住的就是类对象（无论如何，锁住的都是一个对象，也就是说类锁仍然是个对象锁），有别于类的实例对象。修饰非静态方法时，实际上是对调用该方法的对象加锁，即“对象锁”；而修饰静态方法时，实际上时对该类对象加锁，即“类锁”，所有调用静态方法的对象都会呈现出同步的效果。以下情况：\n\n用类直接在两个线程中调用两个不同的同步方法（即静态方法）：会产生互斥，因为对静态对象加锁实际上是对类（.class）加锁，类对象只有一个，可以理解为任何时候都只有一个空间，里面有 N 房间，只有空间上的一把锁，因此房间（同步方法）之间是互斥的。\n用一个类的静态对象在两个线程中调用静态方法和&#x2F;或非静态方法：会产生互斥，因为是同一个对象上的调用。\n一个对象在两个线程上分别调用一个静态同步方法和一个非静态同步方法：不会产生互斥，因为两个方法的锁类型不同，一个是对象锁，一个是类锁，可以并发执行。\n\n获取类锁方法之一是使用类似同步语句块的声明，区别是参数：\npublic void myMethod()&#123;\n    try &#123;\n        // todo sth.\n    &#125; catch (InterruptedException e) &#123;\n        e.printStackTrace();\n    &#125;\n    // 这里参数不是某对象，而是类对象\n    synchronized (className.class) &#123;\n        // todo sth.\n    &#125;\n&#125;\n线程在获取类锁之后，仍然可以获取该类的实例对象的锁（对象锁），因为二者并不是“同一个锁”。\n优化从 JDK1.6 开始，synchronized 可以有很多优化：有适应自旋、锁粗化、锁消除、偏向锁、轻量级锁等，以减少获得&#x2F;释放锁带来的性能消耗，性能上有很大提升。所以目前共有 4 种锁状态，级别从低到高：无锁状态、偏向锁状态、轻量级锁状态、重量级锁状态。这几个状态会随着竞争情况的加剧而逐渐升级，但不可以降级：目的是为了提高获得锁和释放锁的效率。\n锁粗化（Lock Coarsening）将多次连接在一起的加锁、解锁操作合并为一次，将多个连续的锁扩展成一个范围更大的锁。\npublic class StringBufferTest &#123;\n    StringBuffer stringBuffer = new StringBuffer();\n    public void append()&#123;\n        stringBuffer.append(\"a\");\n        stringBuffer.append(\"b\");\n        stringBuffer.append(\"c\");\n    &#125;\n&#125;\n如果这里每次调用 stringBuffer.append 方法都需要加锁和解锁，如果虚拟机检测到有一系列连串的对同一个对象加锁和解锁操作，就会将其合并成一次范围更大的加锁和解锁操作，即在第一次 append 方法时进行加锁，最后一次 append 方法结束后进行解锁。\n锁消除（Lock Elimination）删除不必要的加锁操作。根据代码逃逸技术，如果 jvm 判断出一段代码中，堆上的数据不会逃逸出当前线程，那么可以认为这段代码是线程安全的，也就无需加锁。\n轻级量锁“轻量”是相对于使用 OS 互斥量来实现的传统锁而言的，它并非用来代替重量级锁，而是在没有多线程竞争的前提下，减少传统的重量级锁的使用产生的性能消耗。使用场景是线程交替执行同步块的情况，如果存在同一时间访问同一锁的情况，就会导致轻量锁升级为重量级锁。\n轻量级锁加锁过程\n代码进入同步块时，如果同步对象锁状态为无锁状态（锁标志位为“01”状态，是否为偏向锁为“0”），jvm 首先将在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的 Mark Word 的拷贝，官方称之为 Displaced Mark Word；\n拷贝对象头中的 Mark Word 复制到锁记录中；\njvm 将使用 CAS 操作尝试将对象的 Mark Word 更新为指向 Lock Record 的指针，并将 Lock record 里的owner 指针指向 object mark word。如果更新成功，则执行步骤（4），否则执行步骤（5）；\n更新操作成功，这个线程拥有该对象的锁，并且对象 Mark Word 的锁标志位设置为“00”，即此对象处于轻量级锁定状态；\n更新操作失败，jvm 首先会检查对象的 Mark Word 是否指向当前线程的栈帧，如果是就说明当前线程已经拥有了这个对象的锁，那就可以直接进入同步块继续执行。否则说明多个线程竞争锁，轻量级锁升级为重量级锁，锁标志的状态值变为“10”，Mark Word 中存储的就是指向重量级锁（互斥量）的指针，后面等待锁的线程也要进入阻塞状态。而当前线程便尝试使用自旋来获取锁，自旋就是为了不让线程阻塞，而采用循环去获取锁的过程。\n\n轻量级锁释放过程\n通过 CAS 操作尝试把线程中复制的 Displaced Mark Word 对象替换当前的Mark Word；\n如果替换成功，整个同步过程完成；\n如果替换失败，说明有其他线程尝试过获取该锁（此时锁已升级），需要在释放锁的同时，唤醒被挂起的线程。\n\n适应性自旋Adaptive Spinning，也称自旋锁。从轻量级锁获取的流程可见，当线程在获取轻量级锁的过程中执行 CAS 操作失败时，是要通过自旋来获取重量级锁的。但是，自旋需要消耗 CPU，如果一直获取不到锁的话，那该线程就一直处于自旋状态。解决这个问题最简单的方法就是指定自旋的次数，比如循环 10 次，如果还没有获取到锁就进入阻塞状态。JDK 采用的方法是“适应性自旋”：如果线程成功自旋（获得锁），则下次自旋的次数会更多，如果失败，自旋的次数会减少。\n偏向锁偏向锁的引入是为了在没有多线程竞争的情况下尽量减少不必要的轻量级锁执行，因为轻量级锁的获取&#x2F;释放依赖多次 CAS 原子指令，而偏向锁只需要在置换 ThreadID 的时候依赖一次 CAS 原子指令。可见，轻量级锁是 在线程交替执行同步块时提高性能，偏向锁是 在只有一个线程执行同步块时进一步提高性能。\n偏向锁获取过程\n访问 Mark Word 中偏向锁的标识是否设置成1，锁标志位是否为 01——确认为可偏向状态；\n如果为可偏向状态，则测试线程 ID 是否指向当前线程：如果是，进入步骤（5），否则进入步骤（3）；\n如果线程 ID 并未指向当前线程，则通过 CAS 操作竞争锁。如果竞争成功，则将 Mark Word 中线程 ID 设置为当前线程 ID，然后执行（5）；如果竞争失败，执行（4）；\n如果 CAS 获取偏向锁失败，则表示有竞争。当到达全局安全点（safepoint）时获得偏向锁的线程被挂起，偏向锁升级为轻量级锁，然后被阻塞在安全点的线程继续往下执行同步代码；\n行同步代码。\n\n偏向锁释放过程偏向锁只有遇到其他线程尝试竞争偏向锁时（上述获取过程的第4步），持有偏向锁的线程才会释放锁，线程不会主动去释放偏向锁。偏向锁的撤销，需要等待全局安全点（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，判断锁对象是否处于被锁定状态，撤销偏向锁后恢复到未锁定（标志位为“01”）或轻量级锁（标志位为“00”）的状态。\n锁转换重量级锁、轻量级锁和偏向锁之间的转换\n\n\n关于 java 对象头Synchronized 使用的锁存放在 java 对象头（Header）。HotSpot 的对象头包括两部分内容：第一部分是 Mark Word，存储对象自身的运行时数据，如 hashcode、GC 分代年龄、锁状态标志、线程持有的锁、偏向线程 ID、偏向时间戳等，其长度跟 jvm 位数相关（32-bit 64-bit）。对象头的另一部分是类型指针，即对象指向它的类元数据的指针，jvm 通过这个指针来确定这个对象是哪个类的实例。对象头部分是 8 字节的倍数（1 或 2 倍），因为 HotSpot 内存管理要求对象起始位置必须是 8 字节的整数倍（这也导致对象头后的实例数据部分可能会出现字节填充&#x2F;对齐）。\n\n\n其中 mark word 的状态随着锁标志位的变化如下（默认为无锁状态）：\n\n\n\n[参考]https://blog.csdn.net/lcc793385991/article/details/57551827https://blog.csdn.net/u010842515/article/details/65443084https://blog.csdn.net/zwan0518/article/details/8725704https://blog.csdn.net/zhoufanyang_china/article/details/54601311https://blog.csdn.net/u013142781/article/details/51697672\n","categories":["java"],"tags":["java","并发"]},{"title":"java-协程","url":"/2018/05/26/java/Thread/%E5%8D%8F%E7%A8%8B/","content":"[toc]\n协程在单线程里实现多任务的调度，并在单线程里维持多个任务间的切换。\n","categories":["java"],"tags":["java","并发"]},{"title":"常见问题-cpp","url":"/2018/05/23/QA/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98-cpp/","content":"[toc]\n内存segment fault程序出现“段错误” or “非法操作，该内存地址不能 read&#x2F;write”的错误，是典型的非法指针解引用造成的。当指针指向一个不允许访问（没有读写权限）的内存地址，而程序却试图利用指针读写该地址的时候，就会出现这个错误。在 windows&#x2F;linux 内存布局中，有些地址是始终不允许读写的，如 0 地址；一些地址一开始不允许读写，应用程序必须事先请求获取这些地址的读写权限；或者一些地址一开始并没有映射到实际的物理内存，应用程序必须事先请求将这些地址映射到实际的物理地址后才能自由访问。造成该错误最普遍的原因有：\n\n将指针初始化为 NULL，之后却没有给它一个合理的值就开始使用该指针；\n没有初始化栈上的指针，而指针的值一般会是随机数，之后直接开始使用指针。etc.\n\n空的类大小如果一个类 class 为空，或没有数据成员且没有虚函数成员，则 sizeof(class) &#x3D; 1，这是被编译器安插的一个 char，为了使这个类在内存中被分配一个地址。 \n复合类型（compound type）基于其他类型定义的类型，包括引用、指针等。\n理解“声明语句”一条声明语句由一个 基本数据类型（base type） 和紧随其后的一个 声明符（declarator）列表 组成。每个声明符命名了一个变量，并指定该变量为“与基本数据类型有关的某种类型”。\n指针void*含义是 指向未知类型对象的指针（i.e. 仍然是个指针）。在某些偏向底层的代码中，偶尔需要在不知道对象确切类型的情况下，仅通过对象在内存中的地址存储或传递对象，此时会用到 void。除了函数指针和指向类成员的指针，其他任意类型对象的指针都能被赋值给一个 void 类型的变量（包括一个 void* 赋值给另一个 void）。void 也能比较是否相等（地址），还能把 void* 显式转换成其他类型。而，编译器事实上并不知道 void* 所指的对象到底是什么类型，所以对它执行其他操作可能不太安全并且会引发编译器错误。所以要想使用 void*，必须把它显式转换成某一特定类型的指针。\n数据结构vector 容量变化经测试发现，VS 环境下是1.5倍增长，而 Linux 下使用编译运行发现，是2倍率增长。可以用 reserve()函数指定初始容量。增长包括重新分配内存空间、拷贝原空间、释放原空间三个过程，具体策略为当添加元素时，如果vector空间大小不足，则会以原大小的1.5倍另外配置一块较大的新空间，然后将原空间内容拷贝过来，在新空间的内容末尾添加元素，并释放原空间。也就是说vector的空间动态增加大小，并不是在原空间之后的相邻地址增加新空间，因为vector的空间是线性连续分配的，不能保证原空间之后有可供配置的空间。\n\n空的vector对象，size()和capacity()都为0;\n当空间大小不足时，新分配的空间大小为原空间大小的2倍;\n使用reserve()预先分配一块内存后，在空间未满的情况下，不会引起重新分配，从而提升了效率;\n当reserve()分配的空间比原空间小时，是不会引起重新分配的;\nresize()函数只改变容器的元素数目，未改变容器大小。\n\n重载不能重载的操作符有：\n.（点号）  成员选择\n.*  通过指向成员的指针访问成员\n::（域解析符）  \n?:（条件语句运算符）  \nsizeof（求字节运算符）\nalignof()  对象的对齐方式\ntypeid，static_cast，dynamic_cast，interpret_cast（类型转换符）\n\nOPODPlain Old Data。指 C 风格的 struct 结构体定义的数据结构，其中 struct 结构体中只能定义常规数据类型，不能含有自定义数据类型。\n","categories":["cpp"],"tags":["Q&A","cpp"]},{"title":"C++","url":"/2018/05/22/cpp/C++/","content":"[toc]\n","categories":["cpp"],"tags":["cpp"]},{"title":"C++ IO","url":"/2018/05/22/cpp/IO/","content":"[toc]\n流输入cincin &gt;&gt; para;忽略空格等不可见字符。这里重载的 &gt;&gt; 称为提取符，它按照目标对象的类型解析输入信息（即解析成 int、string 等），可连续使用。\n按行输入3 种方法：\n\ncin 成员函数 get();\ncin 成员函数 getline();\n定义在头文件 &lt;string&gt; 中的全局函数 getline();\n\n前两个函数有 3 个参数：\n\n指向字符缓冲区的指针，用于保存结果；\n缓冲区的大小，保证缓冲区不会溢出；\n结束字符，默认为 ‘\\n’。get() 和 getline() 的区别在于：当遇到输入流中的界定符（即结束符）时 get() 停止执行，但并不从输入流中提取界定符，此时，如果再次调用 get()，会再次遇到该界定符，从而立即返回而不会提取任何输入；getline() 则相反，它将从输入流中提取界定符，但仍然不会把界定符存储到结果缓冲区中。&lt;string&gt; 中定义的 getline() 不是其成员函数，而是在命名空间 std 中声明的独立函数。有两个非默认参数：输入流和 string 对象：将输入流提取到 string 对象，直到遇到第一个界定符（默认 ‘\\n’）并丢弃这个界定符，即，该界定符被取出，但不被放入 string 对象。\n\n文件输入","categories":["cpp"],"tags":["cpp"]},{"title":"关键字","url":"/2018/05/22/cpp/%E5%85%B3%E9%94%AE%E5%AD%97/","content":"[toc]\nexplicitexplicit 关键字用来修饰 类的构造函数，指明该构造函数不能用作隐式类型转换，而只能用于初始化和显式类型转换。多见于 单个参数的构造函数（也可用于无参&#x2F;多个参数的构造函数）。\n","categories":["cpp"],"tags":["cpp"]},{"title":"对象模型","url":"/2018/05/22/cpp/%E5%AF%B9%E8%B1%A1%E6%A8%A1%E5%9E%8B/","content":"[toc]C++ 中有两种 class data members（数据成员）\n\nstatic \nnonstatic\n\n三种 class member functions（成员函数）：\n\nstatic\nnonstatic\nvirtual\n\n对象模型\n成员位置该模型中，\n\nnonstatic data members 被配置在每个 class object 内部，static data members 被放在所有 class object 之外；\nnonstatic&#x2F;static function members 被放在所有 class object 之外，virtual function members（如果有）就在  class object 内部配置一个指向 virtual function members 构成的 virtual table 的指针。\n\n这里的 virtual table（虚表）对象模型中的概念如下：\n虚表virtual table（vtbl），是一个指针组，分别指向类的各个虚函数，而所有的虚函数构成一张虚函数表，也就是这些指针分别指向虚函数表的各个虚函数地址。如果一个 class 定义中声明有虚函数，则 class 会产生一个相应的表，即虚函数表，用来存放所有的指针，每个指针指向一个 class 中的一个虚函数。没有声明虚函数的类则不会产生这张表。即，虚函数表是 class 级别的概念，只有一个。而针对每个类对象，都会添加一个指针（vptr），这个指针指向该类的这个虚函数表。vptr 的设置（setting）和重置（resetting）都由类对象的 constructor、destructor 和 copy assignment 运算符自动完成。\n\n\n虚函数机制实现多态的重要手段，通过虚函数机制（virtual function mechanism），对多态对象施行 执行期类型判断（runtime type resolution），意即以下调用：\nptr-&gt;z();\n是在执行期完成的类型判断，从而找到并调用 z() 的适当实例（即确定来自子类还是父类）。虚函数和非虚函数的区别只在 当使用一个基类指针&#x2F;引用来指向&#x2F;引用一个派生类对象时 才会有所体现。\nhttps://blog.csdn.net/lihao21/article/details/50688337https://blog.csdn.net/wenqiang1208/article/details/53148486\n虚拟继承虚拟基类是为解决多重继承而出现的，即菱形继承问题。虚拟继承在一般的应用中很少用到，所以也往往被忽视，这也主要是因为在 C++ 中，多重继承是不推荐的，也并不常用，而一旦离开了多重继承，虚拟继承就完全失去了存在的必要，也只会降低效率和占用更多的空间。\n","categories":["cpp"],"tags":["cpp"]},{"title":"抽象类","url":"/2018/05/22/cpp/%E6%8A%BD%E8%B1%A1%E7%B1%BB/","content":"https://bbs.csdn.net/topics/310103538\n","categories":["cpp"],"tags":["cpp"]},{"title":"智能指针","url":"/2018/05/22/cpp/%E6%99%BA%E8%83%BD%E6%8C%87%E9%92%88/","content":"[toc]\n智能指针（Smart Pointer）为了解决内存泄漏问题，C++11 引入了智能指针。智能指针实质上是一个对象，只是其行为表现像是一个指针。其原理是，接受一个申请好的内存地址，构造一个保存在 栈上 的智能指针对象，当程序退出栈的作用域范围后，由于栈上的变量自动被销毁，智能指针内部保存的内存也就被释放掉了（除非将智能指针保存起来）。C++11 提供了3种智能指针：std::shared_ptr、std::unique_ptr、std::weak_ptr，定义在&lt;memory&gt;中。\nshared_ptr使用引用计数，即可以有多个 shared_ptr 实例指向同一块动态分配的内存，每一个 shared_ptr 的拷贝都指向相同的内存。每使用一次，内部的引用计数 +1,每析构一次则 -1,当最后一个 shared_ptr 离开作用域，即引用计数为0时，释放该堆内存。shared_ptr 内部的引用计数是线程安全的，但对对象的读写需要加锁。\nunique_ptr不同于 shared_ptr 的引用计数，unique_ptr 意味着所有权，其离开作用域时，会立即释放所指向的内存。它也是线程安全的。unique_ptr 应该是默认的智能指针类型，只有需要共享资源时，才使用 shared_ptr。\nweak_ptr严格来说它不是一个智能指针（也不是一个指针），因为它不能使用 operator* 和 operator-&gt;。它也不负责维护底层内存。唯一的作用是，检查底层被管理的内存是否还有效，即对象是否还存在，并在有效时可以提供一个指向内存的 shared_ptr 以供使用。一般配合 shared_ptr 使用：可以指向 shared_ptr 所指向的对象，但不增加对象的引用计数。这就有可能出现 weak_ptr 所指向的对象实际上已经被释放的情况，因此 weak_ptr 有一个 lock()函数，它可以尝试取回一个指向对象的 shared_ptr。\n","categories":["cpp"],"tags":["cpp"]},{"title":"构造 析构","url":"/2018/05/22/cpp/%E6%9E%84%E9%80%A0%20%E6%9E%90%E6%9E%84/","content":"构造函数默认生成默认情况下，编译器会为一个类自动生成：\n\n一个默认构造函数：X();\n一个拷贝构造函数：X(const X&amp;);\n一个拷贝赋值运算符：X&amp; operator&#x3D;(const X&amp;);\n一个移动构造函数：X(X&amp;&amp;);\n一个移动赋值运算符：X&amp; operator&#x3D;(X&amp;&amp;);\n一个析构函数：~X();\n\n如果用户定义了其中一个&#x2F;多个构造函数，则：\n\n如果声明了任意构造函数，则不再生成默认构造函数；\n如果声明了拷贝操作、移动操作或析构函数，则不再生成相应的拷贝操作、移动操作或析构函数。可以使用显式声明默认操作（&#x3D;default）。\n\n成员初始化顺序构造函数中的参数列表顺序并不代表类中成员变量的初始化顺序，成员的初始化顺序取决于成员在类中声明&#x2F;定义的顺序。\n初始化 赋值首先，类成员的初始化总是在构造函数之前执行。构造函数可以通过初始化列表或传参（也就是用参数给类成员赋值）两种方式初始化类实例。如果没有在构造函数的初始值列表中显式地初始化成员，则该成员将在构造函数体之前进行默认初始化。二者存在一些差别，具体到内置数据类型和自定义数据类型来考虑：\n\n内置数据类型&#x2F;复合类型（指针、引用）：使用成员初始化列表和在构造函数体内赋值，二者的性能和结果上都是一样的；\n用户自定义类型（类类型）：结果上还是一样的。但性能上有差异，类类型的数据成员对象在进入函数体前就已经构造完成，也就是说在成员初始化列表处进行构造对象的工作（仅此一次调用构造函数），然后通过拷贝赋值方式初始化数据成员；而构造函数赋值则是在进入构造函数体后，先将数据成员初始化为空值，然后以“&#x3D;”赋值的方式进行数据成员的赋值工作，这会导致两次调用构造函数：初始化对象一次，给数据成员赋值时一次。另外，一些情况下，只能使用初始化方式：\n成员是类或结构，且构造函数带参数。成员初始化时无法调用缺省（无参）构造函数；\n成员是常量或引用。成员无法赋值，只能被初始化。\n\n委托构造函数C++11 扩展了构造函数初始值的功能，可以定义使用委托构造函数（delegating constructor）：使用类的其他构造函数执行自身初始化过程的构造函数：把自身的一部分&#x2F;全部初始化工作委托给其他构造函数来执行。\n类不变式构造函数的任务是初始化该类的一个对象，初始化操作必须建立一个 类不变式（class invariant），即当成员函数（从类外）被调用时必须保持的某些东西。例，vector 的含初始化容量（int size）的构造函数必须保证至少两点：能够保存 size 个对象；size 非负，所以构造函数要确保传入的 size 非负，并且申请相应的资源，在执行中如果出错（size 为负数或申请空间失败），必须通告异常。\n析构函数如果 class 没有定义析构函数，那么只有在 class 的成员对象或父类拥有析构函数 的情况下，编译器才会自动合成一个析构函数。否则，被视为不需要析构函数从而不被合成。\n虚析构函数用来做基类的类的析构函数一般都是虚函数，是为了 当用一个基类的指针删除一个派生类的对象时，派生类的析构函数会被调用。\n","categories":["cpp"],"tags":["cpp"]},{"title":"目标文件","url":"/2018/05/22/cpp/%E7%9B%AE%E6%A0%87%E6%96%87%E4%BB%B6/","content":"目标文件目标文件就是源代码编译后但还未执行链接操作的中间文件（windows 下的 .obj 和 linux 下的 .o）。\n格式目标文件跟可执行文件的内容和结构很相似，广义上可以看作是一样的，所以采用同一种格式存储。可执行文件格式：windows 下的 PE（Portable Executable）、Linux 下的 ELF（Executable Linkable Format），它们都是 COFF（Common File Format）格式的变种。而且不光是可执行文件和目标文件，动态链接库（windows 下的 .dll 和 linux 下的 .so）、静态链接库（windows 下的 .lib 和 linux 下的 .a）文件也是按照可执行文件的格式存储的。即，在 windows 下都按照 PE-COFF 格式存储，在 linux 下都是按照 ELF 格式存储。\n内容目标文件包含编译后的机器指令、数据、链接时需要的一些信息（如符号表、调试信息、字符串等）。一般以“节（section）”&#x2F;“段（segment）”的形式存储。主要包含：ELF header、.text、.data、.bss、.rodata、comment、etc.\nELF header文件头\n","categories":["cpp"],"tags":["cpp"]},{"title":"编译 链接","url":"/2018/05/22/cpp/%E7%BC%96%E8%AF%91%20%E9%93%BE%E6%8E%A5/","content":"过程gcc 编译过程可以分为几个步骤：预处理&#x2F;预编译、编译、汇编、链接：\n\n实际上 gcc 这个命令本身只是 编译器（包括执行预编译阶段） ccl&#x2F;cclplus、汇编器 as、链接器 ld 的包装，gcc 根据不同参数要求去调用它们，所以即使使用 gcc 将所有命令一步执行到位得到可执行文件，其过程也是按这几个主要步骤执行的。\n预处理一般 gcc -E 结果 xxx.c 生成 xxx.i，xxx.cpp 生成 xxx.ii，但后缀并不严格限制。主要完成这些工作：\n\n展开所有宏定义 #define，即将它们复制到所有出现的地方；\n处理所有条件编译指令：#if、#ifdef、#elif、#else、#endif 等；\n递归处理”#include”预编译指令，将所有被包含的文件插入该预编译指令的位置；\n删除所有注释；\n添加行号和文件名标识，编译时编译器产生的编译错误&#x2F;警告等需要用到；\n保留所有 #pargma 编译器指令。\n\n编译编译过程就是编译器把预处理过的文件进行一系列词法分析、语法分析、语义分析以及 优化，产生汇编代码文件。这是核心和最复杂的部分：\n\n（参见《自我修养》）\n汇编汇编器将编译后的汇编代码转变成机器可执行的指令，每个汇编语句几乎都对应一条机器指令。所以汇编过程相比于编译过程比较简单。它不需要指令优化，没有复杂的语法语义，只需要根据汇编指令和机器指令的对照一一翻译即可。\n链接链接比较复杂，涉及到动态&#x2F;静态库等内容。本质上是代码&#x2F;程序的模块化（或者说随着代码&#x2F;程序规模的不断增加，模块化是一种必然的进化方向），需要组合拼装成完整的一个可执行程序，这就需要将这些模块链接起来。而静态链接、动态链接等都是不断发展不断优化的产物&#x2F;思想。链接过程主要包括 地址和空间分配（Address and Storage Allocation）、符号决议（Symbol Resolution）&#x2F;符号绑定（Symbol Binding）、重定位（Relocation）。\n一些选项\n优化\n-O：主要进行线程跳转（Thread Jump）和延迟退栈（Deferred Stack Pops）两种优化，减小代码的尺寸和运行时间，但不会增加编译时间；-O2：除了完成 -O1（也就是 -O），不需要额外的空间去加速交换；-O3：在 O2 基础上，忽略了有可能增加代码长度的部分，并且增加了减小代码长度的优化；-Os：在 O2 基础上，包括循环展开和其他一些与处理器特性相关的优化工作，增加了内联函数和重名 register，不过可能导致编译出来的二级制程序不能debug；另外，还有一些优化参数，-mcpu 会针对某一型号的 CPU 进行调优而不会导致它不能在另外的 CPU 上运行等。\n\n\n调试信息：使用 -gxxx 产生符合操作系统本地格式的调试信息\n-ggdb：产生 GDB 所需的调试信息。这是可用的、最具表达力的格式；-gstabs：产生 stabs 格式的调试信息（如果支持的话），其中不包含 GDB 扩展。用于 DBX 调试器；-gstabs+：产生 stabs 格式的调试信息（如果支持的话），并且会使用只有 GNU 调试器（GDB）才理解的 GNU 扩展。这些扩展的使用可能会导致其他调试器崩溃或者拒绝读取编译出来的可执行程序；-gxcoff：产生 XCOFF 格式的调试信息（如果支持的话），用于 DBX 调试器。-gxcoff+：同 -gxcoff，”+”具有和 “-gstabs+” 相同的限制语义。\n\n\n警告 错误\n-w：禁止所有告警信息；-Wall：输出所有的常见警告,另外的一些不常见的告警不在这个范围内；-Werror：把所有的警告信息转化为错误信息，并在出现警告时停止向下编译；-pedantic：发出 ANSI C 标准所列的全部警告信息，如果使用了 GCC 对 C 语言的扩展，则提示一个告警信息；-pedantic-error：发出 ANSI C 标准所列的全部错误信息，如果使用了 GCC 对 C 语言的扩展，则提示一个错误信息；\n\n\n-I dir：除了当前目录，还在 dir 寻找头文件、源文件；\n-L dir：搜索除系统标准库目录外的 dir 目录，作为库文件来源；\n-static：指示链接器构建一个完全链接的可执行程序，即链接静态库而不链接动态库；\n-fPIC：指示链接器创建一个共享的目标文件，即 .so 文件;\n-shared：生成动态库，一般和 -fPIC 一起使用。\n\n关于 gcc\n","categories":["cpp"],"tags":["cpp"]},{"title":"STL-配置器","url":"/2018/05/19/cpp/STL/STL%E7%BB%84%E4%BB%B6-%E9%85%8D%E7%BD%AE%E5%99%A8/","content":"[toc]\n空间配置器配置器（allocators），负责空间配置与管理，从实现的角度看，是一个实现了动态空间配置、空间管理、空间释放的 class template。从 STL 应用角度看，它总是隐藏在一切组件（指容器）的背后；从 STL 实现角度看，整个 STL 操作对象都存放在容器里，而容器的空间配置都是由空间配置器完成的。allocator 被称为空间配置器而非内存配置器，是因为空间也有可能是磁盘或其他辅助存储介质，即，可以实现直接向磁盘读取空间的 allocator。\nC++ 内存配置基本操作是 ::operator new()，内存释放基本操作是 ::operator delete()。这两个全局函数相当于 C 的 malloc()和 free()函数。\nSGI 双层配置器SGI 的空间配置与释放设计哲学：\n\n向 system heap 请求空间；\n考虑多线程（multi-threads）状态；\n考虑内存不足时的应对措施；\n考虑过多“小型区块”可能造成的内存碎片（fragment）问题。\n\n考虑到小型区块可能造成的内存破碎问题，SGI 设计了双层级配置器，第一级配置器直接使用 malloc()和free()，第二级配置器则视情况采用不同的策略：当配置区块超过 128 bytes 时，视之为“足够大”，调用第一级配置器；当配置区块小于 128 bytes 时，视之为“过小”，为了降低额外负担（overhead），采用复杂的 memory pool 整理方式，不再借助第一级配置器。\n第一级配置器 __malloc_alloc_template以 malloc()、free()、realloc()等 C 函数执行实际的内存配置、释放、重配置等操作，并实现类似 C++ new-handler 机制（即，它不能直接使用 C++ new-handler 机制，因为它并非使用 ::operator new 来配置内存）。\nC++ new Handler可以要求系统在内存配置请求无法被满足时，调用一个指定的函数，即，一旦 ::operator new()无法完成任务，在抛出 std::bad_alloc 异常之前，先调用指定的处理函数，该处理函数通常被称为 new-handler\nSGI 第一级配置器的空间配置函数 allocate()和 realloc()都是在调用 malloc()和realloc()不成功后，改调用 oom_malloc()和 oom_realloc()。后两者通过内循环不断调用“内存不足处理例程”，期望在某次调用之后，获得足够的内存而完成人物。但如果该例程没有被用户设置，oom_malloc()和 oom_realloc()只能调用 __THROW_BAD_ALLOC，抛出 bad_alloc 异常，或利用 exit(1) 终止程序。空间释放函数 deallocate()直接调用 free()执行。\n设计“内存不足处理例程”是用户（开发者）的责任。\n第二级配置器 __default_alloc_template通过一些机制避免太多小型区域造成的内存碎片。具体做法是，当配置区块超过 128 bytes 时，视之为“足够大”，移交并调用第一级配置器；当配置区块小于 128 bytes 时，采用内存池管理，不再借助第一级配置器。\n第二级配置器的空间配置与释放通过 __default_alloc_template 的标准接口函数 allocate()和 deallocate()进行空间配置和释放。显然，二者会判断空间大小（是否大于 128 bytes），从而决定是否调用第一级配置器的配置&#x2F;释放函数。\n内存池tbd\n","categories":["cpp"],"tags":["cpp"]},{"title":"STL-适配器","url":"/2018/05/19/cpp/STL/STL%E7%BB%84%E4%BB%B6-%E9%80%82%E9%85%8D%E5%99%A8/","content":"[toc]\n适配器(adapters)适配器概念上是一种设计模式：《设计模式》对它的描述为：将一个类的接口 转换成 客户希望的另外一个接口，使得原本由于接口不兼容而不能合作的类能够一起工作。\n分类STL 提供函数对象接口适配器、容器接口适配器、迭代器接口适配器，相应地，它们用于改变&#x2F;转换函数对象、容器、迭代器的接口。\n\n容器适配器：queue、stack，见“序列式容器”；\n\n迭代器适配器：STL 提供了很多应用于迭代器的适配器：insert iterators、reverse iterators、iostream iterators 等，可以从 &lt;iterator&gt; 获得，SGI STL 则定义于 &lt;stl_iterator.h&gt;。\n\nInsert Iterators：可以将一般迭代器的赋值操作转变为插入操作。包括专司尾端插入操作的 back_insert_iterator、头部插入操作的 front_insert_iterator、任意位置插入操作的 insert_iterator，由于它们的使用接口不够直观，STL 提供了相应的封装函数：back_inserter()、front_inserter()、inserter()，提升使用的便捷性。Reverse Iterators：可以将一般迭代器的行进方向逆转，使原本应该前进的 operator++ 变成后退操作，&amp; vice versa。IOStream Iterators：可以将迭代器绑定到某个 iostream 对象上。相应地，绑定到 istream 如 std::cin 上的，称为 istream_iterator，拥有输入功能；绑定到 ostream 如 std::cout 上的，称为 ostream_iterator，拥有输出功能。以此为基础，稍加修改，便可适用于任何 I&#x2F;O 设备上，如绑定到 IE cache 上，或绑定到一个磁盘目录上，etc.\n\n\n函数对象适配器：数量最多、灵活度最高，可以适配、适配、再适配。可以从 &lt;functional&gt; 获得，SGI STL 则定义于 &lt;stl_function.h&gt;。通过它们之间的绑定、组合、修饰，几乎可以无限制地创造出各种可能的表达式，搭配 STL 算法一起使用。而且，这为数众多的适配器也使得“一般函数”、“成员函数”得以和其他适配器或算法无缝结合。\n\n\n","categories":["cpp"],"tags":["cpp"]},{"title":"STL-函数对象","url":"/2018/05/19/cpp/STL/STL-%E5%87%BD%E6%95%B0%E5%AF%B9%E8%B1%A1/","content":"[toc]\n仿函数&#x2F;函数对象将“function call 操作符，即‘()’，重载了的一种类”。在 STL 早期历史中被称为仿函数（functors），C++ 标准后采用的名称是函数对象（function objects）：一种具有函数特性的对象。它在 STL 中扮演“策略”的角色，使得 STL 算法具有灵活的变化，其关键就在于 函数对象的可适配性（adaptability）。\n用途STL 所提供的算法一般有两个版本：一个表现为最常用&#x2F;最直观的某种运算，另一个版本则表现最泛化的演算流程，允许用户“以 template 参数来指定所要采取的策略”。而函数对象的主要作用，也就是以参数形式作为算法的这种策略。之所以函数对象能够作为参数，是因为，当作为调用者时，它可以像函数一样使用（调用&#x2F;被调用）；而作为被调用者时，它能够以对象所定义的 function call operator 扮演函数的实质角色，简单理解就是，一个“行为类似函数”的对象，或，使一个类的使用看上去像是一个函数。\n举例以STL sort()函数为例。第一个版本就是直观上的非递减排序，以 operator&lt; 为排序时的元素位置调整依据；而第二个版本允许用户指定任何“操作”，务求排序后的两两相邻元素都能令该操作为真，即，把某种“操作”作为算法的参数。而实现方式就是：\n\n先将该“操作”（可能有数条指令）设计为一个函数，再将函数指针当作算法的一个参数；\n将该“操作”设计为一个所谓的仿函数（语言层面而言，就是个 class），再以该仿函数产生一个对象，并以此对象作为算法的一个参数。\n\n上述表明了函数指针可以实现“将整组操作当作算法的参数”，但依然引入函数对象的原因是，函数指针不能满足 STL 对抽象性的要求，而且函数指针也不能和 STL 其他组件如适配器等搭配使用，从而产生更灵活的变化。\n分类STL 内建的函数对象包含在 &lt;functional&gt; 头文件里。SGI 定义在&lt;stl_function.h&gt;里。以 操作数（operand）的个数 划分，可以分为:\n\n一元函数对象；\n二元函数对象；\n\n以 功能划分，可分为：\n\n算术运算（Arithmetic）：\n\n加法：plus&lt;T&gt;;减法：minus&lt;T&gt;;乘法：multiplies&lt;T&gt;;除法：divides&lt;T&gt;;取模：modulus&lt;T&gt;;否定：negate&lt;T&gt;;（一元）\n\n\n关系运算（Rational）：\n\n等于：equal_to&lt;T&gt;;不等于：not_equal_to&lt;T&gt;;大于：greater&lt;T&gt;;大于或等于：greater_equal&lt;T&gt;;小于：less&lt;T&gt;;小于或等于：less_equal&lt;T&gt;;\n\n\n逻辑运算（Logical）:\n\nAnd：logical_and&lt;T&gt;;Or：logical_or&lt;T&gt;;Not：logical_not&lt;T&gt;;(一元)\n\n\n\n","categories":["cpp"],"tags":["cpp"]},{"title":"STL-关联式容器","url":"/2018/05/18/cpp/STL/STL-%E5%85%B3%E8%81%94%E5%BC%8F%E5%AE%B9%E5%99%A8/","content":"[toc]容器，置物之所也常用的数据结构不外乎 array（数组）、list（链表）、tree（树）、stack（栈）、queue（队列）、hash table（散列表）、set（集合）、map（映射表）等。根据数据在容器中的排列特性，这些数据结构分为序列式（sequence）和关联式（associative）两种。\n所谓关联式容器，每个元素都由键值对组成。当插入元素时，容器内部结构（如红黑树&#x2F;散列表）会依照其键值大小，以给定规则将该元素插入到适当位置。没有头尾的概念，也就没有诸如 push_back()、pop_back()、begin()、end() 等操作。\n标准关联式容器标准的关联式容器分为 set（集合）和 map（映射表）两大类及其衍生体如，multiset（多键集合）、multimap（多键映射表）。这些容器的底层机制均以 RB-tree（红黑树）实现，而 RB-tree 本身也是一个独立容器，但并不开放使用。C++11引入的关联式容器C++11 标准引入的 STL 容器中，除了 forward_list 是序列式容器外，其余的4种 unordered_set、sunordered_multiset、unordered_map、unordered_multimap 是 基于 hash table 实现的关联式容器。SGI STL 提供的关联式容器此外，SGI STL 还提供了一个不在标准内的关联式容器：hash table（散列表），以及由此为底层机制实现的shash_set（散列集合）、hash_multiset（散列多键集合）、hash_multimap（散列多键映射表）。但随着 C++11 标准的引入，显然，在选择上有了倾向性。\n红黑树实现的关联式容器提供稳定的动态操作时间：查询、插入、删除时间复杂度都是 O(logn)。\nset所有元素根据键值自动排序，set 元素的键值就是实值，实值就是键值，不允许相同键值的元素。set 不可以通过迭代器修改元素值，即，set iterator 是一种 constant iterator。set 所提供的各种操作接口，几乎都是调用底层的 RB-tree 的接口实现的。STL 特别提供了一组 set&#x2F;multiset 相关算法，包括交集（set_intersection）、联集（set_union）、差集（set_difference）、对称差集（set_symmetric_difference）。\nmultiset特性和用法和 set 完全相同。唯一的差别是它允许键值重复，因此它的插入操作采用的是底层 RB-tree 的 insert_equal() 而非 insert_unique()。\nmap所有元素根据键值自动排序，所有元素都是 pair，即键值对，不允许两个元素拥有相同的键值。map 同样不可以通过迭代器修改元素的键值——这会破坏 map 组织（排列规则），但可以修改实值，因为 map 元素的实值并不影响其元素的排列规则。因此，map iterator 既不是一种 constant iterator，也不是一种 mutable iterator。同样地，map 的各种接口也基本借助底层的 RB-tree 来实现。map 和 list 相同的一些性质：插入&#x2F;删除都不影响除被操作元素之外的其他元素的迭代器。\nmultimap特性和用法和 map 完全相同。唯一的差别是它允许键值重复，因此它的插入操作采用的是底层 RB-tree 的 insert_equal() 而非 insert_unique()，和 set&#x2F;multiset 一样。\n散列表实现的关联式容器结合 C++11 引入的4个和 SGI STL 中提供的非标准关联式容器：\nunordered_set &amp; hash_set非有序的 set，理论上查询时间是 O(1)，但这并不意味着一定比上面的红黑树实现更快：实际使用中要考虑数据量等因素，而且 unordered_set 的 hash 函数的构造速度也不一定很快。\nunordered_multiset &amp; hash_multiset特性和用法同上，区别是允许重复键值，所以还是插入函数的底层调用不同（multixxx 调用的是 insert_equal()，而非上面的 insert_unique()。\nunordered_map &amp; hash_map非有序的 map，理论上查询时间是 O(1)。\nunordered_multimap &amp; hash_multimap特性和用法同上，区别是允许重复键值，所以还是插入函数的底层调用不同。\n","categories":["cpp"],"tags":["cpp","容器"]},{"title":"STL-算法","url":"/2018/05/18/cpp/STL/STL-%E7%AE%97%E6%B3%95/","content":"[toc]以有限的步骤，解决逻辑或数学上的问题。STL 提供了 70 多个极富复用价值的算法，涉及到排序、查找、排列组合以及数据的移动&#x2F;复制&#x2F;删除&#x2F;比较&#x2F;组合&#x2F;运算等。特定的算法往往搭配特定的数据结构，如 BST&#x2F;RB-tree 就是为了解决查找问题而发展出来的特殊数据结构。\n关联式容器排序STL 中的 sort \n","categories":["cpp"],"tags":["cpp"]},{"title":"STL-序列式容器","url":"/2018/05/18/cpp/STL/STL-%E5%BA%8F%E5%88%97%E5%BC%8F%E5%AE%B9%E5%99%A8/","content":"[toc]容器，置物之所也常用的数据结构不外乎 array（数组）、list（链表）、tree（树）、stack（栈）、queue（队列）、hash table（散列表）、set（集合）、map（映射表）等。根据数据在容器中的排列特性，这些数据结构分为序列式（sequence）和关联式（associative）两种。\n所谓序列式容器，其中的元素都可序（ordered），但未必有序（sorted）。有以下种类：\narrayC++ 内置（build-in）序列式容器，使用静态连续空间，即，一旦声明就不能改变大小；\nvector与 array 十分相似，差别在于空间运用的灵活性，vector使用动态空间，随着元素的加入，内部可以自行扩充空间以容纳新元素。实现中的技术在于 对大小的控制和重新配置时的数据移动效率。\n容量（capacity）为降低空间配置时的速度成本，vector 实际配置的大小可能比客户端需求量更大一些，以备将来可能的扩充。这便是容量的概念。即，一个 vector 的容量（capacity）永远不小于其大小（size）。\n迭代器连续线性空间可以直接使用普通指针作为迭代器，而不论其元素类型。即提供 Random Access Iterator。vector 维护3个指针迭代器：\n\nstart：目前使用空间的头；\nfinish：目前使用空间的尾；\n目前可用空间的尾。\n\n使用以上3个迭代器，即可轻松提供首尾标示、大小、容量、空容器判断、下标（[]）运算符、最前&#x2F;后端元素值等功能。注意，插入&#x2F;删除会导致原本的迭代器失效：位置会发生变化。\nlistSTL list 是一个双向链表（double linked-list），采用非线性空间，每插入&#x2F;删除一个元素就相应配置&#x2F;释放一个元素空间，即，精准使用空间不浪费。且 对于任意位置元素插入&#x2F;删除，都是常数O(1)时间。\n迭代器具备前移、后移的能力，是 Bidirectional Iterators。和 vector 的迭代器不同，其插入&#x2F;删除操作不会造成原有的迭代器失效，仅仅影响被操作元素（和前后元素）的迭代器，其他位置不受影响。\nforward_listC++11 标准引入的序列式容器，类似于下面提到的 slist。\ndequevector 是单向开口的连续线性空间，而 deque 是一种双向开口的连续线性空间。所谓双向开口：可以在头尾两端分别做元素插入&#x2F;删除操作。（技术角度看，vector 也可以在两端操作，但在头部操作效率很差，无法接受。）deque 没有容量概念：它动态地以分段连续空间组合而成，可以随时增加一段新的空间并拼接起来，因而逻辑上仍然可以看作是连续空间。\n迭代器提供 Random Access Iterator。但它的迭代器不是普通指针，而是复杂的实现方式（因此，除非必要，尽可能选用 vector。比如对 deque 排序操作，完全可以先将其复制到一个 vector，使用 STL sort 排序后再复制回 deque）。由于避开了 vector 扩充过程中“重新分配空间、复制、释放旧空间”的代价高昂的操作，其迭代器实现在维护“整体连续空间”的假象时只能以复杂架构作为代价。\n###################### 基于容器的适配器适配器以既有容器作为底层结构，稍作修改，即可形成一个新的数据结构。这种依赖底层结构，通过修改底层结构接口完成自身所有工作的新的结构，称为 adapter（适配器）。因而 stack、queue 等并不被归类为容器，而是容器适配器（container adapter）。STL 提供以下几种。\nstack一种 FIFO 的数据结构，只有一个开口：通过该开口新增&#x2F;移除元素、取得最顶端元素，但不允许（没有办法）存取顶端元素之外的其他元素，即，不能遍历。这也意味着，stack 没有迭代器。\n实现SGI STL stack 为例，默认以 deque 作为底层结构，实现很简单（复杂工作在 deque 的实现）。stack 使用到的 deque 底层函数有：empty、size、back、push_back、pop_back。list 也具备这些函数，并且也是双向开口的，因而也可以作为底层结构实现 stack。\nqueue也是一种 FIFO 的数据结构，有两个开口：从顶端获取元素，从底端加入元素，没有其他办法获取其他元素。所以类似于 stack，不允许遍历，也没有迭代器，同样是一个适配器结构。可以 deque、list 作为底层结构实现。\nheapheap 并不属于 STL 容器组件，而是作为 priority queue 的助手。其实现是 binary heap（二叉堆），即，一种 complete binary tree（完全二叉树）。由于其元素遵循完全二叉树的排序规则，heap 不提供遍历功能，也就没有迭代器。\npriority_queue优先队列。只允许在底端加入元素，在顶端取出元素。新增&#x2F;移除元素后，依照权值重新排序。默认以 deque 作为底部容器，加上 heap 处理规则实现。\n###################### 非标准序列式容器\nslistSTL list 是双向链表。SGI STL 提供了一个单向链表：slist，不在标准之内。和 list 相同的是插入&#x2F;删除不会导致全部迭代器失效（局部失效需要重建）；不同的是，它的迭代器属于单向的 Forward Iterator。因而功能上有许多限制，但好处是占用的空间更小，某些操作更快。基于效率（而非技术实现）考虑，slist 不提供 push_back()，只提供 push_front（），因此 slist 的元素次序和插入顺序相反。\n","categories":["cpp"],"tags":["cpp","容器"]},{"title":"STL-迭代器","url":"/2018/05/18/cpp/STL/STL%E7%BB%84%E4%BB%B6-%E8%BF%AD%E4%BB%A3%E5%99%A8/","content":"[toc]\n关于迭代器是一种抽象的设计概念，《设计模式》对迭代器模式的定义：提供一种方法，使之能够顺序访问一个聚合对象中各个元素，而又不需暴露该对象内部的表示。容器和算法的泛型化设计可以通过 class remplates 和 function templates 实现，而如何设计出良好的胶着剂，是 STL 的难题。\n详解迭代器是一种行为类似指针（smart pointer）的对象。根据移动特性与实现的操作，STL 提供了5种类型的迭代器：\n\nInput Iterator（输入迭代器），不允许改变，只读（read only）；\nOutput Iterator（输出迭代器），只写（write only）；\nForward Iterator（前向迭代器），允许写入型算法如，replace()，在迭代器所制定的区间进行读写操作；\nBidirectional Iterator（双向迭代器），某些算法需要逆向访问某个迭代器区间（如逆向拷贝某范围的元素）；\nRandom Access Iterator（随即访问迭代器），前四种都只提供一部分指针运算能力：前三种支持 operator++，第四种加上了 operator–，第5种则涵盖所有指针运算：p±n、p[n]、p1-p2、p1 &lt; p2。\n\n\n每一个左边的迭代器都实现了右边迭代器的方法，是进一步的强化。\ntraits 技术STL 使用 iterator_traits 这个结构体专门“萃取”迭代器的特性如，迭代器所指向的对象的类型。有以下5种：\ntempalte&lt;typename I&gt;  \nstruct iterator_traits  \n&#123;  \n    typedef typename I::value_type value_type;  \n    typedef typeanme I:difference_type difference_type;  \n    typedef typename I::pointer pointer;  \n    typedef typename I::reference reference;  \n    typedef typename I::iterator_category iterator_category;  \n&#125;;  \n\n\nvalue_type：指迭代器所指对象的类型，如，原生指针也是一种迭代器，对于原生指针 int*，int 即为指针所指对象的类型，即所谓的 value_type；\n\ndifference_type：用来表示两个迭代器之间的距离，如：\nint array[5] &#x3D; &#123;1, 2, 3, 4, 5&#125;;  \nint *ptr1 &#x3D; array + 1;  &#x2F;&#x2F;指向2  \nint *ptr2 &#x3D; array + 3;  &#x2F;&#x2F;指向4  \nptrdiff_t distance &#x3D; ptr2 - ptr1;  &#x2F;&#x2F;结果即为difference_type\nreference：指迭代器所指对象的类型的引用。一般用在迭代器的 * 运算符重载上，如果 value_type 是 T，那么对应的 reference_type 就是 T&amp;，如果value_type 是 const T，那么对应的 reference_type 就是 const T&amp;。从“迭代器所指对象的内容是否允许改变的角度”，迭代器分为两种：\n\n不允许改变“所指对象的内容”，即 const iterators；如 const int *pic;允许改变“所指对象的内容”，即 mutable iterators，如 int *pi;\n\n\npointer：指迭代器所指的对象，也就是相应的指针。对指针而言，最常用最重要的功能就是解引用 operator* 和成员访问 operator-&gt; 这两个运算符。因此迭代器需要对这两个运算符进行重载。pointer 和 reference 在 C++ 中关联密切：如果“返回一个左值，令它代表 p 所指对象”是可行的，那么，“返回一个左值，令它代表 p 所指对象的地址”也一定可行。即：我们能够返回一个 pointer，指向迭代器所指对象。\n\niterator_category：分类迭代器，以上提到的5类迭代器（Input&#x2F;Output Iterator等），由于有递进增强的关系，在使用时如，某个算法可以接受 Forward Iterator，此时使用 Random Access Iterator 自然同样可用，但可用不代表最佳。任何一个迭代器，其类型永远应该落在“该迭代器所隶属的各种类型中，最强化（最佳效率）的那个”。\n\n\n","categories":["cpp"],"tags":["cpp"]},{"title":"STL","url":"/2018/05/18/cpp/STL/STL/","content":"[toc]\n关于 STLSTL（标准模板库）的中心思想是：将数据容器（containers）和算法（algorithms）分开，彼此独立设计，最后再以胶着剂（迭代器）将它们撮合在一起。\n提供的六大组件：\n容器（containers），各种数据结构如，vector、list、deque、set、map…;\n算法（algorithms），各种常用算法如，sort、search、copy、erase…；\n迭代器（iterators），容器与算法之间的胶着剂，泛型指针，共有5种类型。所有 STL 容器\n仿函数（functors）&#x2F;函数对象（function objects），行为类似函数，可作为算法的某种策略（policy）。从实现的角度看，是一种重载了 operator() 的 class 或 class template，一般函数指针可以视为狭义的仿函数；\n适配器（adapters），修饰仿函数、容器、迭代器等接口（相应地称为：仿函数接口适配器、容器接口适配器、迭代器接口适配器等）。如 queue、stack 等，它们看似容器，但只能算是一种容器适配器，因为其底层完全借助 deque，所有操作都由底层的 deque 提供；\n配置器（allocators），负责空间配置与管理，从实现的角度看，是一个实现了动态空间配置、空间管理、空间释放的 class template。\n\n","categories":["cpp"],"tags":["cpp"]},{"title":"LRU","url":"/2018/05/05/Algs/LRU/","content":"[toc]Least Recently Used，最近最少使用。常用于缓存淘汰机制。\n一个基于双向链表 +Map 的 C++ 实现\n","categories":["Algs"],"tags":["Algs"]},{"title":"KMP算法","url":"/2018/05/05/Algs/KMP%E7%AE%97%E6%B3%95/","content":"[toc]\nThe Knuth-Morris-Pratt Algorithm经典的字符串匹配算法。但实现起来并不复杂。首先一个概念是：\n部分匹配表 The Partial Match Table参考这篇博文：The Knuth-Morris-Pratt Algorithm当弄清楚了什么是部分匹配表之后，接下来就是怎么使用它，在匹配失败的时候进行适当的跳跃。使用参考这部分内容从头到尾彻底理解KMP\n最后给出一个实现\n其他两个字符串匹配算法BM算法和Sunday算法，参考第二篇博客。\n","categories":["Algs"],"tags":["Algs"]},{"title":"外部排序","url":"/2018/05/05/Algs/%E5%A4%96%E9%83%A8%E6%8E%92%E5%BA%8F/","content":"对数据量太大而不能全部放在内存中的关系的排序称为外排序（external sorting），比如数据库索引、文件系统等。外排序中最常用的是 外部排序归并（external sort-merge） 算法。示例：100M 内存情况下，排序 900MB 数据 \n\n读入 100MB 数据到内存，用某种常规内存排序（快排、堆排、归并等）完成排序（这里不考虑排序算法的空间复杂度，如果考虑，减少每次读入数据量）；\n将排序好的数据写回磁盘，产生一个临时文件块；\n重复步骤 1、2，直到完成所有数据都完成排序并写回。此时有 9 个 100MB 的已排序临时文件；\n读入每个临时文件的前 10 MB（10 &#x3D; 100 &#x2F; （9 + 1））数据放入内存的输入缓冲区，最后 10MB 作为输出缓冲区（实践中，将输入缓冲区适当调小，将输出缓冲区适当调大，效果更好）；\n执行 9 路归并，将结果输出到输出缓冲区。当缓冲区满，将其中的数据写回目标文件，清空缓冲区。过程中一旦 9 个输入缓冲区的某个变空，就从这个缓冲区关联的文件，再读入下一个 10 MB 数据，直到该文件被全部读入。最终所有数据被归并，写回目标文件，完成排序。\n\n","categories":["Algs"],"tags":["Algs","Sort"]},{"title":"堆排序","url":"/2018/05/02/Algs/%E5%A0%86%E6%8E%92%E5%BA%8F/","content":"[TOC]两步操作：堆化、下沉（或上浮）。\npublic static void sort(Comparable[] pq) &#123;\n    int n = pq.length;\n    // 构造堆\n    // 从最下层一个非叶节点开始作为根节点，构造子堆\n    // 这样能够保证对该节点的父节点堆化时，下沉动作不会扩散到它的子节点\n    for (int k = n / 2; k >= 1; k--) &#123;\n        sink(pq, k, n);\n        show(pq);\n    &#125;\n\n    // 堆排序过程\n    // 依次下沉当前最大元素，保持堆\n    while (n > 1) &#123;\n        exch(pq, 1, n--);\n        sink(pq, 1, n);\n    &#125;\n&#125;\n\n// 下沉，使得以 k 位置为根节点，构造一个堆\nprivate static void sink(Comparable[] pq, int k, int n) &#123;\n    while (2 * k &lt;= n) &#123;\n        int j = 2 * k;\n        if (j &lt; n &amp;&amp; less(pq, j, j + 1)) j++;\n        if (less(pq, j, k)) break;\n        exch(pq, k, j);\n        k = j;\n    &#125;\n&#125;","categories":["Algs"],"tags":["Algs","Sort"]},{"title":"贪心算法","url":"/2018/05/01/Algs/%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95/","content":"[toc]\n贪心算法（greedy algorithm）每一步都做出当前看起来最佳的选择。即，总是做出 局部最优的选择。理论上，适用于贪心算法的问题，同样能用动态规划方法解决。\n设计步骤首先是基于动态规划的设计方式：\n\n确定问题的最优子结构；\n设计一个递归算法；\n证明如果做出一个贪心的选择，则只剩下一个子问题；并且，证明贪心选择总是安全的；\n设计一个递归算法实现贪心策略；\n将递归算法转换为迭代算法。\n\n更一般地，通过贪心选择改进最优子结构，使得选择后只剩下一个子问题：\n\n最优化问题转换为：做出一次选择后，只剩下一个子问题需要求解；\n证明做出贪心选择后，原问题总是存在最优解，即贪心选择总是安全的（没有因为这一次的选择而丢失客观的最优解）；\n证明做出贪心选择后，剩余的子问题满足性质：其最优解与贪心选择组合即可得到原问题的最优解，即得到了最优子结构。\n\n能否使用贪心的两个要素贪心选择性质（greedy-choice property）通过做出局部最优（贪心）选择来构造全局最优解。与动态规划不同，贪心算法进行选择时可能依赖之前做出的选择，但不依赖任何将来的选择或子问题的解。\n最优子结构同动态规划。\n与动态规划的差别考虑 0-1 背包问题和分数背包问题，显然，后者能够使用贪心算法解决，而 0-1 背包问题则只能使用动态规划。\n","categories":["Algs"],"tags":["Algs"]},{"title":"动态规划","url":"/2018/05/01/Algs/%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92/","content":"[toc]\n动态规划（dynamic programming）与分治相似：都是通过组合子问题的解来求解原问题。而，分治将问题划分为互不相交的子问题，递归地（思路上）求解子问题，再将它们的解组合起来，得到原问题的解；与之不同地，动态规划应用于子问题重叠的情况，i.e. 不同的子问题具有公共的子子问题（递归求解子问题，将其划分为更小的子子问题）。这种情况下，分治算法将做许多不必要的工作——反复求解公共子子问题；而动态规划对每个子问题只求解一次，将结果保存在一个表格（programming 的由来）中，从而避免重复计算子子问题，i.e. 剪枝。典型的时空权衡（time-memory trade-off）问题：以空间换时间。通常用来求解 最优化问题（Optimization Problem），即在很多可行解中寻找 （一个&#x2F;多个）最优解 的过程。\n设计步骤\n刻画一个最优解的结构特征；\n递归地定义最优解的值；\n计算最优解的值——同常采用自底向上的方法；\n利用计算的信息构造一个最优解。\n\n两种实现方法\n\n带备忘录的自顶向下方法（top-down with memoization）。用数组&#x2F;散列表保存递归过程中子问题的解，当要求解一个子问题时，先检查是否已保存过此解，无则计算之；\n自底向上方法（bottom-up method）。需要恰当定义子问题“规模”的概念，使得任何子问题的求解都只依赖于“更小的”子问题的解。因而可以将子问题按规模排序，从小到大进行求解，当求解某个子问题时，它所依赖的更小的子问题已经求解完毕，结果已经保存。这样可以保证每个子问题只求解一次，并且求解它时，它所有的前提子问题都已完成。\n\n原理和适用条件适用场景：\n\n最优子结构；\n子问题重叠；\n\n几个典型问题钢条切割","categories":["Algs"],"tags":["Algs"]},{"title":"快速排序","url":"/2018/05/01/Algs/%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F/","content":"[TOC]\n简介采用分治策略，（两路快排）将一个序列分成两个子序列，独立排序。与归并排序互补：归并排序将序列分成两个部分分别排序，并将有序的子序列归并以将整个序列排序，递归调用发生在处理整个序列之前；而快排则是，当两个子序列都有序时，整个序列也就自然有序了，递归调用发生在处理整个序列之后。\nvoid sort(Comparable[] a, int lo, int hi) &#123;\n    if (lo >= hi) return;\n\n    int j = partition(a, lo, hi);\n    sort(a, lo, j - 1);\n    sort(a, j + 1, hi);\n&#125;\n\nint partition(Comparable[] a, int lo, int hi) &#123;\n    int i = lo, j = hi + 1;  // 左右扫描指针\n    Comparable v = a[lo];  // 切分元素，主元\n    while (true) &#123;\n        // 扫描左右，检查扫描是否结束并交换元素\n        while (less(a[++i], v)) if (i == hi) break;\n        while (less(v, a[--j])) if (j == lo) break;\n        if (i >= j) break;\n        exch(a, i, j);\n    &#125;\n    exch(a, lo, j);  // 将v=a[j]放入正确位置\n    return j;  // a[lo..j-1]&lt;=a[j]&lt;=a[j+1..hi]达成\n&#125;\n优点\n实现简单，适用于各种不同输入数据；\n原地排序，只需要 O(1) 的辅助空间；\n\n缺点实现中要避免低劣性能的影响：划分是否相对均衡，即主元的选取；\n优化\n小规模子序列（7 ~ 15）改用插入排序；\n三取样切分：使用子序列一小部分元素的中位数作主元，取样大小为 3 时效果较好；\n\n","categories":["Algs"],"tags":["Algs","Sort"]},{"title":"归并排序","url":"/2018/05/01/Algs/%E5%BD%92%E5%B9%B6%E6%8E%92%E5%BA%8F/","content":"简述将已有序的子序列合并，得到完全有序的序列的过程，i.e. 先使子序列有序，再使序列段间有序。\n\n时间复杂度： O(NlogN) ;\n空间复杂度：辅助空间：O(N);\n稳定排序，常使用递归实现。\n\nvoid merge(Comparable[] a, int lo, int mid, int hi) &#123;\n    int i = lo, j = mid + 1;\n\n    for (int k = lo; k &lt;= hi; k++)\n        aux[k] = a[k];\n\n    for (int k = lo; k &lt;= hi; k++) &#123;\n        if (i > mid)\n            a[k] = aux[j++];\n        else if (j > hi)\n            a[k] = aux[i++];\n        else if (less(aux[j], aux[i]))\n            a[k] = aux[j++];\n        else\n            a[k] = aux[i++];\n    &#125;\n&#125;\n\n// 自顶向下递归：\nvoid sort(Comparable[] a, int lo, int hi) &#123;\n    if (lo >= hi) return;\n    int mid = lo + (hi - lo) / 2;\n    sort(a, lo, mid);\n    sort(a, mid + 1, hi);\n    merge(a, lo, mid, hi);\n&#125;\n\n// 自底向上循环：\nvoid sort(Comparable[] a) &#123;\n    int N = a.length;\n    aux = new Comparable[N];\n    for (int sz = 1; sz &lt; N; sz = sz + sz) &#123;\n        for (int lo = 0; lo &lt; N - sz; lo += sz + sz)\n            merge(a, lo, lo + sz - 1, Math.min(lo + +sz + sz - 1, N - 1));\n    &#125;\n&#125;\n\n优化\n小规模子序列（7 ~ 15）改用插入排序&#x2F;选择排序；\n测试子序列是否已经有序：a[mid] &lt;&#x3D; a[mid]，则这两个子序列无需调用接下来的 merge() ，直接拷贝即可；\n不将元素复制到辅助空间：将辅助空间也带入 sort()、merge() 方法，每次递归变换二者的位置，从而无需反复拷贝子序列到辅助空间，而是临时将辅助空间用于排序和归并。\n\n","categories":["Algs"],"tags":["Algs","Sort"]},{"title":"Java-JDK9新特性","url":"/2018/04/28/java/JDK/JDK9%E6%96%B0%E7%89%B9%E6%80%A7/","content":"平台级模块系统简述","categories":["java"],"tags":["java","新特性"]},{"title":"JDK8新特性-Lambda","url":"/2018/04/28/java/JDK/JDK8%E6%96%B0%E7%89%B9%E6%80%A7-Lambda/","content":"Lambda 表达式简介允许把函数作为一个方法的参数（传递函数），或者说把代码当作数据。本质上是语法糖方式实现的匿名方法，但这个方法不能独立执行，而要用于实现函数式接口的方法，即，使用 Lambda 表达式实例化函数式接口。因此，Lambda 表达式会导致产生一个匿名类。具体过程是，Lambda 表达式构成了一个函数式接口中（唯一）抽象方法的实现，该函数式接口定义了 Lambda 表达式的目标类型（抽象方法的具体定义）。所以，只有在定义了 Lambda 表达式的目标类型的上下文中，即，该上下文中可以使用相应的接口，才能使用该 Lambda 表达式。当目标类型上下文中出现 Lambda 表达式时，就会自动创建实现了函数式接口的一个类的实例（类似于匿名类），而函数式接口的抽象方法的行为则有 Lambda 表达式定义。通过目标调用该方法时，就会执行 Lambda 表达式。为了在目标类型上下文中使用 Lambda 表达式，抽象方法的类型和 Lambda 表达式的类型必须兼容。eg：如果抽象方法指定了两个 int 型参数，相应的 lambda 表达式的形式就应该是\n\n上下文能够推断参数类型时： (x, y) -&gt; {};\n上下文无法推断参数类型时： (int x, int y) -&gt; {};  如果显式声明一个参数的类型，那么同时必须提供其他剩余参数的类型。\n\n即，Lambda 表达式的参数的类型和数量、返回类型必须和相应的函数式接口的抽象方法兼容，并且 Lambda 表达式可能抛出的异常必须也能被该抽象方法接受。\n闭包函数式语言提供的一种强大的功能：是一个可调用的对象，它记录了一些信息，这些信息来自于创建它的作用域。\n基本语法    (parameters) -&gt; expression或    (parameters) -&gt; {statements;}\n使用和匿名内部类还是有些不同的：匿名内部类只能引用作用域外的 final 修饰的变量（见语法糖部分），而 lambda 表达式则削弱了这一限制：只要是“等效于 final”的变量即可，而不一定非要 final 修饰，也可以认为是隐含转换成了 final 修饰：\nString str = “Hello.”;\nRunnable runnable = () -> System.out.println(str);\nLambda 表达式使用示例Lambda 表达式作用域\n","categories":["java"],"tags":["java","新特性"]},{"title":"Java-JDK8新特性-Stream","url":"/2018/04/28/java/JDK/JDK8%E6%96%B0%E7%89%B9%E6%80%A7-Stream/","content":"[toc]\nStream API简介Stream API (java.util.stream)把真正的函数式编程风格引入到 java 中。这里的 Stream 和 I&#x2F;O 流不同，它更像具有 Iterable 的集合，但行为和集合类又有所不同。官方描述：A sequence of elements supporting sequential &amp; parallel aggregate operations. 可以理解为：\n\nStream 是元素的集合，这让它看起来类似 Iterator；\n支持顺序或并行方式进行聚合操作。\n\n可以把 Stream 当作一个高级版本的 Iterator：对于 Iterator，用户只能按顺序一个一个地遍历元素，过程中对元素执行某些操作；而对于 Stream，用户只要给出需要对元素执行的操作，如“过滤掉长度大于 10 的字符串”、“获取每个字符串的首字母”等，具体这些操作如何应用到每个元素上，则是 Stream 本身需要完成的工作。eg：获取一个 List 中元素不为 null 的个数：\nList&lt;Integer> nums = Lists.newArrayList(1, null, 3, 4, null, 6, 7);\nnums.stream().filter(num -> num != null).count();\n流提供了流畅的 API，可以进行数据转换和对结果执行某些操作，这些流操作既可以是“中间的”，也可以是“末端的”：\n\n中间的：中间的操作保持流打开状态，并允许后续的操作，e.g. filter() 和 map() 方法就是中间的操作。这些操作的返回数据类型还是流，返回当前的流以便串联更多的操作。中间操作是延迟（lazy）的；\n末端的：末端的操作必须是对流的最终操作，当一个末端操作被调用，流被“消耗”并且不可再使用。eg：sum() 方法就是一个末端操作。末端操作会立即开始流中元素的处理。\n\n流操作特性：\n有状态的：有状态的操作给流增加了一些新的属性，如：元素的唯一性&#x2F;元素的最大数量&#x2F;保证元素以排序的方式被处理。这导致比无状态的中间操作代价更大；\n短路：短路操作允许对流的操作尽早停止，而不去检查所有的元素（这跟 &amp;&amp; 条件判断类似）。这是对无限流特殊设计的一个属性，如果对流的操作没有短路，那么代码可能无法终止；\n中间的操作（API 方法）；\n末端的操作（API 方法）。\n\n处理一个流的基本步骤：\n1. 创建 Stream常用途径有两种：\n\n通过 Stream 接口的静态工厂方法：　　三种方式：　　a. of() 方法　　　　接受单一值参数：　　 　　　　 　　static &lt;T> Stream&lt;T>of(T t)：Stream&lt;String> stringStream = Stream.of(\"lazysnail\");　　 　　接受变长参数：　　 　　　　 　　static &lt;T> Stream&lt;T>of(T...values)：Stream&lt;Integer> integerStream = Stream.of(1, 3, 5, 7);　　b. generator() 方法　　　　生成一个无限长度的 Stream，其元素的生成是通过给定的 Supplier（该接口可以看作一个对象的工厂，每次调用返回一个给定类型的对象）：　　　　　　　　static &lt;T> Stream&lt;T>generate(Supplier&lt;T> s);  e.g.\n　　　　// 普通表现形式\n　　　　Stream.generate(new Supplier&lt;Double>() &#123;\n　　　　    @Override\n　　　　    public Double get() &#123;\n        　　　　return Math.random();\n    　　　　&#125;\n　　　　&#125;);\n　　　　// lambda 表达式形式\n　　　　Stream.generate(() -> Math.random());\n　　　　// 方法引用表达形式\n　　　　Stream.generate(Math::random);　　　　以上三种方式作用相同，懒加载生成无限长度的流，一般会配合 limit() 方法触发短路。　　c. iterate() 方法　　　　同样生成无限长度的 Stream，和 generator 不同的是，其元素的生成是重复对给定的种子值（seed）调用指定函数来生成的，元素可以认为是：seed, f(seed), f(f(seed)), …　　　　　　　　static &lt;T> Stream&lt;T>iterate(T seed, UnaryOperator&lt;T> f); e.g.\n　　　　// 先获取一个无限长的正整数集合 Stream，然后打印前 10 个：\n　　　　Stream.iterate(1, item -> item + 1).limit(10).forEach(System.out::println);　　　　同样需要配合 limit() 方法。\n\n通过 Colletcion 接口的默认方法 stream()，把一个 Collection 对象转换成 Stream。　　Collection 接口有个 stream 方法（Since 1.8），其所有实现类都可以获取对应的 Stream 对象：　　　　　　　　Stream&lt;T> stream = collection.stream();\n\n\n2. 转换 Stream执行一个&#x2F;多个中间操作，每次转换都不改变原有 Stream，而是返回一个新的 Stream 对象\n\n中间的操作（API 方法）：　　distinct()：根据 .equals() 的行为排除所有重复元素，有状态的操作；　　　　filter()：过滤所有与断言不匹配的元素；　　\n\n　　map()：通过 Function 对元素执行一对一的转换。有 3 个变种：mapToInt()、mapToLong()、mapToDouble()，即把原始 Stream 转换成一个对应类型的新 Stream，可免除自动装箱&#x2F;拆箱的额外消耗；　　\n　　flatMap()：通过 FlatMapper 将每个元素转变为无或更多的元素，即，每个元素都转换为一个新 Stream 对象，再将子 Stream 的元素压缩到父集合中；　　\n　　limit()：截断，保证后续的操作所能看到的元素的最大数量，有状态的短路操作；　　\n　　skip()：返回一个丢弃原 Stream 前 N 个元素后剩下的元素组成的新 Stream；　　\n　　peek()：生成一个包含原 Stream 的新 Stream，同时提供一个消费函数（Consumer 实例），新 Stream 每个元素被消费的时候都执行给定的消费函数。主要用于调试；　　\n　　sorted()：确保流中的元素在后续的操作中，按照比较器（Comparator）决定的顺序访问，有状态的操作；　　substream()：确保后续的操作只能看到一个范围的（根据 index）元素。有两种形式：有开始索引的、有结束索引的，二者都是有状态的操作，有结束索引的同时也是短路操作。\n性能问题常规操作可能是：如对 Iterable 集合(N 个元素)进行一系列操作，每次都对每个元素进行相应操作，这样的遍历需要 k 次（k 为对每个元素操作的次数），即，时间复杂度为 O(Nk)。而，Stream 提供的转换操作则不同：Stream 的中间转换操作都是 lazy 的：多个转换融合到聚合阶段（reduce&#x2F;fold）通过一次循环完成。i.e. Stream 里有个操作函数的集合，每个转换操作就是把转换函数放入到这个集合中，在聚合操作的时候，循环这个集合，对每个元素执行该集合操作。\n3. 聚合&#x2F;折叠（Reduce&#x2F;Fold）执行一个末端操作，i.e. 对 Stream 进行聚合操作，获得结果。接受一个元素序列作为输入，反复使用某个聚合操作，把序列中的元素聚合成一个总的结果。e.g. 查找一个数字列表的总和或最值、把这些数字累积成一个 List 对象等。\n\nStream 接口通用的聚合操作：reduce()、collect()等；\n特定用途的聚合操作：sum()、count()等；Note：sum() 方法只有 IntStream、LongStream、DoubleStream 的实例才拥有。\n\n末端的操作（API 方法）：　　forEach()：对流中每个元素执行一些操作；　　toArray()：将流中的元素倾倒入一个数组；　　reduce()：通过一个二进制操作将流中的元素合并到一起；　　collect()：将流中的元素倾倒入某些容器，e.g. 一个 Collection 或 Map；　　min()：根据一个比较器找到流中元素的最小值；　　max()：根据一个比较器找到流中元素的最大值；　　count()：计算流中元素的数量；　　anyMatch()：判断流中是否 至少有一个元素 匹配断言，短路操作；　　allMatch()：判断流中是否 每一个元素都 匹配断言，短路操作；　　noneMatch()：判断流中是否 没有任何一个元素 匹配断言，短路操作；　　findFirst()：查找流中的第一个元素，短路操作；　　findAny()：查找流中任意元素，对某些流代价可能比 findFirst 低，短路操作。\n聚合分类可变聚合：把输入的元素累积到一个可变的容器中，e.g. Collection、StringBuilder 等。collect()方法可以把Stream中的所有元素收集到一个结果容器中（e.g. Collection）\n// Supplier supplier是一个工厂函数，用来生成一个新的容器；BiConsumer accumulator也是一个函数，\n// 用来把Stream中的元素添加到结果容器中；BiConsumer combiner还是一个函数，\n// 用来把中间状态的多个结果容器合并成为一个（并发的时候会用到）。\n&lt;R, A> Rcollect(Collector&lt;? super T, A, R> collector)\n&lt;R> R collect(Supplier&lt;R> supplier, BiConsumer&lt;R, ? super T> accumulator, BiConsumer&lt;R, R> combiner)\n\n// e.g. 对一个元素是Integer类型的List，先过滤掉全部的null，然后把剩下的元素收集到一个新的List中。\nList&lt;Integer> nums = Lists.newArrayList(1, 1, null, 2, 3, 4, null, 5, 6, 7, 8, 9, 10);\nList&lt;Integer> numsWithoutNull = nums.stream().filter(num -> num != null).collect(\n        () -> new ArrayList&lt;Integer>(), (list, item) -> list.add(item), (list1, list2) -> list1.addAll(list2)\n    );\n    // Note:\n    // 第一个函数生成一个新的ArrayList实例；\n    // 第二个函数接受两个参数，第一个是前面生成的ArrayList对象，\n    // 第二个是stream中包含的元素，函数体就是把stream中的元素加入ArrayList对象中。\n    // 第二个函数被反复调用直到原stream的元素被消费完毕；\n    // 第三个函数也是接受两个参数，这两个都是ArrayList类型的，\n    // 函数体就是把第二个ArrayList全部加入到第一个中。\n\n其他聚合：reduce()、count()、sum()等方法。\nreduce()方法有三种形式：\nOptional&lt;T> reduce(BinaryOperator&lt;T> accumulator)\nT  reduce(T identity, BinaryOperator&lt;T> accumulator)\n&lt;U> U reduce(U identity, BiFunction&lt;U, ? super T, U> accumulator, BinaryOperator&lt;U> combiner)\n\n// e.g. 一个参数的reduce方法：\nList&lt;Integer> ints = Lists.newArrayList(1, 2, 3, 4, 5, 6, 7, 8, 9, 10);\nSystem.out.println(\"ints sum is: \" + ints.stream().reduce((sum, item) -> sum + item).get());\n// 这个函数有两个参数，第一个参数是上次函数执行的返回值（也称为中间结果），\n// 第二个参数是stream中的元素，这个函数把这两个值相加，\n// 得到的和会被赋值给下次执行这个函数的第一个参数。\n// 第一次执行的时候第一个参数的值是Stream的第一个元素，第二个参数是Stream的第二个元素。\n// 返回类型是Optional，这是Java8防止出现NPE的一种可行方法。\n\n// e.g. 两个参数的reduce方法：\nList&lt;Integer> ints = Lists.newArrayList(1, 2, 3, 4, 5, 6, 7, 8, 9, 10);\nSystem.out.println(\"sum is: \" + ints.stream().reduce(0, (sum, item) -> sum + item));\n// 它允许用户提供一个循环计算的初始值，如果Stream为空，就直接返回该值。\n// 这个方法不会返回Optional，因为其不会出现null值。\n\n// e.g. count()方法示例：\nList&lt;Integer> ints = Lists.newArrayList(1, 2, 3, 4, 5, 6, 7, 8, 9, 10);\nSystem.out.println(\"sum is:\" + ints.stream().count());\n\nStream 示例生成斐波那契数列示例（利用Stream API，可以设计更加简单的数据接口。）\n// 生成斐波那契数列，完全可以用一个无穷流表示\n// 受限long型大小，可以改为BigInteger。\nclass FibonacciSupplier implements Supplier&lt;Long> &#123;\n    long a = 0;\n    long b = 1;\n\n    @Override\n    public Long get() &#123;\n        long x = a + b;\n        a = b;\n        b = x;\n        return a;\n    &#125;\n&#125;\n\npublic class FibonacciStream &#123;\n    public static void main(String[] args) &#123;\n        Stream&lt;Long> fibonacci = Stream.generate(new FibonacciSupplier());\n        fibonacci.limit(10).forEach(System.out::println);\n\n        //如果想取得数列的前10项，用limit(10)，如果想取得数列的第20~30项,用skip()，\n        //通过collect()方法把Stream变为List。该List存储的所有元素就已经是计算出的确定的元素了.\n        List&lt;Long> list = fibonacci.skip(20).limit(10).collect(Collectors.toList());\n    &#125;\n&#125;\n\nStream 的串行和并行一个流就像一个地带器，这些值流过（遍历）的过程中接受某些处理。流支持串行或并行，也可以从一种方式切换到另一种方式，使用 stream.sequential() 切换串行、stream.parallel() 切换并行，串行流在一个线程上连续操作，并行流可能出现在多个线程上。在并行化一个流前，需要考虑很多特性，关于流、它的操作以及数据的目标方面等。e.g. 访问顺序确实对我有影响吗？我的函数是无状态的吗？我的流有足够大，并且我的操作有足够复杂，这些能使得并行化是值得的吗？\nStream vs Collection\nCollection 是关于静止的数据结构，而 Stream 是有关动词算法和计算的。\nCollection 是主要面向内存，存储在内存中；Stream 主要是面向 CPU，通过 CPU 实现计算。\n\n为什么不在集合类实现元素迭代等操作，而是定义了全新的Stream API？Oracle官方给出的解释：\n\n集合类持有的所有元素都是存储在内存中的，非常巨大的集合类会占用大量的内存，而Stream的元素却是在访问的时候才被计算出来，这种“延迟计算”的特性有点类似Clojure的lazy-seq，占用内存很少。\n集合类的迭代逻辑是调用者负责，通常是for循环，而Stream的迭代是隐含在对Stream的各种操作中，e.g. map()。\n\n要理解“延迟计算”，不妨创建一个无穷大小的Stream：如果要表示自然数集合，显然用集合类是不可能实现的，因为自然数有无穷多个。但是Stream可以做到：\n/**\n * 自然数集合的规则非常简单，每个元素都是前一个元素的值+1。\n * 反复调用get()，将得到一个无穷数列，利用这个Supplier，可以创建一个无穷的Stream\n */\nclass NaturalSupplier implements Supplier&lt;Long> &#123;\n    long num = 0;\n\n    public Long get() &#123;\n        this.num = this.num + 1;\n        return this.num;\n    &#125;\n&#125;\n\npublic class NaturalNum &#123;\n    public static void main(String[] args) &#123;\n        /**\n         * 对这个Stream做任何map()、filter()等操作都是完全可以的，这说明Stream API对Stream进行转换并\n         * 生成一个新的Stream并非实时计算，而是做了延迟计算。\n         * 当然，对这个无穷的Stream不能直接调用forEach()，这样会无限打印下去。但是我们可以利用limit()变换，\n         * 把这个无穷Stream变换为有限的Stream。\n         */\n        Stream&lt;Long> natural = Stream.generate(new NaturalSupplier());\n        natural.map((x) -> &#123;\n            return x * x;\n        &#125;).limit(10).forEach(System.out::println);\n    &#125;\n&#125;\n\n\nStream 类\n","categories":["java"],"tags":["java","新特性"]},{"title":"Java-JDK8新特性-接口变化","url":"/2018/04/28/java/JDK/JDK8%E6%96%B0%E7%89%B9%E6%80%A7-%E6%8E%A5%E5%8F%A3%E5%8F%98%E5%8C%96/","content":"[toc]\n接口默认方法（default method）这个比较容易理解，JDK 1.8 之前的接口中，所有的变量都是（public static final）的，所有的方法都是抽象（public static）的，即不能有具体实现。而实现了该接口的类，必须实现接口的所有抽象方法。到了 JDK 1.8，方法定义上有了变化，允许为接口方法提供实现，即接口可以添加非抽象的方法实现，只需要使用 default 关键字即可，这类方法叫做默认方法（扩展方法）。这时，实现了该接口的类，可以选择不实现接口的默认方法，即，继承接口的该方法的实现，行为和接口实现一致。\n接口静态方法JDK 1.8 支持 用 static 修饰接口方法，并且可以实现。此时，只能通过接口名调用该方法，不能通过类名或类的实例对象调用。\n函数式接口（Functional Interface）函数式接口当作普通接口使用时，并没有什么特别之处。定义上和普通接口有一些区别：\n\n是一个接口；\n只有一个待实现的方法，即只有一个抽象方法。\n默认方法和静态方法不影响函数式接口的约定；\n函数式接口可以定义 Object 类定义的任何共有方法（不能修改其方法描述，即不改变其返回类型，参数类型和个数等），如 equals()，而不影响函数式接口的约定：Object 的共有方法被视为函数式接口的隐式成员，因为函数式接口的实例会默认自动实现它们。\n\n与此对应地，新引入了一个注解：@FunctionalInterface。只起到文档的作用，说明这是个函数式接口。编译器并不会使用这个注解来判定一个接口是不是函数式接口。可以认为函数式接口的引入是为了配合 lambda 表达式。\n","categories":["java"],"tags":["java","新特性"]},{"title":"Java-JDK8新特性-方法引用","url":"/2018/04/28/java/JDK/JDK8%E6%96%B0%E7%89%B9%E6%80%A7-%E6%96%B9%E6%B3%95%E5%BC%95%E7%94%A8/","content":"方法引用(Method Reference)简介用来直接访问类或实例的已经存在的方法或构造函数，提供了一种引用而不执行方法的方式，它需要由兼容的函数式接口构成的目标类型上下文，计算时，方法引用会创建函数式接口的一个实例。当 Lambda 表达式只是执行一个方法调用时，不用 Lambda 表达式而直接通过方法引用的形式能提高可读性。方法引用是一种更简洁易懂的 Lambda 表达式。可以认为：\n\n 方法引用的唯一用途是支持 Lambda 的简写：提高可读性，使得逻辑更加清晰。\n\n基本语法对象名&#x2F;类名 :: 方法名eg:\n\n\n\nLambda表达式\n对应的方法引用\n\n\n\nx -&gt; String.valueOf(x)\nString::valueOf\n\n\nx -&gt; x.toString()\nObject::toString\n\n\n() -&gt; x.toString()\nx::toString\n\n\n() -&gt; new ArrayList&lt;&gt; ()\n() -&gt; new ArrayList&lt;&gt;()\n\n\n分类\n静态方法引用\n\n格式：className::staticMethodName\ninterface StringFunc &#123;\n    String func(String str);\n&#125;\n\nclass StringOps &#123;\n    // 静态方法，反转字符串\n    public static String strReverse(String str) &#123;\n        String res = \"\";\n        for (int i = str.length() - 1; i >= 0; i--) &#123;\n            res += str.charAt(i);\n        &#125;\n        return res;\n    &#125;\n&#125;\n\npublic class MethodRef &#123;\n    public static String stringOps(StringFunc sf, String s) &#123;\n        return sf.func(s);\n    &#125;\n\n    public static void main(String[] args) &#123;\n        String str = \"Static Method Reference.\";\n        // StringOps::strReverse 相当于实现了接口方法 func(),\n        // 并在接口方法中使用了 StringOps.strReverse() 操作\n        String res = stringOps(StringOps::strReverse, str);\n        System.out.println(\"Origin str: \" + str);\n        System.out.println(\"str reserved: \" + res);\n    &#125;\n&#125;\n\n实例方法引用\n\n分为实例上的实例方法引用、超类上的实例方法引用、类型上的实例方法引用。上述代码，如果反转字符串方法不是静态方法，而是普通方法，则就需要 StringOps 实例化一个对象(strOps)，并通过该对象调用：    String res &#x3D; StringOps(strOps::strReverse, str);\n\n构造方法引用\n\n分为 构造方法引用（构造器引用）、数组构造方法引用。\n","categories":["java"],"tags":["java","新特性"]},{"title":"Java-JDK8新特性-Optional","url":"/2018/04/28/java/JDK/Optional/","content":"[toc]\nOptional简述字面意思是“可选的”，这里的语义是“指某个值可能有也可能没有（null）”。是为了解决 NullPointerException 空指针异常，通过使用检查空值的方式来防止代码污染。本身是一个容器，其值可能是 null 或者不是 null，java 1.8 之前一般某个函数应该返回空对象但偶尔也可能返回 null，而 java 1.8 开始，推荐返回 Optional 而非 null。\n较之 JavaDocs、@NotNull，本质上，Optional是把处理返回值为空的情况这一责任强加给调用者，即调用者必须考虑这一情况（以避免NPE）。\n优点\n显式提醒开发者需要关注 null 的情况，是一种字面上的约束；\n将平时的一些显式的防御性检测标准化，并提供一些可串联操作；\n解决 null 导致疑惑的概念，e.g. Map 里的 key&#x3D;&#x3D;null 的情况，value&#x3D;&#x3D;null 的情况。\n\n使用为了防止抛出 java.lang.NullPointerException 异常，一般写法：\nStudent student = person.find(\"Neil\");  \n        if (student != null) &#123;  \n            student.doSomething();  \n        &#125;  \n使用Optional的代码写法：\nStudent student = person.find(\"Neil\");  \n        if (student.isPresent()) &#123;  \n            student.get().doSomething();  \n        &#125;  \n如果 isPresent() 返回false，说明这是个空对象；否则，就可以把其中的内容取出来做相应的操作。单从代码量上来说，Optional的代码量并未减少，甚至比原来的代码还多。优点在于不会忘记判空，因为这里得到的不是Student类的对象，而是Optional 类对象。\n实现的方法3 种构造方法\nOptional.of(obj)：要求传入的 obj 不能是 null 值，通过工厂方法创建一个 Optional 类；　　使用：　　当明确将要传给 of() 的 obj 参数不可能为 null 时，e.g. 传入刚 new 出来的对象、非 null 常量时；　　当需要断言 obj 为null 则立即报告 NPE 而不是隐藏空指针异常时；　　i.e. 避免不可预计的 null 传入 Optional。\nOptional.ofNullable(obj)：of方法相似，唯一的区别是可以接受参数为null的情况，此时返回 Optional.empty()，否则返回 Optional.of()；\nOptional.empty()：返回一个空Optional实例。\n\n用法举例用法举例2\n 使用 Optional 时尽量不直接调用 Optional.get() 方法, Optional.isPresent() 更应该被视为一个私有方法, 应依赖于其他像 Optional.orElse(), Optional.orElseGet(), Optional.map() 等这样的方法。\nHow to use Optionals In Java\n","categories":["java"],"tags":["java","新特性"]},{"title":"晚期运行期优化","url":"/2018/04/27/java/JVM/%E6%99%9A%E6%9C%9F%E8%BF%90%E8%A1%8C%E6%9C%9F%E4%BC%98%E5%8C%96/","content":"Java 程序最初是通过解释器（Interpreter）进行解释执行的。而当 JVM 发现某个方法或代码块的运行特别频繁时，就会把这些代码认定为 “热点代码（Hot Spot Code）”。为了提高热点代码的执行效率，在运行时，JVM 将会把这些代码编译成与本地平台相关的机器码，并进行各种层次的优化，完成这个任务的编译器称为 即时编译器（Just In Time Compiler，JIT 编译器）。主流 JVM 一般同时包含解释器和编译器。它们各有优势：\n\n当程序需要快速启动和执行时，解释器可以首先发挥作用，省去编译时间，立即执行；\n在运行期间随着时间推移，编译器逐渐发挥作用，把越来越多的代码编译成本地代码，从而获得更高的执行效率。\n当运行环境中内存资源限制较大（如嵌入式系统），可以使用解释器执行以节约内存；反之可以使用编译器执行来提升效率；\n解释器还作为编译器激进优化时的“逃生门”：深层次优化不成立时回退到解释状态继续执行；等实际中，二者一半是配合工作。\n\nHotSpot 的分层编译（Tiiered Compilation）优化根据编译器编译、优化的规模与耗时，划分出不同的编译层次：\n\n第 0 层，程序解释执行，解释器不开启性能监控功能（Profiling），可触发第 1 层编译；\n第 1 层（C1 编译），将字节码编译为本地代码，进行简单、可靠的优化，如有必要则加入性能监控的逻辑；\n第 2 层&#x2F; 2层以上（C2 编译），将字节码编译为本地代码，会启用一些编译耗时较长的优化，甚至根据性能监控信息进行一些激进&#x2F;不可靠的优化。\n\n实施分层编译后，两个编译器 Client Compiler 和 Server Compiler 会同时工作，许多代码可能会被多次编译：用 Client Compiler 获取更高的编译速度，用 Server Compiler 获取更好的编译质量。\n热点代码&amp;触发条件可见，热点代码有两类：\n\n被多次调用的方法\n被多次执行的循环体\n\n两种情况都是以方法为粒度进行 JIT 编译。尽管后者编译动作是由循环体触发，但编译器仍以整个方法为编译对象。这种编译方式因为发生在方法执行过程中，因此形象地称之为 栈上替换（On Stack Replacement，简称 OSR 编译，即方法栈帧还在栈上，方法就被替换了）。\n判断一段代码是不是热点代码，是不是需要触发 JIT，这样的行为成为热点探测（Hot Spot Detection）。目前常用的方法有两种：\n\n基于采样的热点探测（Sample Based Hot Spot Detection）：JVM 周期性检查各个线程的栈顶，如果发现某个&#x2F;某些方法经常出现在栈顶，那这个方法就是“热点方法”。该方法 实现简单、高效，还可以很容易地获取方法调用关系（将调用堆栈展开即可）。而缺点是 难以精确确认一个方法的热度：容易受到线程阻塞或其他外界因素影响而扰乱热点探测。\n基于计数器的热点探测（Counter Based Hot Spot Detection）：JVM 为每个方法（甚至代码块）建立计数器，统计方法的执行次数，超过特定阈值即认为它是“热点代码”。该方法 统计结果相对精确和严谨；但 实现复杂：需要为每个方法建立并维护计数器，且不能直接获取方法的调用关系。\n\nHotSpot 的实现（Client模式）HotSpot 使用的是第二种方法，且为每个方法准备了两类计数器：方法调用计数器（Invocation Counter）和回边计数器（Back Edge Counter）。在确定了 JVM 运行参数后，这两个计数器都有一个确定的阈值，溢出就会触发 JIT 编译。\n方法调用计数器部分方法调用计数器，就是上面的定义。其默认阈值在 Client 模式下是 1500 次，Server 模式下是 10000 次，可通过 -XX: CompileThreshold 配置。当一个方法被调用时，会先检查该方法是否已存在被编译过的版本，如果存在，优先使用它来执行，否则将该方法的调用计数器 +1，然后判断调用计数器与回边计数器之和是否超过方法调用计数器的阈值，如果超过则向 JIT 编译器提交一个该方法的代码编译请求。不做任何设置情况下，执行引擎不会同步等待编译器请求完成，而是继续进入解释器按照解释方式执行字节码，直到提交的请求被编译器编译完成。当编译工作完成后，这个方法的调用入口地址会被系统自动改写成新的，下一次调用该方法时就会使用已编译的版本。\n\n\n方法调用计数器的衰减不做任何设置情况下，方法调用计数器统计的不是方法被调用的绝对次数，而是一段时间内的次数：当超过一定的时间限度，如果该方法的调用次数仍不足以触发，那么方法调用计数器数值就要减半，这一过程称为 方法调用计数器热度的衰减（Counter Decay），而这段时间就称为该方法的 半衰周期（Counter Half Life Time）。进行热度衰减的动作是在 JVM 进行 GC 时顺便进行的，可使用 -XX: UseCounterDecay 来关闭热度衰减，让方法调用计数器统计绝对次数。这样，只要程序运行时间足够长，大部分方法都会被编译成本地代码。还可以用 -XX: CounterHalfLifeTime 设置半衰周期的时间（秒）。\n回边计数器部分在字节码中遇到控制流向后跳转的指令称为“回边（Back Edge）”。用于统计一个方法中循环体代码执行的次数（准确说是回边次数，比如空循环就不算控制流跳转，也不会被回边计数器统计）。显然，回边计数器是为了触发 OSR 编译。回边计数器阈值计算方式与方法调用计数器阈值和 OSR 比率、解释器监控比率等有关，也和编译器模式（Client、Server）有关。当解释器遇到一条回边指令时，会先查找将要执行的代码片段是否已有编译好的版本，如果有，优先使用它来执行，否则就把回边计数器 +1，然后判断方法调用计数器与回边计数器之和是否超过回边计数器的阈值，如果超过则提交一个 OSR 编译请求，并且把回边计数器的值降低一些，以便继续在解释器中执行循环，等待编译器输出编译结果。回边计数器没有热度衰减的过程，所以统计的是绝对次数。\n\n\nServer VM 的 JIT 会更复杂一些，但流程总体大致如此。上述两种提交，也可以通过 -XX: BackgroundCompilation 配置来禁止后台编译，这样提交编译请求后，执行线程会等待编译完成，然后使用编译后的本地代码继续执行。\n后台编译过程Client Compiler：简单快速的三段式编译器，主要关注点在于局部性的优化，放弃了许多耗时较长的全局优化手段。\n\n一个平台独立的前端将字节码构造成一种高级中间代码表示（High-Level Intermediate Representaion，HIR）。HIR使用静态单分配（Static Single Assignment，SSA）的形式来代表代码值，这可以使得一些在HIR的构造过程之中和之后进行的优化动作更容易实现。在此之前编译器会在字节码上完成一部分基础优化，如方法内联、常量传播等优化将会在字节码被构造成HIR之前完成。\n一个平台相关的后端从HIR中产生低级中间代码表示（Low-Level Intermediate Representation，LIR），而在此之前会在HIR上完成另外一些优化，如空值检查消除、范围检查消除等，以便让 HIR 达到更高效的代码表示形式。\n在平台相关的后端使用线性扫描算法（Linear Scan Register Allocation）在LIR上分配寄存器，并在LIR上做窥孔（Peephole）优化，然后产生机器代码。\n\n\n\nServer Compiler：专门面向服务端的典型应用并为服务端的性能配置特别调整过的编译器，也是一个充分优化过的高级编译器，几乎能达到GNU C++编译器使用-O2参数时的优化强度，它会执行所有经典的优化动作，如无用代码消除（Dead Code Elimination）、循环展开（Loop Unrolling）、循环表达式外提（Loop ExpressionHoisting）、消除公共子表达式（Common Subexpression Elimination）、常量传播（Constant Propagation）、基本块重排序（Basic Block Reordering）等，还会实施一些与Java语言特性密切相关的优化技术，如范围检查消除（Range Check Elimination）、空值检查消除（Null Check Elimination，不过并非所有的空值检查消除都是依赖编译器优化的，有一些是在代码运行过程中自动优化了）等。另外，还可能根据解释器或Client Compiler提供的性能监控信息，进行一些不稳定的激进优化，如守护内联（Guarded Inlining）、分支频率预测（BranchFrequency Prediction）等。本章的下半部分将会挑选上述的一部分优化手段进行分析和讲解。Server Compiler的寄存器分配器是一个全局图着色分配器，它可以充分利用某些处理器架构（如RISC）上的大寄存器集合。以即时编译的标准来看，Server Compiler无疑是比较缓慢的，但它的编译速度依然远远超过传统的静态优化编译器，而且它相对于Client Compiler编译输出的代码质量有所提高，可以减少本地代码的执行时间，从而抵消了额外的编译时间开销，所以也有很多非服务端的应用选择使用Server模式的虚拟机运行。\nJIT编译过程是一个虚拟机中最体现技术水平也是最复杂的部分。\n","categories":["java"],"tags":["java","JVM"]},{"title":"Java-语法糖","url":"/2018/04/27/java/into/java-%E8%AF%AD%E6%B3%95%E7%B3%96/","content":"关于语法糖（Syntactic Sugar）也称糖衣语法，由英国计算机科学家 Peter J · Landin 发明的一个术语，指在计算机预言中添加的某种语法，这种语法对语言的功能并没有影响，但是更方便程序员使用。通常，使用语法糖能够增加程序的可读性，从而减少代码出错的机会。\nJava 中最常用的语法糖主要有：泛型、内部类、自动装箱&#x2F;拆箱、循环遍历、变长参数、条件编译等。JVM 运行时并不支持这些语法，它们在编译阶段还原回简单的基础语法结构，这个过程称为解语法糖。解语法糖的执行在 javac 中，查看 com.sun.tools.javac.main.JavaCompiler 源码可见，在 compile() 中有一个步骤是 desugar()。\n泛型Java 语言中的泛型（Since 1.5），本质是 参数化类型（Parametersized Type） 的应用：即，所操作的数据类型被指定为一个参数。这种参数类型可以用在类、接口和方法的创建中，分别称称为泛型类、泛型接口、泛型方法。它只存在于程序源码中，在编译后的字节码文件中，已经替换为原来的原生类型（Raw Type，也称裸类型），并且在相应地方插入了强制类型转换（运行期间，ArrayList 和 ArrayList 就是同一个类）。java 语言中泛型的这种实现方法被称为类型擦除，基于这种方法实现的泛型称为伪泛型（相对地，类似 C# 的“类型膨胀”实现方法则称为真实泛型）。\n内部类内部类分为 4 种：成员内部类、局部内部类、匿名内部类、静态内部类。从编译结果看，内部类会编译出一个单独的 .class 文件。\n\n成员内部类：最常见的一种形式。特点：不可以定义 static 方法；private 类型对外不可见；public 类型对外可见；成员内部类可以访问其外部类的私有属性，如果成员内部类的属性和其外部类的属性重名，则以成员内部类的属性值为准。\n\n局部内部类：定义在一个方法或者特定作用域里面的类。特点：没有访问修饰符；局部内部类要访问外部的变量或者对象，该变量或对象的引用必须是用final修饰的。\n\n匿名内部类：在多线程模块中大量使用了匿名内部类，使用方便，应用广泛。特点：匿名内部类是唯一没有构造器的类；用范围很有限，一般用于继承抽象类或实现接口（注意只能继承抽象类，不能继承普通类）；Java自动为之起名为XXX$1.classs；部内部类一样，要访问外部的变量或者对象，该变量或对象的引用必须是用 final 修饰的\n\n静态内部类：用static修饰的内部类。特点：可以有静态方法，也可以有非静态方法；只能访问其外部类的静态成员与静态方法；和普通的类一样，要访问静态内部类的静态方法，可以直接类名”.”方法名；要访问静态内部类的非静态方法，必须通过实例；注意一下实例化成员内部类和实例化静态内部类这两种不同的内部类时写法上的差别（1）成员内部类：外部类.内部类 XXX &#x3D; 外部类.new 内部类();（2）静态内部类：外部类.内部类 XXX &#x3D; new 外部类.内部类();\n\n\n条件编译很多语言都提供了条件编译途径，如 C、C++ 中使用预处理器提示符（#ifdef、#endif）来完成条件编译。C、C++ 的预处理器最初的任务是解决编译时的代码依赖关系（如最常见的 #include 预处理命令）。而 java 编译方式则无须使用预处理器——编译器不是一个个地编译 java 文件，而是将所有编译单元的语法树顶级节点输入到待处理列表后再进行编译，因此各个文件之间能够提供符号信息。java 中进行条件编译的方法是：使用条件为常量的 if 语句。\n循环遍历 foreach对于数组的 foreach 循环，javac 直接解析为普通的 for 循环；而对于 List、String 等类型，它们能使用 foreach 的基础是都实现了 Iterator 接口，即，javac 会使用该接口的 hasNetx() 方式完成遍历，这就意味着，需要保证要遍历的对象非空。\n变长参数·   ··1本质上是基于数组的实现。\n使用规则\n优先匹配定长参数，如果匹配到多个含可变参数的方法，编译无法通过；\n变长参数必须作为方法参数列表的最后一个参数，这句话同时隐含了：方法参数列表最多只能有一个可变长参数。\n\n应该避免带有变长参数的方法重载，注意 null 值 和空值可能会影响到变长方法，正确方式是将一个指向 null 的 String 数组作为“可变长”参数传入。\n","categories":["java"],"tags":["java"]},{"title":"String","url":"/2018/04/26/java/SourceCode/String/","content":"&#x3D;&#x3D; vs equals() 比较问题java 中，equals()方法被认为是对对象的值进行深层次的比较，而“&#x3D;&#x3D;”是进行浅层次的比较：&#x3D;&#x3D;\n\n当比较对象是值类型（如基本数据类型）时，对比的是数据的值，此时效果等同于 equals()；\n当比较对象是对象引用时，只要左右两边引用指向同一个地址，才为真，否则，即使两个对象的内容完全一样，也为假。\n\nequals()equals() 比较两个对象的内容，相同返回真。在 String 中，按照如下顺序工作（其他对象也类似）：\n\n比较引用，如果相同，返回 true；\n比较类型，如果类型不同，返回 false；\n比较长度，不等时，返回 false；\n逐字符比较两个字符串，遇到不同，返回 false；\n不满足 2-4，返回 true。\n\n要注意的是，equals()是在 Object 类中的，而 java 中“一切皆是对象”，所以，如果被比较的对象没有覆盖 Object 类中的 equals()的话，必然返回真，这与事实可能不符。而 String 等类型都已经重写了 equals() 方法。另外，jls 规定了 equals()遵循的几个规则：\n\n自反性：对于任何非空引用值 x，x.equals(x) 都应返回 true。\n对称性：对于任何非空引用值 x 和 y，当且仅当 y.equals(x) 返回 true 时，x.equals(y) 才应返回 true。\n传递性：对于任何非空引用值 x、y 和 z，如果 x.equals(y) 返回 true，并且 y.equals(z) 返回 true，那么 x.equals(z) 应返回 true。\n一致性：对于任何非空引用值 x 和 y，多次调用 x.equals(y) 始终返回 true 或始终返回 false，前提是对象上 equals 比较中所用的信息没有被修改。\n对于任何非空引用值 x，x.equals(null) 都应返回 false。\n\n字符串常量池字符串的分配，和其他的对象分配一样，耗费高昂的时间与空间代价。JVM 为了提高性能和减少内存开销，在实例化字符串常量的时候进行了一些优化。为了减少在 JVM 中创建的字符串的数量，字符串类维护了一个字符串池，每当代码创建字符串常量时，JVM 会首先检查字符串常量池。如果字符串已经存在池中，就返回池中的实例引用。如果字符串不在池中，就会实例化一个字符串并放到池中。Java 能够进行这样的优化是因为字符串是不可变的，可以不用担心数据冲突进行共享。这是 java 节约资源的一种方式。从 JVM 角度讲，它属于方法区的运行时常量池的一部分。字符串常量总是指向字符串池中的一个对象，而通过 new 操作符创建的字符串对象不指向字符串池中的任何对象，但是可以通过使用字符串的 intern() 方法来指向其中的某一个。有两种方式进入 String 常量池：\n\n编译期：通过双引号声明的常量（显示声明、静态编译优化后的常量等），JIT 优化也可能产生一些；\n运行期：调用 String 的 intern()方法，可能会将该 String 对象动态地写入。\n\n方式1 的行为是明确的，从 class 文件结构、类加载、编译期及运行期优化等过程都可以很明确地得知。而方式2 在不同 JDK 甚至有不同行为。\n两种创建方式注意到以下代码结果：\nMain.javapublic class Main &#123;\n    public static void main(String[] args) &#123;\n        String s1 = new String(\"123\");\n        String s2 = new String(\"123\");\n\n        String s3 = \"123\";\n        String s4 = \"123\";\n\n        System.out.println(s1 == s2);\n        System.out.println(s3 == s4);\n    &#125;\n&#125;\n------- output: -------\nfalse\ntrue\ns1、s2 是 java 标准的对象创建方式，每调用一次就会在堆上创建一个新的对象，并指向它，同时创建一个相同内容的 String 对象存储在常量池中，如果常量池已存在则不重复创建（事实上 String 常量池只保存一份相同内容的String）；而 s3、s4 则是在栈中创建对象引用变量 str，然后查看 String 常量池中是否存在含有该内容的 String 对象，如果存在，则令 str 直接指向它，如果不存在，则先在池中创建该字符串，然后令 str 指向它。这样充分利用了栈的数据共享的优点。故，s1 和 s2 分别指向不同的两个对象，s3 和 s4 指向的则是同一个地址。考虑到前述事实，如果用 equals() 比较 s1 和 s2 的话，将返回 true。\n注意到以下代码：\npublic class Main &#123;\n    public static void main(String[] args) &#123;\n        String s1 = \"123\";\n        String s2 = \"12\";\n        final String s3 = \"12\";\n        String s4 = \"3\";\n\n        String s5 = \"12\" + \"3\";\n        String s6 = s2 + s4;\n        String s7 = s3 + s4;\n        String s8 = s3 + \"3\";\n        String s9 = new String(\"12\") + \"3\";\n\n        System.out.println(s1 == s5);\n        System.out.println(s1 == s6);\n        System.out.println(s1 == s7);\n        System.out.println(s1 == s8);\n        System.out.println(s1 == s9);\n    &#125;\n&#125;\n------- output: -------\ntrue\nfalse\nfalse\ntrue\nfalse\n这里引出以下问题：\n字符串拼接方法append()方法（StringBuilder&#x2F;StringBuffer）源码（手动添加注释）：\npublic AbstractStringBuilder append(String str) &#123;\n    if (str == null)\n        return appendNull();\n    int len = str.length();\n    // 追加后的字符数组长度是否超过当前值\n    ensureCapacityInternal(count + len);\n    // 复制到目标数组\n    str.getChars(0, len, value, count);\n    count += len;\n    return this;\n&#125;\nprivate AbstractStringBuilder appendNull() &#123;\n    int c = count;\n    ensureCapacityInternal(c + 4);\n    final char[] value = this.value;\n    value[c++] = 'n';\n    value[c++] = 'u';\n    value[c++] = 'l';\n    value[c++] = 'l';\n    count = c;\n    return this;\n&#125;\nprivate void ensureCapacityInternal(int minimumCapacity) &#123;\n    // overflow-conscious code\n    if (minimumCapacity - value.length > 0) &#123;\n        // 加长并拷贝\n        value = Arrays.copyOf(value, newCapacity(minimumCapacity));\n    &#125;\n&#125;\n可以看出，整个 append()方法是通过字符数组的加长、拷贝等处理完成的，没有生成中间对象，只有最后用 toString()返回一个 String 对象。速度最快。\nconcat()方法继续看源码：\npublic String concat(String str) &#123;\n    int otherLen = str.length();\n    if (otherLen == 0) &#123;\n        return this;\n    &#125;\n    // 获取原字符串数组长度\n    int len = value.length;\n    // 将原字符串的字符数组拷贝到 buf 数组\n    char buf[] = Arrays.copyOf(value, len + otherLen);\n    // 追加的字符串转化为字符数组，添加到 buf 中\n    str.getChars(buf, len);\n    // 产生一个新的对象\n    return new String(buf, true);\n&#125;\n整体是一个数组的拷贝，在内存中是原子操作，速度也很快，但最后返回语句会新建一个对象，这对速度有一定影响。\n** “+” **虽然编译器对“+”做了优化，会使用 StringBuilder 的 append()方法进行追加，但它最终会通过 toString()方法转换成 String 字符串，速度比较慢。其过程为：\n\n创建 StringBuilder 对象；\n执行完毕调用 toString() 方法。\n\n具体情况分为：如果加号两边都是字面量（或等效于字面量），形如String str &#x3D; “abc” + “123”;此时的处理方式是直接将 str 作为一个对象处理，相当于先处理右边的加号，再进行创建，参考上面的“&#x3D;”创建规则：String str &#x3D; “abc123”;否则，形如：String str &#x3D; “abc”;str +&#x3D; “123”;此时执行情况则明显不同，相当于将 str 内容取出，再与第二个字符串进拼接，返回新生成的字符串，注意这里有新建动作，所以创建规则相当于使用“new”：String str &#x3D; new StringBuilder(str).append(“123”).toString();即，执行完毕会有 3 个对象存在。而 final 相当于宏，编译器在编译期会把所有用 final 定义的变量直接用定义值替换掉（宏替换）。这就解释了以上代码的结果。\n使用场景：\n\n大多数情况，使用“+”，它符合编码习惯以及可读性较好；\n当频繁进行字符串的运算（拼接、替换、删除等）时，或在系统性能临界的时候，应考虑使用 append() 和 concat()。\n\nString、StringBuffer、StringBuilder简单讲，**String：字符串常量（String 为 final 修饰类）；StringBuffer：字符串变量，线程安全。StringBuilder：字符串变量，非线程安全；**\nStringBuffer（Since JDK1.0）线程安全的可变字符序列，在任意时间点上它都包含某种特定的字符序列，但通过某些方法调用（如 append()、insert()等）可以改变序列的内容和长度。可将该字符串缓冲区安全地用于多个线程。观察源码可见，为提供线程安全，其内部实现中大部分方法都是 synchronized 修饰的。\nStringBuilder（Since JDK5.0）可变字符序列。提供与 StringBuffer 兼容的 API，不过不保证同步，被设计用作 StringBuffer 的一个简易替换，用在字符串缓冲区被单个线程使用的场景（很普遍），大多数情况下，它提供更快的执行效率。\n在频繁对字符串内容进行修改的场景，根据对线程安全性的需求，优先考虑 StringBuilder、StringBuffer 中的一种。\n关于 String 的 intern()方法上面提到，inter()方法可能导致将 String 对象写入 String 常量池。从 JDK 7 开始，常量池 从 PermGen 区移到了 java 堆（jvms 角度讲，应该是从 方法区 移到了 java 堆，PermGen 是 HotSpot 里的概念），语义上的变化为：\n\n调用 intern()方法时，如果堆中有该字符串而常量池中没有，则直接在常量池中保存堆中对象的引用，而不是在常量池中新建对象。\n\n","categories":["java"],"tags":["java"]},{"title":"Java-自动装箱与拆箱","url":"/2018/04/26/java/into/java-%E8%87%AA%E5%8A%A8%E8%A3%85%E7%AE%B1%E4%B8%8E%E6%8B%86%E7%AE%B1/","content":"装箱与拆箱概念Java 为每种基本数据类型提供了对应的包装器类型，形如Integer i &#x3D; 10;这个过程中会自动根据数值创建对应的 Integer 类对象，即，装箱。对应地，自动将包装器类型转换为基本数据类型的过程，就是拆箱：int n &#x3D; i;\n即，装箱就是自动将基本数据类型转换为包装器类型，拆箱就是将包装器类型转换为基本数据类型。\n实现以 Integer 为例，自动装箱调用的是 Integer 的 valueOf(int)方法，拆箱时自动调用的是 Integer 的 intValue()方法。其他的类似。\n几个容易出错的例子：\n\n新建对象还是引用已存在对象？\n\npublic class Main &#123;\n    public static void main(String[] args) &#123;\n\n        Integer i1 = 100;\n        Integer i2 = 100;\n        Integer i3 = 200;\n        Integer i4 = 200;\n\n        System.out.println(i1==i2);\n        System.out.println(i3==i4);\n    &#125;\n&#125;\n------- output: -------\ntrue\nfalse\n输出结果表明i1和i2指向的是同一个对象，而i3和i4指向的是不同的对象。通过查看源码 ↓↓↓这段是 valueOf()方法具体实现：\npublic static Integer valueOf(int i) &#123;\n        if(i >= -128 &amp;&amp; i &lt;= IntegerCache.high)\n            return IntegerCache.cache[i + 128];\n        else\n            return new Integer(i);\n&#125;\n而其中IntegerCache类的实现为：\nprivate static class IntegerCache &#123;\n        static final int high;\n        static final Integer cache[];\n\n        static &#123;\n            final int low = -128;\n\n            // high value may be configured by property\n            int h = 127;\n            if (integerCacheHighPropValue != null) &#123;\n                // Use Long.decode here to avoid invoking methods that\n                // require Integer's autoboxing cache to be initialized\n                int i = Long.decode(integerCacheHighPropValue).intValue();\n                i = Math.max(i, 127);\n                // Maximum array size is Integer.MAX_VALUE\n                h = Math.min(i, Integer.MAX_VALUE - -low);\n            &#125;\n            high = h;\n\n            cache = new Integer[(high - low) + 1];\n            int j = low;\n            for(int k = 0; k &lt; cache.length; k++)\n                cache[k] = new Integer(j++);\n        &#125;\n\n        private IntegerCache() &#123;&#125;\n    &#125;\n可以看出，在通过 valueOf()方法创建 Integer 对象的时候，如果数值在 [-128, 127] 之间，则返回指向 IntegerCache.cache 中已经存在的对象的引用，否则创建一个新的 Ingeter 对象。故，i1 和 i2 会直接从 cache 中取出已经存在的对象，所以它们指向的是同一个对象；而 i3 和 i4 则是新创建的两个不同对象。类似的还有 Long、Short、Character、Byte，但 Double、Float、Boolean 则直接返回新创建的对象。\n\n它们相等吗？注意以下代码：public class Main &#123;\n    public static void main(String[] args) &#123;\n\n        Integer a = 1;\n        Integer b = 2;\n        Integer c = 3;\n        Long g = 3L;\n        Long h = 2L;\n\n        System.out.println(c==(a+b));\n        System.out.println(c.equals(a+b));\n        System.out.println(g==(a+b));\n        System.out.println(g.equals(a+b));\n        System.out.println(g.equals(a+h));\n    &#125;\n&#125;\n\n------- output: -------\ntrue\ntrue\ntrue\nfalse\ntrue\n\n这里需要注意以下事实：\n\n当 “&#x3D;&#x3D;”运算符的两个操作数都是包装器类型的引用，则是比较指向的是否是同一个对象；如果其中有一个操作数是表达式（即包含算术运算），则比较的是数值（即会触发自动拆箱的过程）；\n对于包装器类型，equals方法不会进行类型转换。\n\n其中，c.equals(a+b)会先触发自动拆箱，再触发自动装箱：即，a、b 先各自调用 intValut()方法得到值进行加运算，然后调用 Integer.valueOf()将结果装箱，再与 c 比较。可尝试反编译字节码查看相关内容。\n自动装箱与直接新建的区别即，以下两种创建方式的区别：\nInteger i = new Integer(x);\nInteger i = x;\n主要表现在：\n\n第一种方式不会触发自动装箱的过程，第二种会；\n执行效率和资源占用上：一般情况下，第二种方式优于第一种。\n\n","categories":["java"],"tags":["java"]},{"title":"性能监控和故障处理工具","url":"/2018/04/25/java/JVM/%E6%80%A7%E8%83%BD%E7%9B%91%E6%8E%A7%E5%92%8C%E6%95%85%E9%9A%9C%E5%A4%84%E7%90%86%E5%B7%A5%E5%85%B7/","content":"排查定位问题的时候，一般会用到的数据有：运行日志、异常堆栈、GC 日志、线程快照（threaddump&#x2F;javacore 文件）、堆转储快照（heapdump&#x2F;hprof 文件）等。$JAVA_HOME$&#x2F;bin 目录下有很多功能强大的性能监控、故障定位排查工具，它们大多是 $JAVA_HOME$&#x2F;lib&#x2F;tools.jar 类库的包装，功能代码是在 tools 类库中实现的，因而体积都很小。使用 java 代码实现这些工具的意义在于：当 app 部署到生产环境后，无论是直接接触物理服务器还是远程登陆到服务器上都可能受到限制，借助 tools.jar 类库里面的接口，可以直接在 app 中实现功能强大的监控分析功能。这里是一些常用自带&#x2F;第三方性能监控、故障定位处理工具。\njpsJVM Process Status Tool，显示指定系统内所有 HotSpot 虚拟机进程。功能类似于 Unix&#x2F;Linux 中的 ps 命令：列出正在运行的虚拟机进程，并显示虚拟机执行主类（Main Class，main() 函数所在的类）名称以及这些进程的本地虚拟机唯一 ID（Local Virtual Machine Identifier， LVMID）。\n命令格式jps [options] [hostid]\n主要选项\n-l：显示进程 ID 和主类全名，如果执行的是 jar 包，则输出 jar 路径；\n-m：输出虚拟机进程启动时传递给主类 main() 函数的参数；\n-v：输出虚拟机进程启动时 JVM 参数；\n-q：只输出 LVMID，省略主类的名称。\n\njinfoConfiguration Info for Java，显示虚拟机配置信息。实时查看和调整虚拟机各项参数。\n命令格式jinfo [option] pid\njstatJVM statistics Monitoring Tool，监视收集虚拟机各类运行状态数据。可以显示本地或远程虚拟机的类装载、内存、垃圾收集、JIT 编译等运行数据，在没有 GUI 而只提供纯文本控制台环境的服务器上，它是运行期定位虚拟机性能问题的首选工具。\n命令格式jstat [option vmid [interval [s | ms] [count]]]其中，interval：查询间隔（默认毫秒）；count：查询次数。省略这两个参数即只查询一次。如果是本地虚拟机进程，VMID 与 LVMID 一致，如果是远程虚拟机进程，VMID 格式为：[protocol: ] [ &#x2F;&#x2F; ] lvmid [@hostname [: port] &#x2F; servername]示例：jstat -gc 7717 500 10：每 500 ms 查询一次进程 7717 垃圾收集情况，共查询 10 次。\n主要选项选项比较多，主要分为 3 类：类装载、垃圾收集、运行期编译状况。常用的有\n\n-class：监视类装载数量、卸载数量、总空间以及类装载所耗费的时间\n-gc：监视 java 堆状况，包括 Eden 区、两个 Survivor 区、老年代、永久代等的容量、已用空间、GC 时间合计等信息结果列表大致如下：\n-gccapacity：监视内容基本与 -gc 相同，但输出主要关注 java 堆各个区域使用到的最大、最小空间\n-gcutil：监视内容基本与 -gc 相同，但输出主要关注已使用空间占总空间的百分比\n-gcnew：监视新生代 GC 情况\n-gcnewcapacity：监视内容基本与 -gcnew 相同，但输出主要关注使用到的最大、最小空间\n-gcold：监视老年代 GC 情况\n-gcoldcapacity：监视内容基本与 -gcold 相同，但输出主要关注使用到的最大、最小空间\n-gcmetacapacity：监视 metaspace 情况\n-compiler：输出 JIT 编译器编译过的方法、耗时情况等信息\n-printcompilation：输出已经被 jIT 编译的方法\n\n结果列信息可参考 man jstat 大致如下：\n\nS0C：年轻代中第一个survivor（幸存区）的容量 (字节) \nS1C：年轻代中第二个survivor（幸存区）的容量 (字节) \nS0U：年轻代中第一个survivor（幸存区）目前已使用空间 (字节) \nS1U：年轻代中第二个survivor（幸存区）目前已使用空间 (字节) \nEC：年轻代中Eden（伊甸园）的容量 (字节) \nEU：年轻代中Eden（伊甸园）目前已使用空间 (字节) \nOC：Old代的容量 (字节) \nOU：Old代目前已使用空间 (字节) \nPC：Perm(持久代)的容量 (字节) \nPU：Perm(持久代)目前已使用空间 (字节) \nYGC：从应用程序启动到采样时年轻代中gc次数 \nYGCT：从应用程序启动到采样时年轻代中gc所用时间(s) \nFGC：从应用程序启动到采样时old代(全gc)gc次数 \nFGCT：从应用程序启动到采样时old代(全gc)gc所用时间(s) \nGCT：从应用程序启动到采样时gc用的总时间(s) \nNGCMN：年轻代(young)中初始化(最小)的大小 (字节) \nNGCMX：年轻代(young)的最大容量 (字节) \nNGC：年轻代(young)中当前的容量 (字节) \nOGCMN：old代中初始化(最小)的大小 (字节) \nOGCMX：old代的最大容量 (字节) \nOGC：old代当前新生成的容量 (字节) \nPGCMN：perm代中初始化(最小)的大小 (字节) \nPGCMX：perm代的最大容量 (字节) \nPGC：perm代当前新生成的容量 (字节) \nS0：年轻代中第一个survivor（幸存区）已使用的占当前容量百分比 \nS1：年轻代中第二个survivor（幸存区）已使用的占当前容量百分比 \nE：年轻代中Eden（伊甸园）已使用的占当前容量百分比 \nO：old代已使用的占当前容量百分比 \nP：perm代已使用的占当前容量百分比 \nS0CMX：年轻代中第一个survivor（幸存区）的最大容量 (字节) \nS1CMX ：年轻代中第二个survivor（幸存区）的最大容量 (字节) \nECMX：年轻代中Eden（伊甸园）的最大容量 (字节) \nDSS：当前需要survivor（幸存区）的容量 (字节)（Eden区已满） \nTT： 持有次数限制 \nMTT ： 最大持有次数限制\n\njmapMemory Map for Java，生成虚拟机的内存转储快照（heapdump&#x2F;dump 文件）。也可以通过 -XX: +HeapDumpOnOutOfMemoryError 参数让虚拟机在 OOM 异常出现之后自动生成 dump 文件；或在 Linux 下 通过 kill -3 命令发送进程退出信号，也将生成 dump 文件。jmap 还可以查询 finalize 执行队列、java 堆和永久代的详细信息，如空间使用率、当前使用的收集器种类等。\n命令格式jmap [option] vmid\n主要选项\n-dump：生成 java 堆转储快照，格式为：-dump: [live, ] format&#x3D;b, file&#x3D;   其中 live 子参数说明是否只 dump 出存活的对象。示例：jmap -dump:live,format&#x3D;b,file&#x3D;heap.bin \n-F：对 -dump 选项没有响应时，可用该选项强制生成 dump 快照。（仅在 Linux&#x2F;Solaris 下有效）\n-heap：显示 java 堆详细信息，如使用哪种回收器、参数配置、分代状况等。（仅在 Linux&#x2F;Solaris 下有效）\n-finalizerinfo：显示在 F-Queue 中等待 Finalizer 线程执行 finalie() 方法的对象。（仅在 Linux&#x2F;Solaris 下有效）\n-histo：显示堆中对象统计信息，包括类、实例数量、合计容量等 （histogram）\n\njstackStack Trace for Java，java 堆栈跟踪工具。用于生成虚拟机当前时刻的线程快照（一般为 threaddump 或 javacore 文件）。线程快照就是当前虚拟机内每一条线程正在执行的方法堆栈的集合。生成快照的主要目的是定位线程出现长时间停顿的原因，如线程间锁等待（死锁、活锁）、死循环、请求外部资源（如数据库连接、网络资源、设备资源等）导致的长时间等待等，都是导致线程长时间停顿的常见原因。线程出现停顿的时候通过 jstack 来查看各个线程的调用堆栈，可以看出没有响应的线程到底在后台做些什么事情，或者在等待什么资源。\n命令格式jstack [option] vmid\n主要选项\n-l：除堆栈外，显示关于锁的附加信息\n-m：如果调用到本地方法的话，可以显示 C&#x2F;C++ 的堆栈\n-F：当正常输出的请求不被响应时，强制输出线程堆栈\n\njavapJDK 自带的反汇编器\n命令格式javap [option] xxx.class\n主要选项\n-c：输出类中各方法的未解析的代码，即构成java字节码的指令\n-classpath ：指定javap用来查找类的路径。目录用：分隔\n-extdirs ：覆盖搜索安装方式扩展的位置，扩展的缺省位置为jre&#x2F;lib&#x2F;ext\n-J：直接将flag传给运行时系统\n-l： 输出行及局部变量表\n-public：只显示public类及成员\n-protected：只显示protected和public类及成员。\n-private：显示所有的类和成员\n-package：只显示包、protected和public类及成员，这是缺省设置\n-s：输出内部类型签名\n-bootclasspath ：指定加载自举类所用的路径，如jre&#x2F;lib&#x2F;rt.jar或i18n.jar\n-verbose：打印堆栈大小、各方法的locals及args参数，以及class文件的编译版本\n\njhat分析 heapdump 文件。建立一个 http&#x2F;html 服务器，让用户可以在浏览器上查看分析结果。配合 jmap 使用。分析过程耗时而且消耗硬件资源，一般而言，不会在服务器上直接分析 dump 文件，而是复制到其他机器上进行分析；jhat 的分析功能比较简陋。在 JDK 10 中已弃用，建议使用功能更强大的 VisualVM、Eclipse Memory Analyzer、IBM HeapAnalyzer 等工具。\njconsoleJava Monitoring &amp; Management Console，java 监视与管理控制台。基于 JMX 的可视化监视、管理工具。管理部分的功能是针对 JMX MBean 进行管理， MBean 可以使用代码、中间服务器的管理控制台或者所有符合 JMX 规范的软件进行访问。\n主界面包括 6 个页签：概述、内存、线程、类、VM摘要、MBean\n\n概述整个虚拟机主要数据的概览，包括：堆内存使用情况、线程、类、CPU 占用率，是后续 4 个页签的信息汇总；\n内存相当于可视化的 jstat，用于监视受收集器管理的虚拟机内存（java 堆和永久代）的变化趋势。\n线程相当于可视化的 jstack，遇到线程停顿时可以使用这个页签进行监控分析。\n\nVisualVMAll-in-One Java Troubleshooting Tool，可视化多合一故障处理工具。提供丰富的功能：运行监视、故障处理、性能分析（Profiling），而且，不需要被监视的程序基于特殊的 Agent 运行，因此对应用程序的实际性能的影响很小，使得它可以直接应用在生产环境中。它的“All-in-One”体现在：\n\n显示虚拟机进程以及进程的配置、环境信息（jps、jinfo）；\n监视应用程序的 CPU、GC、堆、方法区、线程等的信息（jstat、jstack）；\ndump 和分析堆转储快照（jmap、jhat）；\n方法级的程序运行性能分析，找出被调用最多、运行时间最长的方法；\n离线程序快照：收集程序的运行时配置、线程 dump、内存 dump 等信息，建立一个快照，可以将快照发送给开发者进行处理；\n丰富的插件资源；\netc.\n\n","categories":["java"],"tags":["java","JVM"]},{"title":"GC优化","url":"/2018/04/25/java/JVM/GC%E4%BC%98%E5%8C%96/","content":"[toc]\n","categories":["java"],"tags":["java","JVM"]},{"title":"GC实现","url":"/2018/04/25/java/JVM/GC%E5%AE%9E%E7%8E%B0/","content":"[toc]收集算法是内存回收的方法论，垃圾收集器是内存回收的具体实现。jvms 并未对垃圾收集器的实现作任何规范。这里以基于 JDK 1.7 的 HotSpot 虚拟机为例：\n\n上图中存在连线的收集器表明两者可以搭配使用，也可以看出不同收集器所处的区域（新生代收集器和老年代收集器）。显然，HotSpot 实现了这么多种类的收集器，就证明并没有一个“万能型收集器”存在以适用于各种场景。不同收集器就是为不同的使用场景而存在的。\nSerial\n最基本、发展历史最悠久的新生代收集器。从名字可以看出，是一个单线程的收集器——并不是仅仅说明它只用一个 CPU 或一条收集线程来完成收集工作，而且它在进行 GC 时，必须暂停其他所有的工作线程（Stop the World），直到它收集结束。“Stop the World”是由 JVM 在后台自动发起和完成的，但这种在用户不可见的情况下把用户正常工作的线程全部停掉，甚至有明显的停顿，这对很多应用来说是难以接受的。随着 JVM 的发展，新的收集器被不断开发实现，它们造成用户线程停顿的时间越来越短，但实现复杂度随之不断增长。但 Serial 收集器依然是 Client 模式下的默认新生代收集器：它简单而高效（与其他收集器的单线程相比），在用户的 桌面应用场景 中，收集几十上百兆新生代的停顿时间可以控制在几十毫秒内，这在 GC 不频繁的情况下是能够接受的。\nParNew\nSerial 收集器的多线程版本。除使用多线程这一点不同外，其他行为包括所有控制参数、收集算法、Stop the World、对象分配规则、回收策略等都与 Serial 收集器一样。ParNew 收集器是许多 运行在 Server 模式下 JVM 的首选新生代收集器。其中一个与性能无关但很重要的原因是，除了 Serial 收集器之外，目前只有它能与 CMS 收集器配合工作。它默认开启的收集线程数与 CPU(核) 数量相同，也可参数指定。\nParallel Scavenge新生代收集器，使用复制算法，并行多线程执行。其特别之处在于，它的关注点与其他收集器不同：CMS 等收集器关注的是尽可能缩短 GC 时用户线程的停顿时间，而 Parallel Scavenge 收集器的目标是达到一个可控制的吞吐量（Throughput）。这里的吞吐量概念是：吞吐量 &#x3D; 用户代码运行时间 &#x2F; (用户代码运行时间 + GC 时间)。因而被称为 _“吞吐量优先”收集器_。停顿时间越短就越适合交互式程序，良好的响应速度能够提升用户体验。而高吞吐量则可以高效率利用 CPU 时间，尽快完成程序的运算任务，主要 适合后台执行而少交互的程序。\n一个值得关注的参数：-XX: UseAdaptiveSizePolicy当打开这个参数，就不需要再手动指定新生代的大小（-Xmn）、Eden 与 Survivor 空间区域的比例（-XX: SurvivorRatio）、晋升老年代对象年龄（-XX: PretenureSizeThreshold）等细节参数了。jVM 将根据当前系统运行情况收集性能监控信息，动态调整这些参数以提供最合适的停顿时间或最大吞吐量。这种调节方式成为 GC 自适应的调节策略（GC Ergonomics）。\nSerial Old是 Serial 收集器的老年代版本，使用“标记-整理”算法。主要用于 Client 模式下。如果在 Server 模式下，主要有两大用途：\n\n在 JDK 1.5 及之前的版本中与 Parallel Scavenge 收集器搭配使用；\n作为 CMS 收集器的后备预案：在发生 Concurrent Mode Failure 时使用。\n\nParallel Old\n是 Parallel Scavenge 收集器的老年代版本，使用“标记-整理“算法。在 JDK 1.6 开始提供，此前，Parallel Scavenge 收集器一直处于比较尴尬的状态：老年代只能用 Serial Old（PS MarkSweep）收集器，性能并不理想。直到该收集器的出现，“吞吐量优先”收集器才有了名副其实的应用组合：在 注重吞吐量及 CPU 资源敏感的场景，都可以优先考虑 Parallel Scavenge + Parallel Old 收集器。\nCMSConcurrent Mark Sweep。\n\n以获取最短 GC 停顿时间为目标。目前很大一部分 java 应用集中在 互联网站或 B&#x2F;S 系统服务器上，这类应用非常注重服务的响应速度，希望系统停顿时间最短以带给用户良好的体验。从名字可以看出，使用的是“标记-清除”算法。但执行过程要更复杂一些：\n\n初始标记（CMS initial mark）\n并发标记（CMS concurrent mark）\n重新标记（CMS remark）\n并发清除（CMS concurrent sweep）\n\n其中，初始标记、重新标记这两个步骤仍需要“Stop the World”。初始标记仅仅是标记一下 GC Roots 能直接关联到的对象，速度很快，并发标记阶段就是进行 GC RootsTracing 的可达性分析过程，而重新标记阶段则是为了修正并发标记期间因用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，这个阶段的停顿会比初始标记阶段稍长一些，但远比并发标记的时间短。而由于整个过程中耗时最长的并发标记和并发清除过程的收集器线程都可以与用户线程一起工作，从总体上来说，CMS 收集器的 GC 过程是与用户线程一起并发执行的。\n缺点CMS 优点是并发收集、低停顿，因此也被称为“Concurrent Low Pause Collector，并发低停顿收集器”。但它也有 3 个明显的缺点：\n\n和面向并发设计的程序一样，CMS 同样对 CPU 资源非常敏感：并发阶段会启动线程，占用一部分 CPU 资源；\n无法处理浮动垃圾（Floating Garbage），可能出现“Concurrent Mode Failure”失败而导致另一次 Full GC。由于 CMS 并发清理阶段用户程序还在执行，因此这期间产生的新垃圾就没有被标记，即浮动垃圾，只能留到下一次 GC 时处理；\n同样有基于“标记-清除”算法的缺点：内存碎片化。为此，CMS 提供了一个参数 -XX: UseCMSCompactAtFullCollection（默认开启），用于在 CMS 要进行 Full GC 时开启内存碎片的整理过程，过程中无法并发，即，会导致停顿时间变长；还提供了另一个参数 -XX: CMSFullGCsBeforeCompaction，用于设置执行多少次不压缩的 Full GC 后，跟着执行一次带压缩的 GC（默认为 0，表示每次进入 Full GC 时都会进行碎片整理）。\n\nG1Garbage First。\n\n当前收集器技术发展的最前沿成果之一，面向服务端应用。特点有：\n\n并行与并发：能充分利用多 CPU、多核环境下的硬件优势，使用多个 CPU 来缩短“Stop the World”停顿的时间，部分其他收集器原本需要停顿的 GC 动作，G1 仍然可以通过并发的方式让 java 程序继续执行；\n分代收集：与其他收集器一样，G1 保留了分代概念。虽然可以不需要其他收集器配合就能独立管理整个 GC 堆，但它也能够采用不同方式处理不同存活时间的对象，以获取更好的收集效果；\n空间整合：与 CMS 的“标记-清理” 算法不同，G1 从整体来看是基于“标记-整理”算法的，从局部（两个 Region 之间）来看却是基于“复制”算法实现的——总之，都不会产生空间碎片。有利于程序的长时间运行；\n可预测的停顿：这是 G1 相比于 CMS 的另一大优势。能够建立可预测的停顿时间模型，让使用者明确指定在 M 毫秒的时间片段内，消耗在 GC 上的时间不得超过 N 毫秒——这几乎就是 实时 Java（RTSJ）的垃圾收集器的特征了。\n\n不同于 CMS 等进行收集的范围是整个新生代或老年代，使用 G1 收集器时，java 堆的内存布局有很大变化：将整个 java 堆划分为多个大小相等的独立区域（Region），同时保留的新生代&#x2F;老年代的概念在这里也不再是物理隔离的，而是都作为一部分 Region（不需要物理上连续）的集合。其特点中之所以能够建立可预测的停顿时间模型，就是因为它可以有计划地避免在整个 java 堆中进行全区域的垃圾回收。G1 跟踪各个 Region 里 GC 堆的价值大小（回收所获的的空间大小以及回收所需的时间的经验值），在后台维护一个优先列表，每次根据允许的收集时间，优先回收价值最大的 Region（这也就是 Garbage-First名称的由来）。Region 不可能是孤立的，对象间的引用关系复杂，还是会导致可达性分析时扫描整个 java 堆？这个问题不光在 G1 中存在，只是 G1 中更加明显。G1 中每个 Region 都有一个与之对应的 Remembered Set，jVM 用它来避免全堆扫描。JVM 发现程序在对 reference 类型的数据进行写操作时，会产生一个 Write Barrier 暂时中断写操作，检查 reference 引用的对象是否处于不同 Region 中（在分代的例子中就是检查是否老年代中的对象引用了新生代中的对象），如果是，就通过 CardTable 把相关引用信息记录到被引用对象所属 Region 的 Remembered Set 中。当进行内存回收时，在 GC 根节点的枚举范围中加入 Remembered Set 即可保证不对全堆扫描，也不会有遗漏。如果不计算维护 Remembered Set 的操作，G1 收集器的执行大致可划分为：\n\n初始标记（Initial Marking）\n并发标记（Concurrent Marking）\n最终标记（Final Marking）\n筛选回收（Live Data Counting &amp; Evacuation）\n\n可以看出，前两个阶段和 CMS 的类似，而“最终标记”其实也类似于 CMS 的“重新标记”，只不过是把并发标记阶段期间新产生的垃圾记录到 Remembered Set Logs 中（CMS 无法处理之），随后需要停顿线程，将该日志记录合并到 Remembered Set中，最后在筛选回收阶段首先对各个 Region 的回收价值和成本进行排序，根据用户所期望的 GC 停顿时间来制定回收计划，这个阶段可以并发执行（但由于停顿时间是用户可控制的，并且停顿用户线程能大幅提高收集效率，也可停顿执行）。在追求低停顿的场景，无疑 G1 是更好的选择，但如果追求吞吐量，那么 G1 也许并非首选。\n","categories":["java"],"tags":["java","JVM"]},{"title":"GC算法","url":"/2018/04/25/java/JVM/GC%E7%AE%97%E6%B3%95/","content":"GC 算法的实现涉及大量的程序细节，且各个平台上的 JVM 操作内存的方法也不相同，所以算法的具体实现有很大差异。但策略思想是通用的。\n判断对象存活状态GC 面临的首要问题是，如何判断对象是否存活，即是否可以被回收？常见方法有引用计数法、可达性分析等。\n引用计数Reference Counting给对象添加一个引用计数器，每当有一个地方引用它时，计数器就 +1，当引用失效时，计数器就 -1，计数器为 0 的对象就是不能再被使用的，即可被回收。尽管该算法理论上实现简单、判定效率高，但它无法解决一个很重要的问题：无法解决对象之间的相互循环引用问题。从而没有进入大多数主流商用 JVM。\n可达性分析Reachability Analysis主流程序语言判定对象是否存活的常用算法实现。基本思路就是通过一系列被称为“GC Roots”的对象作为起始点，从这些节点开始向下搜索，搜索所经过的路径被称为“引用链（Reference Chain）”，当一个对象到 GC Roots 没有任何引用链相连（即，GC Roots 到 该对象不可达）时，就证明该对象是不可用的，即可被回收。\n\n可作为 GC Roots 的对象主要在全局性的引用（如常量和类静态属性）与执行上下文（如栈帧中的本地变量）中，一般有：\n\n虚拟机栈（栈帧中的本地变量表）中引用的对象；\n方法区中类静态属性引用的对象；\n方法区中常量引用的对象；\n本地方法栈中 JNI（即一般所说的 Native 方法）引用的对象。\n\n两次标记过程即使在可达性分析算法中不可达的对象，也不会立即被回收。而真正回收一个对象，需要经历至少两次标记过程：\n\n在可达性分析后发现该对象不可达，则对该对象进行第一次标记并进行一次筛选。筛选的条件是该对象是否有必要执行 finalize() 方法：当对象没有覆盖 finalize() 方法或 finalize() 方法已经被 JVM 调用过，这两种情况都视为“没有必要执行”。\n如果该对象被判定为有必要执行 finalize() 方法，那么该对象就会被放置在一个叫做 F-Queue 的队列中，并在稍后由一个由 JVM 自动建立的、优先级较低的 Finalizer 线程去执行它（仅仅触发对象的 finalize() 方法，而不一定会等待该方法执行结束——可能该方法根本不会结束）。finalize() 方法是对象逃脱死亡命运的最后一次机会——如果在该方法中重新建立引用链，那么在第二次标记时该对象将被移出“即将回收”集合。\n\n方法区 GC判定一个常量是否是“废弃常量”比较简单：没有任何对象引用这个常量。而判定一个“无用的类”，需要同时满足以下条件：\n\n该类的所有实例都已经被回收，即，java 堆中不存在该类的任何实例；\n加载该类的 ClassLoader 已经被回收；\n该类对应的 java.lang.Class 对象没有在任何地方被引用，无法在任何地方通过反射访问该类的方法。\n\nGC 算法解决如何筛选可回收资源问题之后，下一步就是确定垃圾回收的具体实现。最基础的就是“标记-回收”算法，其他很多算法基于此进行改进。\n标记-清除Mark-Sweep\n\n最基础的回收算法——后续的回收算法都是基于这种思路并在某些方面加以改进。算法分为“标记”和“清除”两个阶段：首先标记出所有需要回收的对象，完成后统一回收所有被标记的对象。基础的实现存在一些问题：\n\n效率上，标记和清除两个过程的效率都不高；\n空间上，标记-清除之后会产生大量内存碎片，可能导致后续的对象无法完成内存分配，从而更为频繁地触发垃圾回收。\n\n复制（Copying）\n为解决效率问题，将可用内存按照容量划分为大小相等的两块，每次只使用其中的一块。当正在使用的内存块用完了，就将仍存活的对象复制到另一块上去，然后清理该内存块。这样使得每次都是对半块内存进行回收，分配时也就不用考虑内存碎片等复杂情况，只要移动堆顶指针，按顺序分配内存即可。实现简单，运行高效，缺点也很明显：可用内存小于整个配置内存的一半。一般不会直接采用这种算法。\n改进的复制算法\nIBM 研究表明，新生代中的对象 98% 是“朝生夕死”的，所以不需要按照 1:1 来划分内存空间。而是，如 HotSpot 等 JVM 实现（一开始就没有通过 1:1 模式实现，分代方式从最初就是这样的布局），按照 8:1:1 划分为一快较大的 Eden 空间和两块等大的较小的 Survivor 空间。每次使用 Eden 空间和其中一块 Survivor 空间，当发生回收时，将 Eden 和在用的 Survivor 中的存活对象一次性复制到另一块 Survivor 空间中，然后清理 Eden 空间和复制转移存活对象后的 Survivor 空间。显然，可能发生 Survivor 空间不够用的情况，这时需要依赖其他内存（如老年代）进行分配担保（Handle Promotion）。而且，存活率较高时，需要较多的复制操作，效率问题依然存在。\n标记-整理Mark-Compact\n\n根据老年代的特点，提出“标记-整理”算法。标记过程同“标记-清除”算法，但后续步骤不是直接对可回收对象进行清理，而是让所有存活的对象都向一端移动，然后直接清理端边界以外的内存。\n分代收集Generational Collection当前商业 JVM 的 GC 都采用的算法，本质上是为了优化 GC 效率性能。根据对象存活周期的不同，将内存划分为几块：一般把 java 堆分为新生代和老年代，这样就可以根据各个年代的特点进行采用更适当的 GC 算法。在新生代中，每次 GC 时都发现有大量对象死去，只有少量继续存活，那么就使用复制算法——只需要复制少量存活对象就可以完成 GC；而老年代中因为对象存活率较高，又没有额外空间对它进行分配担保，就必须使用“标记-清除”或“标记-整理”算法。可见，分代是对所讨论 GC 算法的一种细粒度的复合使用。\n\n\n","categories":["java"],"tags":["java","JVM"]},{"title":"类加载","url":"/2018/04/25/java/JVM/%E7%B1%BB%E5%8A%A0%E8%BD%BD/","content":"JVM 把描述类的数据从 class 文件加载到内存，并对数据进行校验、转换解析和初始化，最终形成可以被 JVM 直接使用的 java 类型，这就是 JVM 的类加载机制。java 中，类型的加载、连接和初始化过程都是在程序运行期间完成的，这种策略为应用程序提供了高度的灵活性。\n类加载时机类从被加载到 JVM 内存中开始，到卸载出内存为止，整个生命周期包括：加载（Loading）、验证（Verification）、准备（Preparation）、解析（Resolution）、初始化（Initialization）、使用（Using）、卸载（Unloading）。其中，验证、准备、解析 3 部分统称为连接（Linking）：\n\n\n其中，加载、验证、准备、初始化、卸载这 5 个阶段的顺序是确定的（但并非串行，通常是交叉混合式进行的，只是开始执行的顺序是确定的），而解析在某些情况下可能在初始化阶段之后再开始：为了支持 java 的运行时绑定（也称动态绑定&#x2F;晚期绑定）。jvms 规定了 5 种情况下，才能对类立即进行“初始化”：\n\n遇到 new、getstatic、putstatic、invokestatic 这4条字节码指令时，如果类没有进行过初始化，则先触发其初始化。常见场景是：使用 new 关键字实例化对象、读取或设置一个类的静态字段（被final修饰、已在编译期把结果放入常量池的静态字段除外）、调用一个类的静态方法；\n使用 java.lang.reflect 包的方法对类进行反射调用时，如果类没有进行过初始化，则先触发其初始化；\n初始化一个类时，如果发现其父类没有进行过初始化，则先触发其父类的初始化；\nJVM 启动时，用户需要指定一个要执行的主类，JVM 会先初始化该主类；\n使用JDK 1.7+ 的动态语言支持时，如果一个 java.lang.invoke.MethodHandle 实例最后的解析结果是 REF_getStatic、REF_putStatic、REF_invokeStatic 的方法句柄，并且这个方法句柄所对应的类没有进行过初始化，则先触发其初始化。\n\n类加载过程加载“加载”是“类加载（Class Loading）”的一个阶段，jvms 要求这一阶段需要完成以下工作：\n\n通过一个类的全限定名来获取定义此类的二进制字节流；\n将这个字节流所代表的静态存储结构转化为方法区的运行时数据结构；\n在内存中生成一个代表这个类的 java.lang.Class 对象，作为方法区这个类的各种数据的访问入口。\n\n该阶段用户应用程序可以通过自定义类加载器参与，类加载其余过程由 JVM 主导并控制。\n验证是为了确保 class 文件的字节流中包含的信息符合当前 JVM 的要求，并且不会危害 JVM 自身的安全。是连接阶段的第一步。主要包括：\n\n文件格式验证，魔数、版本、常量池中常量是否被支持、是否含有 utf-8 以外的编码格式…\n元数据验证，对字节码描述信息进行语义分析校验，可能包括：该类是否有父类；父类是否继承了不允许继承的类（final 修饰的类）；如果不是抽象类，是否实现了父类&#x2F;接口必须实现的所有方法；字段、方法是否与父类产生矛盾…\n字节码验证，最复杂的验证阶段：通过数据流和控制流分析，确保程序语义合法、合乎逻辑；\n符号引用验证，JVM 将符号引用转化为直接引用，该校验发生在解析阶段。\n\n准备正式为类变量分配内存并设置类变量初始值（一般就是零值），这些变量所使用的内存都在方法区中分配：仅包括类变量（static 修饰）而不包括实例变量，实例变量将在对象实例化时随着对象一起分配在 java 堆中。\n解析JVM 将常量池内的符号引用替换为直接引用的过程。解析阶段的两者含义：\n\n符号引用（Symbolic References）：以一组符号来描述所引用的目标，符号可以是任何形式的字面量，只要使用时能无歧义地定位到目标即可。符号引用与虚拟机实现的内存布局无关，引用的目标并不一定已经加载到内存中。各种虚拟机实现的内存布局可以各不相同，但是它们能接受的符号引用必须都是一致的，因为符号引用的字面量形式明确定义在Java虚拟机规范的Class文件格式中。\n可以是直接指向目标的指针、相对偏移量或是一个能间接定位到目标的句柄。直接引用是和虚拟机实现的内存布局相关的，同一个符号引用在不同虚拟机实例上翻译出来的直接引用一般不会相同。如果有了直接引用，那引用的目标必定已经在内存中存在。\n\n初始化类加载过程的最后一步。\n类加载器类加载器（Class Loader）是 java 语言的一项创新。在类加载的第一阶段“加载”过程中，需要通过 类的全限定名 来获取定义此类的二进制字节流，完成这个操作的模块就是 类加载器。这一操作是在 JVM 外部实现的，以便让应用程序自己（开发者）决定如何获取所需的类。jvms 并没有指明类的二进制字节流要从一个 .class 文件获取，也没有指明从哪里获取、怎样获取。这种开放使得 java 在许多领域得到充分利用，目前有以下常用方式获取字节流：\n\n从 zip 包中读取：jar，ear，war 等；\n从网络中获取，最典型的应用就是 Applet；\n运行时计算生成，最典型的是动态代理技术，在 java.lang.reflect.Proxy 中，就是用了 ProxyGenerator.generateProxyClass 来为特定接口生成形式为 “*$Proxy” 的代理类的二进制字节流；\n由其他文件生成，最典型的 jsp 应用，由 jsp 文件生成对应的 Class 类，etc.\n\n分类从 JVM 角度看，只存在两种类加载器：\n\n启动类加载器（Bootstrap ClassLoader），JVM 自身的一部分，C++ 实现。负责将 \\lib 目录中或被 -Xbootclasspath 参数所指定的路径中的类库加载到 JVM 内存中，这些类库必须能够被 JVM 识别（仅按照文件名识别，如 tr.jar，名称不符合的类库不会被加载）。_如果需要把加载请求委派给启动类加载器，直接使用 null 代替即可_。\n所有其他的类加载器，独立于 JVM，java 实现，全部继承自抽象类 java.lang.ClassLoader。包括下面的扩展类加载器、应用程序类加载器等。\n\n从开发人员角度看，绝大部分 java 程序会使用到以下 3 种系统提供的类加载器：\n\n启动类加载器（Bootstrap ClassLoader）；\n扩展类加载器（Extension ClassLoader）,这个加载器由 sun.misc.Launcher $ExtClassLoader 实现，它负责加载\\lib\\ext目录中的，或者被 java.ext.dirs 系统变量所指定的路径中的所有类库，开发者可以直接使用扩展类加载器；\n应用程序类加载器（Application ClassLoader）：这个类加载器由 sun.misc.Launcher $App-ClassLoader 实现。这个类加载器是 ClassLoader 中的 getSystemClassLoader() 的返回值（所以也称它为系统类加载器）。它负责加载用户类路径（ClassPath）上所指定的类库，开发者可以直接使用这个类加载器。如果应用程序中没有自定义类加载器，一般情况下它就是默认类加载器。\n\n类缓存双亲委派模型\n所谓的类加载器的双亲委派模型指的是 类加载器之间的层次关系。图中所示类加载器之间的层次关系，就是类加载器的双亲委派模型（Parents Delegation Model）。双亲委派模型要求除了顶层的启动类加载器之外，其余的类加载器都应有自己的父加载器。类加载器之间的父子关系一般不会以继承关系（Inheritance）的关系来实现，而是使用组合（Composition）关系来复用父加载器的代码。_双亲委派模型不是强制性约束模型，而是 java 设计者推荐给开发者的一种类加载器实现方式_。\n工作过程如果一个类收到了类加载的请求，它首先不会自己尝试加载这个类，而是把这个请求委派给父加载器去完成，每一个层次的类加载器都是如此。因此所有的加载请求最终都应该传送到顶层的启动类加载器中，只有当父加载器反馈自己无法完成该加载请求（其搜索内没有找到所需的类）时，子类加载器才会尝试自己去加载。即搜索是从顶层加载器到发出加载请求的加载器各自维护的搜索范围依次进行搜索的。实现双亲委派模型的代码集中在 java.lang.ClassLoader 的 loadClass() 中，具体流程：先检查是否已经加载过该类，若没有，则调用父加载器的 loadClass()，若父加载器为 null，则默认使用启动类加载器作为父加载器。如果父加载器加载失败，抛出 ClassNotFoundException 后，调用自身 findClass() 进行加载。\nprotected Class&lt;?> loadClass(String name, boolean resolve)\n    throws ClassNotFoundException &#123;\n    synchronized (getClassLoadingLock(name)) &#123;\n        // 检查是否已经加载过该类\n        Class&lt;?> c = findLoadedClass(name);\n        if (c == null) &#123;\n            long t0 = System.nanoTime();\n            try &#123;\n                if (parent != null) &#123;\n                    c = parent.loadClass(name, false);\n                &#125; else &#123;\n                    c = findBootstrapClassOrNull(name);\n                &#125;\n            &#125; catch (ClassNotFoundException e) &#123;\n                // ClassNotFoundException thrown if class not found\n                // from the non-null parent class loader\n            &#125;\n\n            if (c == null) &#123;\n                // If still not found, then invoke findClass in order\n                // to find the class.\n                long t1 = System.nanoTime();\n                c = findClass(name);\n\n                // this is the defining class loader; record the stats\n                PerfCounter.getParentDelegationTime().addTime(t1 - t0);\n                PerfCounter.getFindClassTime().addElapsedTimeFrom(t1);\n                PerfCounter.getFindClasses().increment();\n            &#125;\n        &#125;\n        if (resolve) &#123;\n            resolveClass(c);\n        &#125;\n        return c;\n    &#125;\n&#125;\n\n意义使用双亲委派模型来组织类加载器之间的关系，好处之一是：java 类随着它的类加载器一起，具备了一种带有优先级的层次关系。例如 java.lang.Object 类，它存放在 rt.jar 中，无论哪个类加载器请求加载这个类，最终都是委派给处于模型顶层的启动类加载器进行加载，因此 Object 类在程序的各种类加载器环境中都是同一个类。相对地，如果不使用双亲委派模型，而是由各个类加载器自行加载请求类的话，如果开发者编写了一个名为 java.lang.Object 的类，并把它放在程序的 ClassPath 中，那么系统将会出现多个不同的 Object 类，这会导致 java 类型体系中最基础的行为也无法保证，应用程序也将变得非常混乱。内存模型中，判断一个对象是否为某个类型时，前提是比较对象与被比较对象都来自同一个类加载器，否则没有对比的意义——返回 false。\n破坏双亲委派模型上述已经提到，这只是一个推荐实现，而非强制约束，这就意味着有可能（有意&#x2F;无意）不被遵循。（详见《深入理解 java 虚拟机》）。\n自定义类加载器几个重要方法\nloadClass()上面已经提到。\nfindClass()protected Class&lt;?> findClass(String name) throws ClassNotFoundException &#123;\n    throw new ClassNotFoundException(name);\n&#125;\n可见，默认抛出异常。上面提到 locaClass() 在父加载器无法加载类时，会调用自身的 findClass() 进行加载，所以必须在 loadClass() 中实现将一个指定类名转换为 class 对象，转换中借助 defineClass 方法。\ndefineClass()protected final Class&lt;?> defineClass(String name, byte[] b, int off, int len)\n        throws ClassFormatError  &#123;\n        return defineClass(name, b, off, len, null);\n&#125;\n\n将一个字节数组转为 class 对象，这个字节数组是 class 文件读取后最终的字节数组。如，假设 class 文件是加密过的，则需要解密后作为形参传入。\n\n\n\nhttps://www.jianshu.com/p/fa77095120b7https://blog.csdn.net/huachao1001/article/details/52297075https://blog.csdn.net/zhaoenweiex/article/details/63289374\n","categories":["java"],"tags":["java","JVM"]},{"title":"数据类型","url":"/2018/04/25/java/into/%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B/","content":"Java 语言是静态类型（statical typed）的，所以也是强类型（strong typed）的，即，每个变量都具有一种类型，并且每种类型都是严格定义的。Java中有两种数据类型：primitive type 和 reference type，即，基本类型和引用类型。\n\n\nprimitive typereference typeJDK 1.2 之后，java扩充了引用的概念，分为：强引用、软引用、弱引用、虚引用 4 种。引用强度依次减弱。java 引用\n强引用（Strong Reference）代码中普遍存在的，类似“Object obj &#x3D; new Object ( )”这类引用，只要强引用还在，GC 就不会回收被引用的对象；\n软引用（Soft Reference）描述一些还有用但并非必须的对象。对于软引用关联着的对象，在系统将要发生内存溢出异常之前，将会把这些对象列进回收范围之中进行第二次回收。如果这次回收还是没有足够的内存，才会抛出内存溢出异常；\n弱引用（Weak Reference）同样用来描述非必需对象，但强度比软引用更弱一些。被弱引用关联的对象只能生存到下一次 GC 发生之前。当 GC 工作时，无论当前内存是否够用，都会回收掉只被弱引用关联的对象；\n虚引用（Phantom Reference）也称幽灵引用&#x2F;幻影引用，是最弱的一种引用关系。一个对象是否有虚引用的存在，完全不会对其生存时间构成影响，也无法通过虚引用来取得一个对象实例。为一个对象设置虚引用关联的唯一目的是能在这个对象被 GC 回收时收到一个系统通知。\n","categories":["java"],"tags":["java"]},{"title":"硬链 软链","url":"/2018/04/23/Linux/%E7%A1%AC%E9%93%BE%20%E8%BD%AF%E9%93%BE/","content":"文件现代 OS 为解决信息能独立于进程之外被长期存储引入了文件。Unix 系统中除进程外，一切皆是文件，Linux 与之一脉相承。Linux 不区分文件和目录：目录是记录了其他文件名的文件。因此，使用 mkdir 创建目录时，若期望创建目录的名称与现有的文件名&#x2F;目录名重复，则会创建失败。\ninode一般，文件包括文件名和数据。Linux 称之为用户数据（user data）和元数据（metadata）：\n\n元数据：文件的附加属性，文件名 + inode，即索引节点号，它是文件的唯一标识（而不是文件名，文件名只是方便人们记忆和使用）。\n用户数据：即文件数据块（data block），数据块是记录文件真实内容的地方。\n\n即，除了文件名以外的所有文件信息，都保存在 inode 中。主要包括：\n\n文件的字节数；\n文件拥有者的 User ID；\n文件的 Group ID；\n文件的读、写、执行权限；\n三个时间戳：ctime：inode 上一次变动的时间，mtime：文件内容上一次变动的时间，atime：文件上一次打开的时间；\n链接数：即有多少文件名指向这个 inode；\n文件数据 block 的位置。\n\n目录文件的链接数比较特殊：创建目录时，默认会生成两个目录项，“.”和“..”，前者的 inode 号就是当前目录的 inode 号，等同于当前目录的“硬链接”；后者的 inode 号就是当前目录的父目录的 inode 号，等同于父目录的“硬链接”。所以，任何一个目录的“硬链接”总数，总是等于 2 + 子目录总数（含隐藏目录）。\nOS（Unix, Linux）使用 inode 号识别不同的文件。当读取某个文件时，必须经过文件名指向其 inode 号，获取 inode 信息，再根据该信息，找到文件数据所在的 block，完成数据读取。\n\n查看 inode 命令：\n\nstat filename  # 列出该文件的 inode 号\nls -i  # 列出文件名和 inode 号\n\n查看 inode 使用情况：\n\ndf -i\n\nOS 将硬盘分为两个区域：数据区，存放文件数据；inode 区（inode table），存放 inode 所包含的信息。inode 会占用硬盘空间，每个大小一般为 128 字节或者 256 字节。假定 1 GB 硬盘中，每个 inode 大小为 128 字节，每 1 KB 设置一个 inode，则 inode table 占用 128 MB，占总量的 12.8%。查看 inode 节点大小：\n\nsudo dumpe2fs -h &#x2F;dev&#x2F;sda5 | grep “Inode size”\n\n由于每个文件都会占用一个 inode，所以可能先于硬盘而耗尽，这时，同样无法继续创建新文件。\n到此，不难理解目录的权限。目录文件的读权限（r）和写权限（w），都是针对目录文件本身的。由于目录文件内只有文件名和 inode 号，所以如果只有该目录文件的读权限，则只能获取文件名，无法获取其他信息（包括 inode 节点中的信息），从而，读取 inode 节点内的信息需要目录文件的执行权限（x）。\ninode 特殊作用由于 inode 号与文件名分离，导致了 Unix&#x2F;Linux 系统的一些特有现象：\n\n有时，文件名包含特殊字符导致无法删除，这时直接删除 inode 节点，就能起到删除文件的作用；\n移动&#x2F;重命名文件，并不影响 inode 号；\n打开一个文件后，系统就以 inode 号来识别该文件，不再考虑文件名。因此，通常来说，系统无法通过 inode 号得知文件名。\n\n第三点使得软件更新变得简单，可以在不关闭软件的情况下进行更新而不需要重启。更新时，新版文件以同样的文件名，生成一个新的 inode，不会影响到正在运行中的文件。等下一次运行该软件时，文件名就自动指向新版文件，旧版文件的 inode 则被回收。\n为解决文件的共享使用，Linux 引入了两种链接：硬链接（hard link）与软链接（soft link，又称符号链接，symbolic link）。链接的好处：便于文件共享、隐藏文件路径、增加权限安全、节省存储空间等。\n硬链接如果一个 inode 号对应多个文件名，则这些文件就是硬链接。即，硬链接就是同一个文件使用了多个别名。因此，其特性有：\n\n文件有相同的 inode 和 data block；\n只能对已存在的文件进行创建；\n不能跨文件系统进行硬链接的创建 ；\n不能对目录进行创建，只能对文件创建；\n删除一个硬链接文件并不影响其他有相同 inode 号的文件。\n\ninode 仅在各文件系统下是唯一的，因此不能交叉文件系统创建硬链接。而现代 Linux 文件系统目录中均隐藏了两个特殊的目录：当前目录（.）和父目录（..），查看其 inode 号可知它们就是两个硬链接，如果允许对目录创建硬链接，则会产生目录环。\n软链接如果一个文件的用户数据块中存放的内容是另一个文件的路径名的指向，则该文件就是软链接。即，访问软链接时，系统会自动将访问者导向其数据指向的路径，即另一个文件。除了内容存放的是一个文件路径指向外，可以把它看作一个普通文件，并且软链接占用一个 inode。其特性与硬链接有明显不同：\n\n有自己的文件属性及权限等；\n可对不存在的文件或目录创建软链接；\n可跨文件系统；\n可对文件或目录创建；\n创建软链接时，链接计数 i_nlink 不会增加；\n删除软链接并不影响被指向的文件，但若被指向的原文件被删除，则相关软连接被称为死链接（即 dangling link，若被指向路径文件被重新创建，死链接可恢复为正常的软链接）。\n\n","categories":[],"tags":["Linux","OS"]},{"title":"常见问题-lang","url":"/2018/04/23/QA/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98-lang/","content":"什么是匿名函数（Anonymous Function）一类无需定义标识符（函数名）的函数或子程序。\n“随机访问&#x2F;随机读写”怎么理解？这涉及到内存的概念：RAM，i.e. Random Access Memory，其中“Random”不仅有随机的意思，还可以理解成“任意”，即访问任意存储节点位置，这就是其与硬盘、磁带等需要寻道、倒带才可以访问指定位置的存储设备不同之处。加之内存、高速缓存不需要寻址并且没有 I&#x2F;O 开销，所以速度上非常快。作为廉价集群解决方案，Hadoop 中 HDFS 之所以默认存储块大小为 64M，也是为了减少拼接块在硬盘上的寻址时间。\n赋值语句作为返回值简单赋值语句作为返回值，如 while(i&#x3D;1)、return i&#x3D;2; 等，返回值就是所赋的值本身，即 while(i&#x3D;1) 相当于 while(1)，return i&#x3D;2 相当于 return 2；\n","categories":[],"tags":["Q&A"]},{"title":"py-迭代器","url":"/2018/04/23/py/py-%E8%BF%AD%E4%BB%A3%E5%99%A8/","content":"迭代（Iteration）如，给定一个 list 或 tuple，可以通过 for 循环遍历之，称之为 迭代。只要是可迭代对象，无论是否可以使用下标遍历，都可以使用迭代，如 dict。通过 collections 模块的 Iterable 类型判断来验证一个对象是否可迭代：\n&gt;&gt;&gt; from collections import Iterable\n&gt;&gt;&gt; isinstance(&quot;abc&quot;, Iterable)  # True\ndict 默认迭代的是 key，迭代 value：for v in d.values( )；迭代 key 和 value：for k, v in d.items( )。\n生成器（Generator）通过列表生成式（List Comprehensions），可以用来创建 list，如\n&gt;&gt;&gt; [x * x for x in range(1, 6)]\n&gt;&gt;&gt; [1, 4, 9, 16, 25]\n但是列表生成式的容量受内存限制：声明的容量会直接占用相应的内存。所以，如果列表元素可以按照某种算法推算出来，那么就可以在循环中不断推算出后续元素，这样就不必创建完整的 list，从而节省空间。这种边循环边计算的机制，被称为生成器（Generator）。\n创建\n\n最简单的方式，把上面的生成式“[]”改成“()”，就成了创建一个 generator：&gt;&gt;&gt; (x * x for x in range(1, 6))\n&gt;&gt;&gt; &lt;generator object &lt;genexpr&gt; at 0x7f2a39f1b280&gt;\nyield 关键字如果一个函数定义中使用了 yield 关键字，那么它就不再是一个普通函数，而是一个迭代器。\n\n访问\n\n使用 next(g)，每次使用，会返回一个对象，直到对象被用尽；\nfor 循环。\n\n","categories":["py"],"tags":["py"]},{"title":"Python-装饰器","url":"/2018/04/23/py/py-%E8%A3%85%E9%A5%B0%E5%99%A8/","content":"函数是一个对象，可以赋值给变量，所以也可以通过变量调用该函数：\n&gt;&gt;&gt; f &#x3D; abs( )\n&gt;&gt;&gt; f( )  # 调用 abs( )\n\n如果，我们想要增强 abs( ) 函数的功能，但又不想（不能）修改其定义，这种在代码运行期间动态增加功能的方式，称之为装饰器（Decorator）。\n装饰器本质上是一个 python 函数，为已经存在的对象添加额外的功能：它可以让其他函数在不需要做任何代码修改变动的情况下增加额外功能，其返回值也是一个函数。使用场景主要有：面向切面需求的场景，如插入日志、性能测试、事务处理、缓存、权限校验等。\n","categories":["py"],"tags":["py"]},{"title":"常见问题——OS","url":"/2018/04/22/QA/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98-OS/","content":"进程 线程\n线程与进程的区别？进程和线程的主要差别在于它们是 操作系统资源的不同管理方式。\n\n\n进程有自己的地址空间；线程之间共享地址空间，但各自拥有自己的堆栈和局部变量。\n进程间切换所消耗的资源较大，对效率影响也就比较大；线程间切换相对高效。\n一个程序至少有一个进程，一个进程至少有一个线程。\n执行过程中的区别：每个线程有一个运行的入口、顺序执行序列、出口，但线程不能独立执行，必须依存在进程中，由进程提供多个线程的执行控制。\n\n","categories":["OS"],"tags":["OS","Q&A"]},{"title":"常见问题-py","url":"/2018/04/22/QA/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98-py/","content":"python 中 range 和 xrange 的区别range函数说明：range(start, stop[, step])，根据 start、stop 指定的范围和步长 step 生成一个序列 list。xrage使用方法和 range 一样，但生成的不再是 list，而是一个生成器。在 python3.x 中，range 就是使用 xrange 的实现方式，所以不再有 xrange 函数。\n","categories":["py"],"tags":["Q&A","py"]},{"title":"死锁","url":"/2018/04/20/OS/%E6%AD%BB%E9%94%81/","content":"资源的申请和释放OS 的各种资源如 CPU、内存空间、文件、I&#x2F;O 设备等，都是有限的。进程在使用资源之前必须申请，使用之后必须释放。资源的申请与释放属于系统调用嗯。即，正常情况下的顺序是：\n\n申请。如果申请不能立即被允许（如，所申请资源正在被其他进程所占用），那么申请进程必须等待，直到获取该资源；\n使用。进程对资源进行操作（如，在打印机上打印一份文档）；\n释放。进程将占用的资源释放。\n\n定义当一组进程中的每个进程都在等待一个事件，而这一事件只能由这组进程中的某一个进程引起，那么这组进程就处于死锁状态。\n产生死锁的必要条件同时满足以下 4 个条件，才会产生死锁：\n\n互斥：至少有一个资源必须处于非共享模式，即一次只有一个进程使用。如果另一进程申请该资源，那么申请进程必须等到该资源被释放；\n占有并等待：一个进程必须占有至少一个资源，并等待另一资源，而该资源为其他进程所占有；\n非抢占&#x2F;不可剥夺：资源不能被抢占，即资源只能在进程完成&#x2F;结束任务后自动释放；\n循环等待：一组等待进程造成资源上的循环等待。\n\n这些条件并不完全独立，比如循环等待条件就意味着占有并等待条件已经发生。\n处理方法从原理上讲，有 3 种解决死锁的方法：\n\n使用协议以预防&#x2F;避免死锁，确保系统不会进入死锁状态；\n允许系统进入死锁状态，然后检测，并加以恢复；\n忽视这个问题，认为死锁不可能在系统内发生。\n\n绝大多数 OS 采用第三种方法，包括 UNIX 和 Windows。即，应用程序开发人员要自行处理死锁问题。\n死锁预防从出现死锁的 4 个必要条件可知，只要确保至少一个条件不成立，就能预防死锁发生：\n\n互斥：对于非共享资源，必须要有互斥条件。共享资源，如只读文件，不需要互斥访问；\n占有并等待：当一个进程申请一个资源时，它不能占有其他资源。一种方式是每个进程在执行前申请并获得所有资源；另一种是允许进程在没有资源时才可申请，而在申请更多资源之前，必须释放已分配的所有资源；\n非抢占：可以使用这样的协议破坏非抢占：如果一个进程占有资源并申请另一个不能被立即分配的资源，那么其现有已分配的资源都可以被抢占，即这些资源都被隐式地释放了；\n循环等待：资源排序？不可行。要从应用程序设计角度解决循环等待问题。\n\n死锁避免死锁预防的方法限制了资源的申请方式，副作用是低设备使用率和系统吞吐率。另一种方式：通过计算可用资源与进程所需资源来决定当前申请是否能够给予满足或必须等待，从而避免死锁发生。：\n\n银行家算法\n资源分配图算法\n安全状态\n\n死锁检测\n死锁恢复\n\n终止进程：一次终止一个进程直到死锁解除；一次性终止所有死锁进程；\n抢占资源：问题有 如何选择牺牲品，即抢占哪个进程的资源；回滚，被抢占的进程如何处理；饥饿，如何确保不会发生饥饿（某一进程总是被选为牺牲品）。\n\n","categories":["OS"],"tags":["OS"]},{"title":"java-原子操作","url":"/2018/04/20/java/Thread/%E5%8E%9F%E5%AD%90%E6%93%8D%E4%BD%9C/","content":"在 JUC 包的许多类中，如 Semaphore、ConcurrentLinkedQueue，都提供了比 synchronized 机制更高的性能和可伸缩性。这种性能的提升主要来源于 原子变量 和 非阻塞的同步机制。主要是利用 CPU 硬件对并发的支持，如 CAS 技术等。\n分类java.util.concurrent.atomic 包中提供了一些原子类：AtomicXxx，它们是线程安全的，但不是通过同步或锁机制来实现的，比锁的粒度更细，量级更轻。原子变量的操作会变为平台提供的用于并发访问的硬件原语。由于是非阻塞算法设计，不存在死锁和其他活跃性问题。即使原子变量没有用于非阻塞算法的开发，它们也可以作为一种“更好的 vloatile 类型变量”。原子变量提供了与 volatile 类型变量相同的内存语义，并且支持原子的更新操作，从而使它们更加适用于实现计数器、序列生成器和统计数据收集等，同时还能比基于锁的方法提供更高的可伸缩性。共有 12 个原子变量类，细分如下：\n\n标量类（Scalar）：AtomicInteger、AtomicLong、AtomicBoolean、AtomicReference。最常用的一类原子变量；\n更新器类：AtomicIntegerFieldUpdater、AtomicLongFieldUpdater、AtomicReferenceFieldUpdater\n数组类：AtomicIntegerArray、AtomicLongArray、AtomicReferenceArray；\n复合变量类：AtomicStampedReference、AtomicMarkableReference；\n\n所有这些类都支持 CAS。AtomicInteger、AtomicLong 还支持算术运算。如果想模拟其他基本类型的原子变量，可以将 short、byte 等类型通过与 int 类型进行转换，以及使用 floatToIntBits 或 doubleToLongBits 来转换浮点数。\n为什么不直接使用锁锁有以下问题：\n\n因线程持有锁而导致其他线程被挂起并在稍后恢复的过程中，切换上下文或线程调度的开销可能比较大；\n持有锁的线程被延迟执行（缺页、调度延迟等）情况发生时，所有等待该锁的其他线程也将无法执行：\n对于细粒度的操作（如递增计数器）来说，锁是一种高开销的机制。\n\nJava 语言的锁定语法本身很简洁，但 JVM 和操作在管理锁时需要完成的工作并不简单。实现锁定时需要遍历 JVM 中一条非常复杂的代码路径，并可能导致 OS 级的锁定、线程挂起以及上下文切换等操作。\n独占锁是一种悲观技术——它假设最坏情况（如果你不锁门，那么就会有破坏者进入），并且只有在确保其他线程不会造成干扰的情况下才能执行。对于细粒度的操作，还有一种更高效的乐观方法，可以在不发生干扰的情况下完成更新操作。这种方法需要借助冲突检查机制来判断在更新过程中是否存在来自于其他线程的干扰，如果存在，这个操作将失败，并且可以选择是否重试。\n硬件对并发的支持 CAS实现方面见底层技术和内存模型。以 AtomicInteger 为例，看看在没有锁的情况下如何做到数据的正确性。\npublic class AtomicInteger extends Number implements java.io.Serializable &#123;\n    private volatile int value; \n    ... &#125;\n显然，在没有锁的情况下，要借助 volatile 解决可见性问题，以便在获取变量的值的时候可以直接读取：\npublic final int get() &#123; return value; &#125;\n++i 的实现：\n// jdk 1.7-\npublic final int incrementAndGet() &#123;\n    for (;;) &#123;\n        int current = get();\n        int next = current + 1;\n        if (compareAndSet(current, next))\n            return next;\n    &#125;\n&#125;\n...\npublic final boolean compareAndSet(int expect, int update) &#123;\n    return unsafe.compareAndSwapInt(this, valueOffset, expect, update);\n&#125;\n可见在这里采用了 CAS（compareAndSet）操作：每次从内存中读取数据然后将此数据和 +1 后的结果进行 CAS 操作，如果成功就返回结果，否则重试直到成功为止。其中 compareAndSet 方法利用 JNI 来完成 CPU 指令的操作。而到了 JDK1.8+，该方法有所调整，但整体解决方案还是一样的：\npublic final int incrementAndGet() &#123;\n    return U.getAndAddInt(this, VALUE, 1) + 1;\n&#125;\n...\npublic final int getAndAddInt(Object o, long offset, int delta) &#123;\n    int v;\n    do &#123;\n        v = getIntVolatile(o, offset);\n    &#125; while (!weakCompareAndSetInt(o, offset, v, v + delta));\n    return v;\n&#125;\n\n","categories":["java"],"tags":["java","并发"]},{"title":"CPU调度","url":"/2018/04/20/OS/CPU%E8%B0%83%E5%BA%A6/","content":"CPU 调度的基本单位是线程。对于单处理器系统，每次只允许一个进程运行，任何其他进程必须等待，直到 CPU 空闲能被调度。多道程序 的目标是在任何时候都有某些进程在运行，以最大化利用 CPU：多个进程同时处于内存中，当前正在执行的进程遇到必须等待的情况，如等待 I&#x2F;O 请求完成时，OS 从该进程拿走 CPU 的使用权，交由其他进程继续执行。即，CPU 调度。几乎所有的计算机资源在使用前都需要调度，而 CPU 是最重要的资源之一。所以 CPU 调度设计很重要。\n抢占调度CPU 调度决策在4种环境下发生：\n\n当一个进程从运行状态切换到等待状态（如，I&#x2F;O 请求，调用 wait( ) 等待一个子进程的终止）\n当一个进程从运行状态切换到就绪状态（如，出现中断）\n当一个进程从等待状态切换到就绪状态（如，I&#x2F;O 完成）\n当一个进程终止时。\n\n对于情况 1 和 4，只能直接调度。而对于情况 2 和 3，可以进行选择。当调度只能发生在情况 1 和 4 时，称调度方案是 非抢占的（nonpreemptive） 或 协作的（cooperative），否则，称为 抢占的（preemptive）。非抢占调度中，一旦 CPU 分配给一个进程，那么该进程会一直使用 CPU 直到进程终止或切换到等待状态。但，抢占调度对访问共享数据是有代价的：考虑两个进程共享数据的情况，第一个进程正在更新数据时，它被抢占以使得第二个进程能够运行，此时可能试图读共享区域的数据，那么该数据就处在不一致的状态。这时需要 同步机制 来协调：OS 随时都能接受中断，所以受中断影响的代码段必须加以保护以避免同时访问。\n调度算法\n先到先服务（First Come， First Served）最简单的调度算法，可以用 FIFO 队列来实现。这是一种非抢占式的调度算法，考虑到无法均衡 CPU 密集型和 I&#x2F;O 密集型任务，该方法平均性能并不理想。\n\n最短作业优先（Shortest-Job First）SJF 调度算法可证明为最佳，因为给定一组进程，该算法平均等待时间最小。但其困难在于，如何知道下一个 CPU 区间的长度，即，如何确定哪个进程是”最短作业”。所以近似做法是，用数学方式预测下一个 CPU 区间长度。\n\n优先级调度SJF 也可以算作优先级调度算法的一个特例：预测的 CPU 区间越大，优先级越小。优先级通常为固定区间的数字，但对于数字大小和优先级的对应（更小的数代表更高还是更低的优先级），各种系统的具体实现并不相同。优先级调度可以是抢占的也可以是非抢占的：新到达进程优先级高于当前进程，抢占式调度会抢占 CPU，非抢占式调度只将新进程加到就绪队列的头部。主要问题是 无穷阻塞&#x2F;饥饿，可以运行但缺乏 CPU 的进程可以认为是阻塞的，优先级调度可能会使某个低优先级进程无穷等待 CPU。据说，在 1973 年关闭 MIT 的 IBM 7094 时，发现有一个低优先级进程是于 1967 年提交但一直未运行。解决方案之一是老化技术（aging）：随着等待时间的加长，增加等待进程的优先级。\n\n轮转法（Round-Robin）专门为分时系统设计的。类似于 FCFS 调度，但增加了抢占以切换进程。定义一个较小的时间单元（时间片），通常为 10-100 ms，将就绪进程队列作为循环队列，为每个进程分配不超过一个时间片的 CPU。等待时间可能较长。问题是选择合适的时间片大小：过大就和 FCFS 算法一样，过小会导致频繁切换进程，导致系统调用上下文切换所浪费的时间开销过大。\n\n多级队列（Multilevel Queue Scheduling Algorithm）如果进程可以很容易地分组情况下，如划分为前台（交互）进程和后台（批处理）进程，可以建立另一种调度算法。对每个分组采用不同的调度算法，如前台进程队列采用 RR 调度，后台队列采用 FCFS 调度等。此外，队列之间也必须有调度，通常采用固定优先级抢占调度：显然前台进程队列需要更高的优先级。进一步，多级反馈队列调度算法（Multilevel Feedback Queue Scheduling Algorithm），允许进程在队列之间移动：如果进程使用过多 CPU 时间，会被转移到更低优先级队列；而较低优先级队列中等待时间过长的进程会被转移到更高优先级队列，以这种形式的老化来防止饥饿的发生。\n\n\n多处理器的调度\n非对称多处理（Asymmetric Multiprocessing）让一个处理器（主服务器）处理所有的调度决定、I&#x2F;O 处理和其他系统活动，其他处理器只执行用户代码。这种方法比较简单：只有一个处理器访问系统数据结构，减轻了数据共享的需要。\n\n对称多处理（Symmetric Multiprocessing，SMP）每个处理器自我调度。所有进程处于一个共同的就绪队列中，或每个处理器有它自己的私有就绪进程队列。但要保证两个处理器不能选择同一个进程，且进程不会从队列中丢失。\n\n\n处理器亲和性进程从一个处理器中断，再次执行时被转移到其他处理器的话：被迁移的第一个处理器缓存中的内容必须置为无效，而将要迁移到的第二个处理器的缓存需要重建。由于使缓存无效或重新构建的代价很高，大多数 SMP 试图避免在处理器间迁移进程，而是尽可能保证使一个进程在同一个处理器上运行，称之为处理器亲和性，即一个进程需要有一种对其所在处理器的亲和性。如Linux，提供一个支持硬亲和性（hard affinity）的系统调用，从而允许进程指定它不允许迁移到其他处理器上。如果 OS 无法保证这一点，就会出现软亲和性（soft affinity），这时进程可能会在处理器间移动。\n负载平衡（Load Balancing）SMP 系统中，保持所有处理器工作负载平衡很重要。通常这一概念只是针对拥有自己私有可执行进程队列的处理器而言的。在具有共同队列的系统中，通常不需要负载平衡，因为一旦某个处理器完成了一个进程，它就会立即从队列中取下一个进程继续执行。\n","categories":["OS"],"tags":["OS"]},{"title":"目录结构","url":"/2018/04/18/Linux/%E7%9B%AE%E5%BD%95%E7%BB%93%E6%9E%84/","content":"&#x2F;　　根目录，万物起源。——where everything begins.&#x2F;bin　　包含系统启动和运行所必须的二进制程序。&#x2F;boot　　包含 Linux 内核、最初的 RMA 磁盘映像（系统启动时，由驱动程序所需）、启动加载程序：\n\n&#x2F;boot&#x2F;grub&#x2F;grub.conf or menu.lst　　被用来配置启动加载程序。&#x2F;boot&#x2F;vmlinuz　　Linux 内核。\n\n&#x2F;dev　　包含设备结点的特殊目录。“一切皆文件”也适用于设备，在这个目录里，内核以文件形式维护着它支持的设备。&#x2F;etc　　包含所有系统层面的配置文件。也包含一系列的 shell 脚本，在系统启动时，这些脚本运行每个系统服务。这个目录中的任何文件应该是可读的文本文件。全称：一说 et cetera. 即，常用的 etc 缩写，用来存放“不能归类到其他目录的所有内容；一说 Editable Text configuration&#x2F;Extended Tool Chest.(用来存放配置文件)”\n\n&#x2F;etc&#x2F;crontab　　定义自动运行的任务。可用“crontab -e”查看所添加的自启动任务。&#x2F;etc&#x2F;fstab　　包含存储设备的列表，以及与它们相关的挂载点。&#x2F;etc&#x2F;passwd　　用户账户列表\n\n&#x2F;home　　通常配置环境下，系统会在 &#x2F;home 下，给每个用户分配一个目录。普通用户只能在自己的目录下创建文件。这个限制保护系统免受错误的用户活动破坏。&#x2F;lib　　核心系统程序所需要的库文件。这些文件与 Windows 中的动态链接库相似。&#x2F;lost+found　　每个使用 Linux 文件系统的格式化分区或设备，例如 ext4 文件系统，都会有这个目录。当部分恢复一个损坏的文件系统时，会用到这个目录。除非文件系统真的损坏了，否则这个目录会保持空状态。&#x2F;media　　现代 Linux 中，&#x2F;media 会包含可移除媒体设备的挂载点，例如 USB 驱动器，CD-ROMs 等。这些设备连接到计算机后，会自动挂载到这个目录结点下。&#x2F;mnt　　早些的 Linux 中，该目录包含可移除设备的挂载点。&#x2F;opt　　用来安装“可选的”软件。主要存储可能安装在系统中的（商业）软件。&#x2F;proc　　Linux 进程文件系统（process file system），也称虚拟文件系统，之所以称之为虚拟，是因为其包含的文件和子目录并未存储在磁盘上，而是由内核在进程访问此类信息时动态创建而成。以文件系统目录和文件的形式，提供一个指向内核数据结构的接口，为查看和改变各种系统属性提供方法。它是一个由 Linux 内核维护的虚拟文件系统，只存在内存当中，不占用外存空间。这个目录很特殊。从存储在硬盘上的文件的意义上说，它不是真正的文件系统，而是根据用户文件 I&#x2F;O 请求的需要来计算。以文件系统的方式为访问系统内核数据的操作提供接口。它所包含的文件是内核的窥视孔，用户和应用程序可以通过 proc 得到系统的信息，这些文件是可读的，可以反映内核是怎样监管计算机的。比如 ps 命令，Linux 下此命令是一个完全非特权程序，它就是对 &#x2F;proc 的部分信息进行解析和格式化，用以查看系统中运行的各个进程的相关信息。&#x2F;root　　root 账户的 &#x2F;home 目录。&#x2F;sbin　　包含“系统”二进制文件。它们是用来完成重大系统任务的程序，通常为 su（超级用户） 保留。&#x2F;tmp　　存储由各种程序创建的临时文件。一些配置会导致系统每次重启时清空这个目录。&#x2F;usr　　在 Linux 中，&#x2F;usr 可能是最大的一个目录，包含普通用户所需要的所有程序和文件。\n\n&#x2F;usr&#x2F;bin　　包含系统安装的可执行程序。通常，这里会包含很多程序。&#x2F;usr&#x2F;lib　　包含由 &#x2F;usr&#x2F;bin 目录中的程序所用的共享库。usr&#x2F;local　　非系统发行版自带，却打算让系统使用的程序安装目录。通常，由源码编译的程序会安装在 &#x2F;usr&#x2F;local&#x2F;bin 下。新的 Linux 中会存在这个目录，但是空的，直到系统管理员放些东西进去。&#x2F;usr&#x2F;sbin　　包含许多系统管理程序。&#x2F;usr&#x2F;share　　包含许多由 &#x2F;usr&#x2F;bin 中程序使用的共享数据。如默认的配置文件、图标、桌面背景、音频文件等。&#x2F;usr&#x2F;share&#x2F;doc　　大多数安装在系统的软件包会包含一些文档。一般在这里可以找到按照软件包分类的文档。\n\n&#x2F;var　　除了 &#x2F;tmp 和 &#x2F;home 外，一般目录都是静态的，即，内容不会改变。&#x2F;var 是可能需要改动的文件存储的地方。各种数据库、假脱机文件、用户邮件等，都驻扎在这里。&#x2F;var&#x2F;log　　包含日志文件，各种系统活动的记录。这些文件非常重要，并且应该时时监测它们。其中比较重要的有：\n\n&#x2F;var&#x2F;log&#x2F;messages　　系统报错日志。核心日志，包含系统启动时的引导信息，运行时的状态消息，IO 错误，网络错误和其他系统错误等。&#x2F;var&#x2F;log&#x2F;boot.log　　系统引导日志。&#x2F;var&#x2F;log&#x2F;dmesg　　核心启动日志。&#x2F;var&#x2F;log&#x2F;secure　　安全信息和系统登陆与网络连接信息。&#x2F;var&#x2F;log&#x2F;wtmp　　记录登陆者信息，二进制文件，who -u -&#x2F;var&#x2F;log&#x2F;wtmp 查看信息。&#x2F;var&#x2F;log&#x2F;cron　　自启动任务日志\n\n","categories":[],"tags":["Linux"]},{"title":"查询","url":"/2018/04/17/MySQL/%E6%9F%A5%E8%AF%A2/","content":"查询一般的查询处理步骤\n语法分析与翻译\n优化\n执行\n\n进一步的，MySQL 中处理查询的步骤：\n\n客户端发送一条查询给服务器。\n服务器先检查查询缓存（如果查询缓存是开的），如果命中，则直接返回缓存中的结果；否则进入下一步。\n服务器端进行 SQL 解析、预处理，再经优化器生成执行计划。\nMysQL 根据优化器生成的执行计划，调用相应存储引擎的 API 来执行查询。\n返回结果给客户端。\n\n执行计划(execution plan)执行计划就是 MySQL 如何执行一条 sql 语句，包括 sql 查询的顺序、是否适用索引、以及使用的索引信息等内容。使用 explain 关键字查看 sql 语句生成的执行计划。基本语法：\nmysql> EXPLAIN SELECT ...;\n一些变体：\n       // 将表格形式的执行计划转化成 select 语句，\n       // 使用 show warnings 可以得到优化器优化后的查询语句\nmysql> EXPLAIN EXTENDED SELECT ...;\n\n       // 用于分区表的EXPLAIN\nmysql> EXPLAIN PARTITIONS SELECT ...;\n一个例子：\n\n\n可以看到，执行计划中包含 id、table 等基本信息：\nid由一组数字组成，表示一个查询中各个子查询的执行顺序。按照如下规则执行：\n\nid 相同，按顺序执行，从上到下；\nid 不同，id 值越大优先级越高，越先被执行；\nid 为 null，表示一个结果集，不需要使用它查询，常出现在 union 等查询语句中。\n\nselect_type每个子查询的查询类型，常见查询类型有：\n\n\ntable查询的数据表，当从衍生表中查询数据时会显示 “derived x” x 对应执行计划的 id。\npartitions表分区、表创建时可以指定通过哪个列进行表分区，如：\ncreate table tmp (\n    id int unsigned not null AUTO_INCREMENT,\n    name varchar(255),\n    PRIMARY KEY (id)\n) engine = innodb\npartition by key (id) partitions 5;\n对应的执行计划中 partitions 字段：\n\n\ntype\nALL：扫描全表数据\nindex：遍历索引\nrange：索引范围查找\nindex_subquery：在子查询中使用 ref\nunique_subquery：在子查询中使用 eq_ref\nref_or_null：对 Null 进行索引的优化的 ref\nfulltext：使用全文索引\nref：使用非唯一索引查找数据\neq_ref：在 join 查询中使用 PRIMARY KEYorUNIQUE NOT NULL 索引关联。\nconst：使用主键或者唯一索引，且匹配的结果只有一条记录。\nsystem const：连接类型的特例，查询的表为系统表。\n\npossible_keys可能使用的索引，不一定会使用。查询涉及到的字段上若存在索引，则该索引将被列出来。当该列为 NULL 时就要考虑当前的 SQL 是否需要优化了。\nkey在查询中实际使用的索引，若没有使用索引，显示为 NULL。查询中若使用了覆盖索引(覆盖索引：索引的数据覆盖了需要查询的所有数据)，则该索引仅出现在 key 列表中。 \nkey_length索引长度char()、varchar() 长度的计算公式：(Character Set：utf8mb4&#x3D;4,utf8&#x3D;3,gbk&#x3D;2,latin1&#x3D;1) * 列长度 + 1(允许null) + 2(变长列)其他类型索引长度的计算公式：\nCREATE TABLE `student` (\n  `id` int(11) unsigned NOT NULL AUTO_INCREMENT,\n  `name` varchar(128) NOT NULL DEFAULT '',\n  `age` int(11),\n  PRIMARY KEY (`id`),\n  UNIQUE KEY `idx` (`name`),\n  KEY `idx_age` (`age`)\n) ENGINE=InnoDB AUTO_INCREMENT=2 DEFAULT CHARSET=utf8mb4;\nname 索引长度：编码为 utf8mb4，列长为 128，不允许为 NULL,字段类型为 varchar(128)。则 计算其 key_length &#x3D; 128 * 4 + 0 + 2 &#x3D; 514：\n\nage 索引长度：int 类型占 4 位，允许 null，索引长度为 5：\n\n\nref表的连接匹配条件，即哪些列或常量被用于查找索引列上的值.\nrows返回估算的结果集数目，并不是一个准确的值。\nextraextra的信息非常丰富，常见的有：\n\nUsing index：使用覆盖索引\nUsing where：使用了 where 子句来过滤结果集\nUsing filesort：使用文件排序，使用非索引列进行排序时出现，非常消耗性能，尽量优化。\nUsing temporary：使用了临时表。参考：MySQL extra\n\n执行计划\n查询缓存很多数据库都能够缓存查询的执行计划，对于相同类型的 sql 就可以跳过 sql 解析和执行计划生成阶段。MySQL 还有另一种缓存类型：缓存完整的 SELECT 查询结果，即查询缓存。MySQL 查询缓存保存查询返回的完整结果，当查询命中该缓存时，直接返回结果，跳过解析、优化和执行阶段。这对查询发起者是透明的，是否使用查询缓存数据并不影响用户获得的查询结果。默认是关闭的。在配置文件中使用相关参数配置：\n[mysqld]：\n// 开启\nquery_cache_type = ON  \n// 使用的总内存空间 \nquery_cache_size = 20M  \n// 分配内存块的最小单位\nquery_cache_min_res_unit\n// 最大缓存结果数量\nquery_cache_limit\n// 如果数据被其他连接锁住，是否仍从缓存中取结果\nquery_cache_wlock_invalidate\n...\n\n\n跟踪表变化查询缓存会跟踪查询中涉及到的所有表，如果某个表被修改，那么所有和该表有关的查询缓存数据都将失效。尽管表变化可能不影响（某些）查询缓存数据的结果，但这种实现代价很小而且简单。缓存数据存放在一个引用表中，通过哈希值包含查询语句及其使用的数据库、协议版本等信息，通过该哈希值来判断是否命中缓存。\n何时使用查询缓存缓存和缓存失效都会带来额外开销，只有当断言缓存带来的资源节约大于缓存资源消耗时才应考虑使用查询缓存，这跟服务器压力模型有关。理论上可以通过对比开启&#x2F;关闭的系统运行效率来判断，但这并不能给出进一步的性能指标差异是否与查询缓存相关。\n哪些因素导致性能下降查询的生命周期：从客户端到服务器，在服务器上进行解析，生成执行计划，执行，返回结果给客户端。其中“执行”可以看作最重要的阶段，它包括为检索数据而发起的所有存储引擎调用、调用中的数据处理（筛选、排序、分组等）等操作，这也是优化重点考虑的部分。此外的时间消耗如网络、CPU 计算、生成统计信息、锁操作等，这些的优化和查询优化没有直接关系。而每个消耗大量时间的查询操作中，基本都有一些不恰当的操作：某些操作重复了很多次，某些操作执行很慢等，优化的目的就是减少和消除这些不必要的操作。\n慢查询性能低下的一个主要原因是访问了不必要的数据，或者说访问的数据太多。某些查询可能不可避免地需要筛选大量数据，但这种操作并不多见。大部分性能低下的查询都可以通过减少访问的数据量来优化：\n\n确认是否检索大量超过需要的数据，通常是访问了太多的行，也有可能是访问了不必要的列。\n确认 MySQL 服务器层是否在分析大量超过需要的数据行。\n\n慢查询日志MySQL 的慢查询日志（slow query log）是其日志记录的一种：用来记录 响应时间超过阈值的语句。默认情况下该日志记录并不启用，因为开启会对性能造成一定影响，一般调优需要时会开启，以记录语句执行情况从而分析查找可以调优的部分。\n相关参数慢查询日志相关参数slow_query_log：是否开启慢查询日志，1 表示开启，0 表示关闭log-slow-queries：旧版（5.5-）慢查询日志存储路径。可以不设置该参数，系统默认给一个缺省的文件 host_name-slow.logslow-query-log-file：新版（5.6+）慢查询日志存储路径。可以不设置该参数，系统默认给一个缺省的文件 host_name-slow.loglong_query_time：慢查询阈值，当查询时间多于设定的阈值时，记录日志。单位：slog_queries_not_using_indexes：未使用索引的查询也被记录到慢查询日志中（可选项）。log_output：日志存储方式。log_output&#x3D;’FILE’ 表示将日志存入文件，默认值是’FILE’。log_output&#x3D;’TABLE’ 表示将日志存入数据库，这样日志信息就会被写入到 mysql.slow_log 表中。MySQL 支持同时两种日志存储方式，配置的时候以逗号隔开即可：log_output&#x3D;’FILE,TABLE’。日志记录到系统的专用日志表中，要比记录到文件耗费更多的系统资源，因此对于需要启用慢查询日志，又需要能够获得更高的系统性能，那么建议优先记录到文件。\n慢查询概念MySQL慢查询\n慢查询分析方法mysqldumpslow安装自带的分析工具，可以查看慢查询日志里记录的语句，也就是超过执行时间阈值的那些执行效率低下的语句。可以汇总分类，用参数控制排序方式、匹配输出等，从而更好地分析。\nexplain 分析使用 EXPLAIN 关键字可以模拟优化器执行 SQL 查询语句，从而知道 MySQL 是如何处理 SQL 语句的。这可以帮助分析查询语句或是表结构的性能瓶颈。通过 EXPLAIN 命令可以得到:\n\n表的读取顺序\n数据读取操作的操作类型\n哪些索引可以使用\n哪些索引被实际使用\n表之间的引用\n每张表有多少行被优化器查询\n\nprofiling 分析如果觉得 EXPLAIN 的信息不够详细，可以同通过 profiling 命令得到更准确的 SQL 执行消耗系统资源的信息。profiling 默认是关闭的，打开命令：\nmysql> set profiling=1;\n\n查询分析工具\n执行顺序查询优化https://www.jianshu.com/p/dac715a88b44\n","categories":["DB"],"tags":["DB","MySQL"]},{"title":"语法","url":"/2018/04/17/MySQL/%E8%AF%AD%E6%B3%95/","content":"WHERE &amp; HAVING首先，二者都可以实现过滤记录的功能。区别主要有：\n\n都作为过滤记录使用时，WHERE 可以作用于表的任意列字段，而 HAVING 只能作用于之前已经筛选出的列字段；\n作用对象不同，WHERE 作用于表和视图，HAVING 作用于组。WHERE 无法与聚集函数（AVG() COUNT() SUM() MAX() MIN() 等）一起使用，即，再筛选条件只能是表中的列，而 HAVING 可以将结果的聚集处理组作为再筛选条件，即，一般会包含聚集函数，跟在 GROUP BY 之后；\n即，WHERE 在聚合前筛选，即作用在 GROUP BY 和 HAVING 之前，HAVING 在聚合后对组记录再进行筛选。\n\njoin(连接&#x2F;联结)在同一查询的结果集中包含来自多个表的列，这种操作叫做连接。类型有 自连接、 内连接、外连接、交叉连接。\n自连接自连接是指对一张表的列进行自我连接，即多个查询操作作用在同一张表上的列。一种方法是嵌套子查询，还有一种方法是使用表别名。\n内连结默认的连接方式。\n等值连接连接条件中使用等于号（&#x3D;）运算符，其查询结果中列出被连接表中的所有列，包括其中的重复列。\n不等连接连接条件中使用除等于号之外运算符（&gt;、&lt;、&lt;&gt;、&gt;&#x3D;、&lt;&#x3D;、!&gt;和!&lt;）\n外连接左连接&#x2F;左外连接返回左表中的所有行，如果左表中行在右表中没有匹配行，则结果中右表中的列返回空值。\n右连接&#x2F;右外连接与左连接相反，返回右表中的所有行，如果右表中行在左表中没有匹配行，则结果中左表中的列返回空值。\n全连接是左连接和右连接的组合，返回左表和右表中的所有行。当某行在另一表中没有匹配行，则另一表中的列返回空值。\n交叉连接&#x2F;笛卡儿积不带 WHERE 条件子句，它将会返回被连接的两个表的笛卡尔积，返回结果的行数等于两个表行数的乘积。如果带 WHERE，返回或显示的是匹配的行数。有 WHERE 子句，往往会先生成两个表行数乘积的数据表，然后才根据 WHERE 条件从中选择。\n参考：连接概念\n","categories":["DB"],"tags":["DB","MySQL"]},{"title":"HTTP","url":"/2018/04/17/CN/HTTP/","content":"HyperText Transfer Protocol，超文本传输协议，它是 web 的核心。HTTP 协议是无状态的，即对于事务处理没有记忆能力。\nHTTP 请求报文格式一个 HTTP 请求报文由请求行(request line)、首部行（header line）、空行、请求数据四部分组成。\n\n\n请求行3个字段：方法字段、URL 字段、协议版本字段。\n方法字段包括：GET、POST、HEAD、PUT、DELETE、OPTIONS、TRACE、CONNECT\nGET绝大多数请求报文使用 GET 方法：从服务器读取文档、点击网页链接&#x2F;键入网页地址浏览网页等。该方法要求服务器将 URL 定位的资源放在响应报文的数据部分，回送给客户端。此时请求数据为空，而请求参数和对应的值附加在 URL 后面，利用‘？’代表 URL 的结尾与请求参数的开始，并且参数长度受限，一般 1024 个字符。不适合传送私密数据（要放在 URL 后面），也不适合大量数据传送的场景。\nPOST对于以上不适合 GET 的情况，可以考虑 POST 方式（即 POST 可以完成 GET 请求）。可以允许客户端给服务器提供更多的信息。将请求参数封装在 请求数据 中，以 “名称&#x2F;值”的形式，没有大小限制，也不会显示在 URL 中。适用于页面表单中（但 GET 同样能用于表单）。二者各有优势，分情况使用。\nGET vs POST\nGET 在浏览器回退时是无害的，而 POST 会再次提交请求。\nGET 产生的 URL 地址可以被 Bookmark，而 POST 不可以。\nGET 请求会被浏览器主动 cache，而 POST 不会，除非手动设置。\nGET 请求只能进行 url 编码，而 POST 支持多种编码方式。\nGET 请求参数会被完整保留在浏览器历史记录里，而 POST 中的参数不会被保留。\nGET 请求在 URL 中传送的参数是有长度限制的，而 POST 没有限制。\n对参数的数据类型，GET 只接受 ASCII 字符，而 POST 没有限制。\nGET 比 POST 更不安全，因为参数直接暴露在 URL 上，所以不能用来传递敏感信息。\nGET 参数通过 URL 传递，POST 放在 Request body 中。\n\n参考: GET 与 POST 区别\nHEAD类似 GET，只不过服务器接收到 HEAD 请求后只返回响应头，而不发送相应内容。因此当我们只需要查看某个页面的状态的时候，使用 HEAD 是非常高效的。\nPUT向服务器放置资源；\nDELETE请求服务器删除资源；\nURL 字段带有请求对象的标识。\n协议版本字段自解释的，一般为 HTTP&#x2F;1.1.\n首部行通知服务器有关客户端请求的信息，用“关键字: 值”对组成，每行一对。典型的请求首部有：\n\nUser-Agent：产生请求的浏览器类型；\nAccept：客户端可识别的内容类型列表；\nHost：请求的主机名，允许多个域名同处一个IP地址，即虚拟主机。\nConnection:Keep-Alive&#x2F;Close：长连接&#x2F;短连接标识\n\n空行最后一个首部行之后的一行，发送回车符和换行符，通知服务器不再有请求头。\n请求数据请求数据不在 GET 方法中使用，而在 POST 方法中使用。POST 方法适用于需要客户填写表单的场合。\nHTTP 响应报文一个 HTTP 响应报文由三部分组成：状态行(status line)、首部行(header line)、响应数据(response body)。\n\n\n状态行3个字段：协议版本字段、状态码、响应状态信息。\n协议版本字段一般为 HTTP&#x2F;1.1；\n状态码（2xx、4xx 等）。\n响应状态信息跟随在状态码后的状态信息：\n1xx指示信息，请求已接收，继续处理。\n2xx成功，请求已被成功接收、处理、接受。\n\n200 OK：请求成功；\n\n3xx重定向，要完成请求必须进行更进一步的操作。\n\n301 Moved Permanently：请求的对象已经被永久转移，新的 URL 在响应报文的 Location 首部中。客户端将自动获取新的 URL。\n303 See Other：重定向到其他页面，见 Location\n304 Not Modified：告诉客户端自从上次请求取得后，该资源未修改，可使用本地缓存\n\n4xx客户端错误，请求有语法错误或请求无法实现。\n\n400 Bad Request：客户端请求语法有错误，不能被服务器所理解\n401 Unauthorized：请求未经授权\n403 Forbidden：服务器收到请求，但是拒绝提供服务\n404 Not Found：请求资源不存在\n\n5xx服务器端错误，未能实现该合法请求。\n\n500 Internal Server Error：服务器发生不可预期的错误\n503 Server Unavailable：服务器当前不能处理客户端的请求，一段时间后可能恢复\n505 HTTP Version Not Supported：服务器不支持请求报文使用的 HTTP 协议版本\n\n首部行常见的有：Connection：close   告诉客户端发完报文后将关闭该 TCP 连接；Date：xxx   服务器发送该报文的时间；Server：xxx   服务器类型，如 Apache Web；Last-Modified：xxx   缓存相关；Content-Length：xxx   被发送对象的字节数；Content-Type：xxx   响应正文中对象的类型；Cache-Control：xxx   告诉客户端如何控制响应内容的缓存；Location：xxx   重定向请求资源；Set-Cookie：xxx   设置客户端的 cookie；\n响应数据即被请求的数据。\n长连接 短连接HTTP 协议的长连接和短连接，实质上是 TCP 协议的长连接和短连接。HTTP&#x2F;1.0 中，默认使用的是短连接，即，浏览器和服务器每进行一次 HTTP 操作，就建立一次 TCP 连接，任务结束就断开连接。如果客户端浏览器访问的某个 HTML 或其他类型的 Web 页中包含有其他的 Web 资源，如 JavaScript 文件、CSS 文件、图像文件等，每当浏览器遇到这样一个 Web 资源，就会建立一个 HTTP 会话。到了 HTTP&#x2F;1.1，默认使用长连接，即请求报文首部行中“Connection:Keep-Alive”字段，用以保持连接特性。使用长连接情况下，当打开一个网页后，客户端和服务器之间用于传输 HTTP 数据的 TCP 连接不会关闭，如果客户端再次访问这个服务器上的网页，会继续使用这个已经建立的连接。Keep-Alive 不会永久保持连接，而是有一个保持时间，可以在不同的服务器软件（如 Apache）中设置该变量，要求双方都支持长连接字段。\n对比显然，长连接可以省去较多的 TCP 建立&#x2F;关闭的操作，减少浪费，节约时间。对于频繁请求资源的场景，如直播、流媒体，较适用长连接。短连接对于服务器来说管理较为简单，适用于网页浏览等数据刷新频度较低的场景，存在的连接都是有用的连接，不需要额外的控制手段。但如果客户请求频繁，将在 TCP 的建立和关闭操作上浪费时间和带宽。\nHTTPSHypertext Transfer Protocol over Secure Socket Layer，以安全为目标的 HTTP 协议通道，简单讲是 HTTP 的安全版。即 HTTP 下加入 SSL 层。所以，HTTPS 的安全基础是 SSL，因此加密的详细内容就需要 SSL。\nhttps://www.jianshu.com/p/30b8b40a671chttps://www.cnblogs.com/zxj015/p/6530766.html\n","categories":["CN"],"tags":["CN"]},{"title":"CDN","url":"/2018/04/17/CN/CDN/","content":"Content Delivery Network，内容分发网络。以流式视频服务（或是流式音频也可采用）为例。\n","categories":["CN"],"tags":["CN"]},{"title":"网络层","url":"/2018/04/17/CN/%E7%BD%91%E7%BB%9C%E5%B1%82/","content":"\n可见，网络层主要由 3 个组件组成：IP 协议、路由选择协议、ICMP 协议。完成编址和转发。这里包括后两个。\nIPICMPInternet Control Message Protocol，因特网控制报文协议。典型用途是差错报告。如运行一个 Telnet、FTP、HTTP 会话时，有可能会遇到“目的网络不可达”之类的错误报文，它们就是在 ICMP 中产生的：在某个位置，IP 路由器不能找到一条路径，以通往 Telnet、FTP、HTTP 应用指定的主机，该路由器就会向应用的发起端主机发出一个类型 3 的 ICMP 报文以指示该错误。ICMP 报文由一个类型字段和一个编码字段组成，并且包含引起该 ICMP 报文首次生成的 IP 数据报的首部和前 8 字节内容（用以发送方确定引发该擦错的数据报）。一些 ICMP 报文类型：\n\n可见，常用的 ping 就是发送一个 ICMP 类型 8 编码 0 的报文段到指定主机。目的主机看到该回显请求（echo）后，发回一个类型 0 编码 0 的 ICMP 回显应答。大多数 TCP&#x2F;IP 实现直接在操作系统中支持 ping 服务，即该服务器不是一个进程。ICMP 被当做 IP 层的一部分。\nIGMPInternet Group Management Protocol，互联网组管理协议。用于主机和路由器的多播路由选择协议。也是 IP 层的一部分。IGMP 报文通过 IP 首部中协议字段值为 2 来指明，有固定的报文长度：\n\nIGMP 报文类型只有 3 种：\n\nmembership_query\nmembership_report\nleave_group\n\n路由选择协议路由选择算法有链路状态路由选择算法、距离向量路由选择算法、层次路由选择。\n毒性反转（poisoned reverse）技术见 CNATD p253.\nRIP自治系统内部的路由选择协议。Routing Information Protocol，路由选择信息协议。使用的是 距离向量算法，使用跳数作为费用测度。\nOSPF自治系统内部的路由选择协议。Open Shortest Path First，开放最短路径优先。核心是一个使用洪范链路状态信息的 链路状态协议 和一个 Dijkstra 最低费用路径算法。\nBGP自治系统间的路由选择协议。Border Gateway Protocol，边界网关协议。BGP4 是当今互联网域间路由选择协议事实上的标准。\n网络层设备主要是路由器。\n","categories":["CN"],"tags":["CN"]},{"title":"计算机网络","url":"/2018/04/17/CN/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C/","content":"OSI(Open System Interconnect，开放式系统互联) 7 层模型：\n\n\n\n\n重要的内容集中在应用层（HTTP、FTP、SMTP、远程登陆协议（TELNET、Rlogin），运输层（TCP、UDP），网络层（IP、ICMP、IGMP、RIP）。\n应用层\nHTTP HTTPS超文本传输协议，一种文件传输协议，运行在 TCP 之上。\n\nFTP文件传输协议，运行在 TCP 之上。\n\nSMTP简单邮件传输协议，运行在 TCP 之上。\n\nTELNET远程登陆服务的标准协议和主要方式，运行在 TCP 之上。\n\nDNS域名服务系统。\n\n\n运输层网络层IPICMP","categories":["CN"],"tags":["CN"]},{"title":"链路层物理层","url":"/2018/04/17/CN/%E9%93%BE%E8%B7%AF%E5%B1%82%E7%89%A9%E7%90%86%E5%B1%82/","content":"链路层服务\nframing：成帧。在每个网络层数据报经链路层传送之前，几乎所有的链路层协议都要将其用链路层帧封装起来。一个帧由一个数据字段和若干首部字段组成，网络层数据报就封装在数据字段中。帧结构由具体的链路层协议规定。\n链路接入。媒体访问控制协议（Medium Access Control，MAC） 规定了帧在链路上的传输规则。\n可靠交付。当链路层协议提供可靠交付服务时，它保证无差错地经链路层移动每个网络层数据报。与运输层 TCP 提供的可靠交付服务类似，链路层可靠交付服务通常通过确认和重传来保证。而许多有线的链路层协议并不提供可靠交付服务。\n差错检测和纠错。信号衰减、电磁噪声等可能导致链路层数据比特位差错，许多链路层协议提供这类错误的检测和纠正功能：让发送节点在帧中包含差错检测比特位，让接收节点进行差错检查。\n\n差错检测和纠错技术方法有：\n\n奇偶校验\n检验和\n循环冗余检测（Cyclic Redundancy Check，CRC）编码，也称多项式编码。\n\n设备链路层设备主要有：网卡、网桥。网卡：又称 NIC 卡，用于计算机和局域网的通信；网桥：用于在数据链路层扩展以太网，根据MAC帧的目的地址对收到的帧进行转发和过滤。 含有转发表。它隔离了冲突域，但不隔离广播域。\n寻址链路层使用 MAC 寻址。Media Access Control Address，媒体访问控制。也称局域网地址（LAN Address）、以太网地址（Ethernet Address）、物理地址（Physical Address）。48 位，IEEE 负责管理 MAC 地址空间的分配。\nARPAddress Resolution Protocol，ARP，地址解析协议。它是一个通用协议，但主要负责网络层地址（IP，主要是 32 位 IPv4）和链路层地址（MAC，48位）之间的转换。\n物理层设备主要有：HUB，中继器，网线（如果这个也算）。中继器：将信号放大再调整传输，防止网络早期远距离传输的信号衰减。HUB：HUB 模式下，某主机A向连在同一个 HUB 的主机 B 发送 bits 时，是先将 bits 发给 HUB，然后 HUB 直接发送给与该 HUB 相连接的每一个机器； HUB 中若有有多个主机想发送 bits，那么冲突可能会相当严重。因此后来引入了 Ethernet HUB，它有一个所谓的 CSMA&#x2F;CD 检测算法，用来解决 HUB 的冲突问题。半双工传输。\n","categories":["CN"],"tags":["CN"]},{"title":"应用层","url":"/2018/04/17/CN/%E5%BA%94%E7%94%A8%E5%B1%82/","content":"HTTP HTTPsFTPFile Transfer Protocol，文件传输协议，运行在 TCP 之上的应用层协议。FTP 使用两个并行的 TCP 连接，一个是控制连接（control connection），一个数据连接（data connection）。\n\n\n控制连接使用 21 端口。用于在两个主机之间传输控制信息，如用户标识、口令、改变远程目录命令、存放（put）&#x2F;获取（get）文件命令等。由于命令通常由用户键入，所以 IP 对控制连接的服务类型是“最大限度地减小延迟”。\n数据连接使用 20 端口。用于实际发送&#x2F;接收文件。由于该连接用于传输文件，所以 IP 对控制连接的服务类型是“最大限度地提高吞吐量”。用途分类：\n从客户向服务器发送一个文件；\n从服务器向客户发送一个文件；\n从服务器向客户发送文件或目录列表。\n\n过程\n\nClient 发起控制连接：当用户主机（Client）与远程主机（Server）开始一个 FTP 会话时，Client 首先在 Server 的 21 号端口发送本机用户标识和口令等，试图建立一个 TCP 连接，即控制连接。\nServer 响应：Server 在控制连接上接收切换目录以及文件传输请求之后，向 Client 发起一个 TCP 连接，即数据连接，开始数据传送&#x2F;接收（单个文件），直到完成文件传输，关闭该连接。如果期间再次发起文件传输请求，则再建立新的数据连接，即数据连接可能有多条，但每条只负责一个文件的传输。\n\n不同的连接状态可见，控制连接贯穿整个用户会话期间，而每次文件传输都需要建立新的数据连接，并在完成文件传输后关闭，即数据连接的生命周期和文件相关联。FTP 必须在整个会话期间保留 Client 的状态：当前目录位置等信息。\n命令和回答FTP 的命令和应答是人可读的，由 7 bit ASCII 格式在控制连接上传送。\n命令由 4 个大写字母组成，可能有可选参数，常见的有：\n\nUSER username：向服务器传送用户标识；\nPASS password：向服务器传送用户口令；\nLIST：用于请求服务器回送当前远程目录中的所有文件列表。该文件列表经一个（新建的）数据连接传输，而不是在控制连接上传输；\nRETR filename：用于从远程主机的当前目录获取（get）文件。该命令引起远程主机发起一个数据连接，并经该连接发送所请求的文件；\nSTOR filename：用于在远程主机的当前目录上存放（put）文件。由用户发起一个数据连接并发送文件。\n\n回答命令和回答一一对应。回答是 3 位数字后跟可选信息，这与 HTTP 响应报文段状态行的状态吗和状态信息的结构相同，常见的有：\n\n331 Username OK，Password required；\n125：Data connection already open，transfer starting；\n425：Can’t open data connection（无法打开数据连接）；\n452：Error writing file（写文件错误）。\n\nDNS因特网目录服务。提供主机名到 IP 地址的转换。\nSMTPSimple Mail Transfer Protocol，简单邮件传输协议。典型的电子邮件服务流程：\n\n用户与用户代理打交道，可能有多个用户代理可供选择。用 TCP 进行的邮件交换由报文传送代理 MTA（Message Transfer Agent）完成。两个 MTA 之间用 NVT ASCII 进行通信。客户向服务器发出命令，服务器用数字应答码和可选的人可读字符串进行响应（和 FTP 类似）。\n远程登陆协议远程登录（Remote Login）是 Internet 上最广泛的应用之一。TCP&#x2F;IP 网络上提供两种远程登陆方式：TELNET、Rlogin。\nTELNET 协议telecommunication network protocol，电信网络协议的缩写（比较老的一种协议，现在的含义有所改变）。\n\n\nRlogin 协议应用层设备OSI 七层模型中，对应的应用层、表示层和会话层在 TCP&#x2F;IP 五层结构中统归于应用层，这里的设备有软件。\n","categories":["CN"],"tags":["CN"]},{"title":"常见问题-CN","url":"/2018/04/17/QA/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98-CN/","content":"网络层单播 多播 广播 任播单播 Unicast网络中两个节点之间的通信，信息的接收和传递终点只涉及两个节点。单播在网络中应用广泛，网络上绝大部分的数据都是以单播的形式传输的。例如，收发电子邮件、浏览网页时，必须与邮件服务器、Web 服务器建立连接，此时使用的就是单播数据传输方式。但是通常使用“点对点通信”（Point to Point，P2P）代替“单播”，因为“单播”一般与“多播”和“广播”相对应使用。\n多播&#x2F;组播 Multicast网上视频会议、视频点播特别适合采用多播方式。如果采用单播方式，逐个节点传输，那么有多少个目标节点，就会有多少次传送过程，这种方式显然效率极低且流量负载很高，是不可取的；如果采用不区分目标、全部发送的广播方式，虽然一次可以传送完数据，但是显然达不到区分特定数据接收对象的目的。采用多播方式，既可以实现一次传送所有目标节点的数据，也可以达到只对特定对象传送数据的目的。 　　组播同时具备单播和广播的优点，非常具有发展前景。IP 网络的多播一般通过多播 IP 地址来实现。多播 IP 地址就是 D 类 IP 地址，即 224.0.0.0 至 239.255.255.255 之间的 IP 地址。\n广播 Broadcast广播在网络中的应用较多，如客户机通过 DHCP 自动获取 IP 地址的过程就是通过广播来实现的。但是同单播和多播相比，广播几乎占用了子网内网络的所有带宽。集线器由于其工作原理决定了不可能过滤广播风暴，一般的交换机也没有这一功能，不过现在有的网络交换机（如全向的QS系列交换机）也有过滤广播风暴功能了，路由器本身就有隔离广播风暴的作用。　IP 网络中，广播地址用 IP 地址 255.255.255.255 来表示，这个 IP 地址代表同一子网内所有的 IP 地址。\n单播、多播和广播的区别\n多路复用多路复用（Multiplexing，又称“多工”）是计算机网络概念。表示在一个信道上传输多路信号或数据流的过程和技术。因为多路复用能够将多个低速信道整合到一个高速信道进行传输，从而有效地利用了高速信道。通过使用多路复用，通信运营商可以避免维护多条线路，从而有效地节约运营成本。\n","categories":["CN"],"tags":["CN","Q&A"]},{"title":"运行时数据区域","url":"/2018/04/16/java/JVM/%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA%E5%9F%9F/","content":"JVM 是基于栈的。JVM 运行 java 程序过程中会把其管理的内存划分为若干不同用途的数据区域：它们的创建&#x2F;销毁时间不尽相同，有的区域随 JVM 的启动而存在，有的则依赖于用户线程的启动&#x2F;结束而建立&#x2F;销毁。jvms 规定了以下运行时数据区域：\n\n\nPC（Program Counter Register）程序计数器。较小的一块内存空间，可以看作当前线程锁执行的字节码的行号指示器。JVM 概念模型里，字节码解释器工作时就是通过改变 PC 值来选取下一条需要执行的字节码指令。每个线程都需要独立的 PC，即这类内存区域为“线程私有”的。PC 是唯一一个在 jvms 中没有规定任何 OutOfMemoryError 情况的区域。\nJava 虚拟机栈（Java VM Stacks）也是线程私有的，其生命周期和线程相同。虚拟机栈描述的是 java 方法执行的内存模型：每个方法在执行的同时都会创建一个 栈帧（Stack Frame），用于存储 局部变量表、操作数栈、动态链接、方法出口 等信息。每个方法从调用直到执行完成的过程，就对应着一个栈帧在虚拟机栈中入栈到出栈的过程。栈帧方法运行时的基础数据结构，可以理解为一个方法的运行空间。由两部分组成：\n\n局部变量表 存放了编译器可知的各种基本数据类型（boolean、byte、char、short、int、float、long、double）、方法参数、对象引用（reference 类型，它不等同于对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向一个代表对象的句柄或其他于此对象相关的位置）和 returnAddress 类型（指向了一条字节码指令的地址）。其中，64 bit 长度的 long 和 double 会占用 2 个局部变量空间（Slot），其余类型占用 1 个。所以，局部变量表所需内存空间在编译期间就能完成分配。当进入一个方法时，这个方法需要在帧中分配多大的局部变量空间是完全确定的，方法运行期间不会改变局部变量表的大小。\n操作数栈 存放操作数。java 程序编译后的字节码指令的操作数都存放在这里。当执行某条带 n 个操作数的指令时，就从栈顶取出 n 个操作数，把指令计算结果（如果有）再入栈。一般所谓的“JVM 执行引擎是基于栈”的时候，指的就是操作数栈。\n\njvms 规定了该区域的两种异常：\n\n如果线程请求的栈深度大于 VM 所允许的深度，将抛出 StackOverflowError 异常；\n如果虚拟机栈可以动态扩展（当前大部分 jvm 都支持，但 jvms 也允许固定长度），而在扩展时无法申请到足够的内存，将抛出 OutOfMemoryError 异常。\n\n本地方法栈（Native Method Stacks）与虚拟机栈作用相似，区别在于虚拟机栈为 VM 执行 java 方法（即字节码）服务，而本地方法栈为 VM 使用到的 Native 方法服务。jvms 没有对本地方法栈中方法使用的语言、使用方式、数据结构作任何强制规定，所以具体的 VM 可以自由实现它（如，Sun HotSpot 就直接把本地方法栈和虚拟机栈合二为一）。异常情况也同虚拟机栈。\n以上 3 个数据区域随线程创建而创建，随线程终结而终结。\nJava 堆（Java Heap）JVM 所管理的内存中最大的一块。被所有线程共享，在 VM 启动时创建。Java 堆的唯一目的就是存放 对象实例，几乎所有的对象都在这里分配内存。jvms 描述是：所有的对象实例以及数组都要在堆上分配（The heap is the run-time data area from which memory for all class instances &amp; arrays is allocated）。但随着 JIT 编译器的发展与逃逸分析技术逐渐成熟，栈上分配、标量替换优化技术将会导致一些微妙的变化，这个规范也就显得渐渐不那么“绝对”了。Java 堆是垃圾收集器管理（GC）的主要区域，因此也称为 GC 堆，Garbage Collected Heap。从不同角度出发，java 堆又可以做进一步的细分：\n\n从内存分配角度看，线程共享的 java 堆中可能划分出多个 线程私有的分配缓冲区（Thread Local Allocation Buffer， TLAB）；\n从内存回收角度看，由于现在的收集器基本都采用分代收集算法，所以 java 堆还可以划分为：新生代、老年代。再细致一点的还有： Eden 空间、From Survivor 空间、To Survivor 空间等。\n\n无论如何划分，java 堆存储的都仍然是对象实例。jvms 规定 java 堆可以处于物理上不连续的内存空间，只要逻辑上是连续的即可；既可以是固定大小的，也可以是可扩展的。当前主流 VM 都是按照可扩展来实现的（通过 -Xmx 和 -Xms）。如果在堆中没有足够内存以完成实例分配，并且堆大小也无法再扩展时，将抛出 OutOfMemoryError 异常。\n方法区（Method Area）与 java 堆一样，是被所有线程共享的内存区域，在 VM 启动时创建。用于存储已被 VM 加载的 类信息、常量、静态变量、即时编译器编译后的代码等数据。虽然 jvms 将方法区描述为堆的一部分，但其别名叫做 Non-Heap（非堆），以示区别，没有对具体实现作约束。JDK 1.8 之前，HotSpot 将方法区实现为永久代，1.8 之后取消永久代，替代的是 Metaspace，永久代中的 class metadata 转移到 native memory（本地内存）中，interned Strings 和 class static variables 转移到 java heap 中，永久代参数（PermSize MaxPermSize）替换为元空间参数（MetaspaceSize，MaxMetaspaceSize）。而其他 VM 如 BEA JRockit、IBM J9 等，本就没有永久代的概念。jvms 对方法区的描述比较宽松，同样不需要连续的物理内存，可固定大小，也可扩展，还可以选择不实现垃圾收集（相对而言，垃圾收集行为较少发生在方法区中）。当方法区无法满足内存分配需求时，将抛出 OutOfMemoryError 异常。\n运行时常量池（Runtime Constant Pool）Class 文件中除了类版本、字段、方法、接口等描述信息，还有一项信息是 常量池（Constant Pool Table），用于存放编译期生成的各种字面量和符号引用，这部分内容将在类加载后进入方法区的运行时常量池中存放。其中符号引用（Symbolic Reference）属于编译原理概念，包含三类常量：\n\n类和接口的全限定名（Full Qualified Name）；\n字段的名称和描述符（Descriptor）；\n方法的名称和描述符。\n\n运行时常量池相对于 Class 文件常量池的一个重要特征是具备动态性。即，java 语言并不要求常量一定在编译期间才能产生，运行期间也可能将新的常量放入其中。而 Class 文件对每一部分（包括常量池）的格式都有严格规定，每个字节用于存储哪种数据都必须符合规范。作为方法区的一部分，当运行时常量池无法再申请到内存时将抛出 OutOfMemoryError 异常。\n运行时常量池位置变化这个问题牵扯较多，如果不清晰，可能会遇到一些难以理解的运行错误，如典型的 String 的 intern()方法。首先明确一点，从上述可知，方法区逻辑上属于 java 堆，只不过涉及到 GC 等问题时，可以进行细化操作。而具体的运行时常量池位置则跟 JDK 版本和相应虚拟机（这里指内置的 HotSpot）有关。\n\nJDK1.6 及以前：HotSpot 将 GC 分代收集扩展到了方法区，主要回收目标是针对常量池和对类型的卸载，并使用永久代（PermGen）概念实现了方法区（这也是人们常称方法区为永久代的原因，但二者并不相同，观察的角度也不同：前者是 jvms 规范内存的逻辑划分，后者是 jvm 针对规范的具体实现），所以运行时常量池处在永久代中。此时 OOM 错误显示为 PermGen space 。\nJDK1.7：移到了 java 堆中。字符串常量池也在该版本移到 java 堆。也是从这个版本开始，也许是 Oracle 为了兼容收购来的 JRockit（没有永久代的概念） 和原本的 HotSpot，决定逐步移除 HotSpot 中的永久代。此时 OOM 错误显示为 Java heap space。__\nJDK1.8：彻底移除整个永久代，取而代之的是一个独立空间——metaspace（元空间），它独立于 java 堆，使用本地内存，所以不再有 OOM 错误，理论上大小只受到物理内存的限制。\n\n相关概念\n常量池表（Constant Pool Table)：class 文件中存储所有常量（包括字符串）的表，这是 class 文件中的内容，其实就是其中的一部分字节码指令，跟“pool”、运行时概念不相关；\n\n运行时常量池（Runtime Constant Pool）：运行时的内容。大部分内容是随着 JVM 的运行，从常量池转化而来，每个 class 对应一个运行时常量池；\n\n字符串常量池（String Pool）：与运行时常量池不是一个概念，字符串常量池是 JVM 实例全局共享的，即，全局只有一个。jvms 规定进入这里的 String 实例叫做“被驻留的 interned string”，HotSpot 使用哈希表 String Table 来引用堆中的字符串实例，被引用就是被驻留。\n\nMetaspace（元空间）：JDK8 HotSpot 使用本地内存来存储类的元数据信息，这块内存就是元空间。本质上，还是对应于 jvms 里的方法区，只不过实现上不再使用 java 堆的一部分（之前版本的方法区实现，也就是永久代，逻辑上属于 java 堆的一部分），而是直接使用本地内存，这意味着不再出现 OOM 错误。\n\n\n直接内存（Direct Memory）并非 VM 运行时数据区的一部分，也不是 jvms 中定义的内存区域。JDK 1.4 新加入了 NIO（New Input&#x2F;Output）类，引入了一种基于通道（Channel）与缓冲区（Buffer）的 I&#x2F;O 方式，它可以使用 Native 函数库直接分配堆外内存，然后通过一个存储在 java 堆中的 DirectByteBuffer 对象作为这块内存的引用进行进行操作。这样能在一些场景中显著提高性能，因为 避免在 java 堆 和 Native 堆中来回复制数据。本机直接内存的分配不受 java 堆大小的限制，只跟本机物理内存等有关。但如果配置不当，也会造成动态扩展时物理内存已耗尽而抛出 OutOfMemoryError 异常。\n管理可见，直接内存的管理工作并不完全依赖于 JVM。直接内存区域可以进行自动内存管理(GC)，但机制并不完善。\nJDK 1.8 中 HotSpot 内存模型\n\nhttp://www.cnblogs.com/xrq730/p/4827590.html\n","categories":["java"],"tags":["java","JVM"]},{"title":"Linux-常用命令","url":"/2018/04/15/Linux/Linux-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","content":"查看内存使用情况\n\nfree 命令：man 解释：Display amount of free and used memory in the system。free -m：显示内存情况：已用、未用、总量等信息。ps：free 命令读取的信息就来源于 &#x2F;proc&#x2F;meminfo。其中的 buffers 列为块设备 inode 管理的所有 page cache 数量；cached 为内核总缓存-buffers-交换缓存总和。\n&#x2F;proc&#x2F;meminfocat &#x2F;proc&#x2F;meminfo：显示内存的详细情况，包括以上信息。\ntoptop [-u 用户名]：当前用户进程占用资源情况，包括 进程所有者、NI（nice值）、CPU、内存、S（进程状态：S：休眠，R：正在运行，Z：僵死，N：进程优先级为负）等信息。默认以 CPU 使用率排序，输入大写 M 可以切换成以内存使用率排序，大写 P 以 CPU 占用率排序。\npmap 命令：man 解释：report memory map of a process。pmap -d 进程号：根据进程查看该进程相关信息占用的内存情况。\n\n查看电池状态upower -i upower -e | grep &#39;BAT&#39;\n","categories":[],"tags":["Linux","Shell"]},{"title":"Linux-常用配置","url":"/2018/04/15/Linux/Linux-%E5%B8%B8%E7%94%A8%E9%85%8D%E7%BD%AE/","content":"设置服务开机自启动基础知识：系统启动过程中，内核被加载后，执行的第一个程序是 &#x2F;sbin&#x2F;init，init 程序会读取 inittab 文件的内容，从而确定系统的运行级（0-6，即 rc0.d - rc6.d。ps：rc 一般指：run command）。确定运行级后执行 &#x2F;etc&#x2F;rc.d&#x2F;rc.sysinit，对系统进行一些初始化。之后启动内核模块，启动内核模块之后执行相应的运行级文件（rc0.d - rc6.d），然后执行 &#x2F;etc&#x2F;rc.d&#x2F;rc.local，最后执行 &#x2F;bin&#x2F;login 进入登陆状态。从上述内容可知，在系统启动过程中有两种任务启动方法：\n\n将启动脚本放在 &#x2F;etc&#x2F;rc.d&#x2F;init.d 文件中，并建立到 rc0.d - rc6.d 的链接。init.d 中存放着一些系统启动时要运行的服务的脚本，但并不是每个脚本都会被执行。Linux 把 init.d 中的服务链接到运行级 rc0.d - rc.6.d 中，在确定系统的运行机制后执行相应运行级的 rc?.d。这是推荐使用的配置方式。\n将启动脚本放在 &#x2F;etc&#x2F;rc&#x2F;local 中，这是在其他的初始化脚本执行完后才执行的，用户可以在此进行个性化操作，配置需要启动的服务等。\n\n而在用户成功登陆后，也可以进行自启动任务的配置。分别在相关的文件中：3. &#x2F;etc&#x2F;profile：全局环境设置，对系统中每个用户都有效。每个用户登陆后都会立即执行该脚本，因此，任何用户登陆后都需要执行的任务就放在这里。4. &#x2F;etc&#x2F;.bashrc：对所有用户有效，每次打开 shell 时会执行该脚本，保存的是系统 bash shell 的信息。5. ~&#x2F;.bash_profile：当前用户有效，登陆后执行该脚本。6. ~&#x2F;.bashrc：当前用户有效，每次打开 shell 时执行该脚本。\n&#x2F;etc&#x2F;profile 和 ~&#x2F;.bash_profile，&#x2F;etc&#x2F;bashrc 和 ~&#x2F;.bashrc 的区别可以理解成全局变量（影响所有用户）和局部变量（影响当前用户）。而 *profile 和 *bashrc 的区别是，前者时交互式、login 方式进入 bash 运行的，后者是非交互式 non-login 方式进入 bash 运行的。交互模式：shell 等待用户输入，并且执行提交的命令。即：登陆、执行命令、退出。非交互模式：shell 不与用户进行交互，而是读取存放在文件中的命令并执行，当执行到文件结尾，shell 也就终止了。\n定时任务参考链接：Linux 下添加定时任务周期执行的任务一般由守护进程 cron 来处理。它读取一个&#x2F;多个配置文件，文件中包含了命令行及其调用时间。配置文件名为 crontab（cron table 的缩写）。cron 在3个地方查找配置文件：\n\n&#x2F;var&#x2F;spool&#x2F;cron：包括 root 的所有用户的 crontab 任务，以创建者的名字命名，比如 neil 创建的 crontab 对应的就是 &#x2F;var&#x2F;spool&#x2F;cron&#x2F;neil。一般一个用户最多只有一个 crontab 文件。\n&#x2F;etc&#x2F;crontab：负责安排由系统管理员制定的维护系统以及其他任务的 crontab。\n&#x2F;etc&#x2F;cron.d：存放任何要执行的 crontab 文件&#x2F;脚本。\n\n权限：管理在 &#x2F;var&#x2F;adm&#x2F;cron 下，文件 cron.allow 和 cron.deny 用法：\n\n如果两个文件都不存在，则只有 root 才能使用 crontab 命令。\n如果 cron.allow 存在而 cron.deny 不存在，则只有列在 cron.allow 中的用户才能使用 crontab 命令，如果 root 用户不在里面，则 root 用户也不能使用。\n如果 cron.allow 不存在而 cron.deny 存在，则只有列在 cron.deny 中的用户不能使用 crontab 命令，其他用户均可用。\n如果两个文件都存在，则列在 cron.allow 中的可以使用 crontab 命令，列在 crontab.deny 的不能使用，如果某用户同时出现在两个文件中，以 cron.allow 为准，可以使用。\n\ncrontab 文件：七个域：minute  hour  day-of-month  month  day-of-week  user  commands合法值：00-59    00-23    01-31          01-12   0-6                 neil   脚本命令特殊值：“*”：代表所有取值范围内的数字，”&#x2F;“：代表“每”的意思（“&#x2F;5”表示每5个单位），”-“：代表范围，从某个数字到某个数字，”,”：分开几个离散的数字。cron 一词来源于希腊语的 “chronos”，意为时间，用来管理现行时间顺序。\n查看系统信息cat &#x2F;etc&#x2F;issue　　查看发行版本号cat &#x2F;etc&#x2F;lsb_release　 内核版本等lsb_release -a　　详细的系统信息(lsb：Linux Standard Base)uname -r　　查看内核版本号uname -a      详细信息cat &#x2F;proc&#x2F;version      内核版本、编译内核的 gcc 版本、编译时间、编译者的用户名等dmesg | grep “Linux”：打印内核信息（gmesg：display message or driver message）\n","categories":[],"tags":["Linux","Shell"]},{"title":"java-线程","url":"/2018/04/14/java/Thread/java-%E7%BA%BF%E7%A8%8B/","content":"[toc]\nCPU 调度单位大多数现代 OS 中，都是以线程为基本的调度单位，而不是进程。在并发编程中，需要处理两个关键问题：线程之间的通信和同步。线程间通信主要通过 共享内存和消息传递 两种方式，而 java 的并发采用的是共享内存模型，线程间的通信是隐式进行的，对程序员透明。在共享内存并发模型里，同步是显式进行的，即必须显式指定某个方法&#x2F;代码段需要在线程之间互斥执行；而在消息传递并发模型里，由于消息的发送必须在消息的接受之前，因此同步是隐式进行的。线程允许在同一个进程中同时存在多个程序控制流。共享进程范围内的一些资源：堆资源、内存句柄、文件句柄等；但线程拥有自己的程序计数器（PC）、栈、局部变量等。\n两级调度模型HotSpot 采用 一对一映射模型，即每一个 java 线程都唯一映射到一条本地操作系统内核线程。在上层，进程使用用户级的调度器（Executor 框架）将任务映射到线程；在底层，OS 内核将这些线程映射到硬件处理器（CPU 核）上：\n","categories":["java"],"tags":["java","线程","并发"]},{"title":"java-线程安全实现","url":"/2018/04/14/java/Thread/%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8/","content":"[toc]\n线程安全造成线程不安全的原因是多个线程对临界区资源的冲突访问（多线程只读是没有问题的，而一旦涉及到写，那么读写都将变得不可预知）。所以，从这个角度讲，保证线程安全的措施有：\n\n同步&#x2F;锁；\n消除对变量的共享（ThreadLocal）。\n\nJVM 机制在 JVM 中，每个对象和类在逻辑上都是和一个监视器相关联的。对于对象来说，相关联的监视器保护对象的实例变量。对于类来说，监视器保护类的类变量。（如果一个对象没有实例变量，或者一个类没有变量，相关联的监视器就什么也不监视）。为了实现监视器的排他性监视能力，JVM 为每一个对象和类都关联一个锁。代表任何时候只允许一个线程拥有的特权。线程访问实例变量或者类变量不需锁。但是如果线程获取了锁，那么在它释放这个锁之前，就没有其他线程可以获取同样数据的锁了。（锁住一个对象就是获取对象相关联的监视器）。类锁实际上用对象锁来实现。当虚拟机装载一个 class 文件的时候，它就会创建一个 java.lang.Class 类的实例。当锁住一个对象的时候，实际上锁住的是那个类的 Class 对象。一个线程可以多次对同一个对象上锁。对于每一个对象，JVM 维护一个加锁计数器，线程每获得一次该对象，计数器就加1，每释放一次，计数器就减 1，当计数器值为0时，锁就被完全释放了。java 编程人员不需要自己动手加锁，对象锁是 JVM 内部使用的。在 java 程序中，只需要使用 synchronized 块或者 synchronized 方法就可以标志一个监视区域。当每次进入一个监视区域时，JVM 都会自动锁上对象或者类。\n线程安全的实现方式有以下几种：\n\n不使用单例模式，而是使用多实例；\n使用锁机制：synchronized、lock 等；\n使用 JUC 类库。\n\n无同步方案要保证线程安全，并不是一定就要进行同步，两者没有因果关系。同步只是保证共享数据争用时的正确性的手段，如果一个方法本来就不涉及共享数据，那它自然就无须任何同步措施去保证正确性，因此会有一些代码天生就是线程安全的，笔者简单地介绍其中的两类。可重入代码（Reentrant Code）：这种代码也叫做纯代码（Pure Code），可以在代码执行的任何时刻中断它，转而去执行另外一段代码（包括递归调用它本身），而在控制权返回后，原来的程序不会出现任何错误。相对线程安全来说，可重入性是更基本的特性，它可以保证线程安全，即所有的可重入的代码都是线程安全的，但是并非所有的线程安全的代码都是可重入的。可重入代码有一些共同的特征，例如不依赖存储在堆上的数据和公用的系统资源、用到的状态量都由参数中传入、不调用非可重入的方法等。我们可以通过一个简单的原则来判断代码是否具备可重入性：如果一个方法，它的返回结果是可以预测的，只要输入了相同的数据，就都能返回相同的结果，那它就满足可重入性的要求，当然也就是线程安全的。线程本地存储（Thread Local Storage）：如果一段代码中所需要的数据必须与其他代码共享，那就看看这些共享数据的代码是否能保证在同一个线程中执行？如果能保证，我们就可以把共享数据的可见范围限制在同一个线程之内，这样，无须同步也能保证线程之间不出现数据争用的问题。符合这种特点的应用并不少见，大部分使用消费队列的架构模式（如“生产者-消费者”模式）都会将产品的消费过程尽量在一个线程中消费完，其中最重要的一个应用实例就是经典Web交互模型中的“一个请求对应一个服务器线程”（Thread-per-Request）的处理方式，这种处理方式的广泛应用使得很多Web服务端应用都可以使用线程本地存储来解决线程安全问题。Java语言中，如果一个变量要被多线程访问，可以使用volatile关键字声明它为“易变的”；如果一个变量要被某个线程独享，Java中就没有类似C++中__declspec（thread）[3]这样的关键字，不过还是可以通过java.lang.ThreadLocal类来实现线程本地存储的功能。每一个线程的Thread对象中都有一个ThreadLocalMap对象，这个对象存储了一组以ThreadLocal.threadLocalHashCode为键，以本地线程变量为值的K-V值对，ThreadLocal对象就是当前线程的ThreadLocalMap的访问入口，每一个ThreadLocal对象都包含了一个独一无二的threadLocalHashCode值，使用这个值就可以在线程K-V值对中找回对应的本地线程变量。\n锁多线程并发中，共享数据、保证数据一致性的工具。\n隐式锁 synchronizedjava-Synchronized\n显式锁 Lock 和 ReentrantLock加锁和解锁都是显式实现的。\nsynchronized vs lockjava 的两种锁机制。在竞争条件下 ReentrantLock 的实现要比 synchronized 的实现更具有伸缩性。JDK1.6 之前，多线程环境下 synchronized 的吞吐量下降得非常严重，而 ReentrantLock 则能基本保持在同一个比较稳定的水平上。与其说 ReentrantLock 性能好，还不如说 synchronized 还有非常大的优化余地。后续的技术发展也证明了这一点，JDK1.6 对 synchronized 优化措施效果明显，synchronized 与 ReentrantLock 的性能基本上是完全持平了。因此，性能因素不再是选择 ReentrantLock 的理由，虚拟机在未来的性能改进中肯定也会更加偏向于原生的 synchronized，所以还是提倡在 synchronized 能实现需求的情况下，优先考虑使用 synchronized 来进行同步。\n用法上synchronized：使用在需要同步的对象中，可以用在方法级别上，也可以加在特定代码块中，括号中表示需要锁的对象；lock：需要显示指定起始和终止位置。一般就是使用 ReentrantLock 类作为锁，多个线程中必须要使用一个 ReentrantLoc 类作为对象才能保证锁的生效。而且在加锁和解锁处需要通过 lock() 和 unlock() 显式指出。所以一般要在 finally 块中写 unlock() 以防死锁。此外，ReentrantLoc 类提供了 2 种 竞争锁机制：公平锁和非公平锁。一般而言，非公平锁效率更高：公平锁需要维护线程队列顺序。\n性能上synchronized 是托管给 JVM 执行的，而 lock 是 java 写的控制锁的代码。synchronized 采用的是 CPU 悲观锁机制，即线程获得的是独占锁；而 lock 采用的是乐观锁机制，其实现就是 CAS。研究 ReentrantLock 源码可以发现，其中一个比较重要的获得锁的方法是 compareAndsetState()，这里就是调用的 CPU 提供的特殊指令支持。\n用途上一般情况下，两者没有显著区别。而在特殊的复杂并发同步问题中，如以下情况，则更适合 ReentrantLock：\n\n某个线程在等待一个锁的控制权期间，需要中断；\n需要分开处理一些 wait-notify，ReentrantLoc 里的 Condition 应用，能够控制 notify 特定线程；\n具有公平锁功能，每个到来的线程都将排队等待。\n\n如何选择JDK1.6 加入了对 synchronized 关键字的很多改进，使得两者在性能上差距已经不是很明显，加上后续的不断改进以及官方默认更倾向于鼓励用户使用它的态度，如果非要在二者之间选择，应该首选 synchronized。其能够提供更简洁的实现，这成了性能之外的另一优势，而且相比于需要显式管理的 Lock，显然出错的概率更小；然而，在解决特定问题，尤其是 synchronized 解决不了或者不易实现的情况下，如，尝试在一定时间&#x2F;次数获取锁，如果不能获得则放弃，此时就要使用 juc 类库中的方法，包括 Lock。此外：\n\n最好两个都不用，而是使用 JUC（java.util.concurrent）包提供的机制，能够帮助用户处理所有与锁相关的代码；\n如果 synchronized 关键字能满足用户的需求，就用 synchronized，因为它能简化代码；\n如果需要更高级的功能，就用 ReentrantLock 类，此时要注意及时释放锁，否则会出现死锁，通常在 finally 代码释放锁。\n\n自旋锁&#x2F;可重入锁不仅仅在 java 语义下。\n自旋锁让当前线程不停地在循环体内执行（空循环），当循环条件被其他线程改变时（比如等待的锁被释放并收到通知）才能进入临界区。由于线程没有改变状态如阻塞挂起等，而是继续空循环以便快速响应，这将导致：当线程数量不断增加时，整体性能明显下降，因为每个线程都处于自旋状态，会白白浪费 CPU 时间等资源。所以适用于线程竞争不太激烈并且线程保持锁的时间相对较短的场景。此外，自旋锁有可能导致 死锁：当一个线程内两次调用请求某个锁时，第二次请求将在自旋上陷入死锁。\n可重入锁也称递归锁，指同一线程中，外层方法&#x2F;函数获得锁之后，内层方法&#x2F;函数即使仍然有获取该锁的操作，也无需再次申请锁（如果需要申请，此时也是不被允许的），而是直接可以进入该锁所同步着的代码块。可重入锁最大的作用是 避免死锁：可避免上述自旋锁的死锁情况发生。但所有基于锁的实现都无可避免地可能产生死锁。可重入锁会在由于某些原因导致锁没有被正确释放（无论隐式锁还是显式锁，在遇到一些特殊情况会导致锁无法正常被释放）而导致死锁发生。\n锁与无锁基于锁的并发优点：1、编程模型简单，如果小心控制上锁顺序，一般来说不会有死锁的问题；2、可以通过调节锁的粒度来调节性能。缺点：1、所有基于锁的算法都有死锁的可能；2、上锁和解锁时进程要从用户态切换到内核态，并可能伴随有线程的调度、上下文切换等，开销比较重；3、对共享数据的读与写之间会有互斥。\n无锁编程（lock free）常见的 lock free 编程一般是基于CAS(Compare And Swap)操作：CAS(void ptr, Any oldValue, Any newValue);即查看内存地址ptr处的值，如果为oldValue则将其改为newValue，并返回true，否则返回false。X86平台上的CAS操作一般是通过CPU的CMPXCHG指令来完成的。CPU在执行此指令时会首先锁住CPU总线，禁止其它核心对内存的访问，然后再查看或修改ptr的值。简单的说CAS利用了CPU的硬件锁来实现对共享资源的串行使用。优点：1、开销较小：不需要进入内核，不需要切换线程；2、没有死锁：总线锁最长持续为一次read+write的时间；3、只有写操作需要使用CAS，读操作与串行代码完全相同，可实现读写不互斥。缺点：1、编程非常复杂，两行代码之间可能发生任何事，很多常识性的假设都不成立。2、CAS模型覆盖的情况非常少，无法用CAS实现原子的复数操作。\n对比在性能层面上，CAS与mutex&#x2F;readwrite lock各有千秋，简述如下：1、单线程下CAS的开销大约为10次加法操作，mutex的上锁+解锁大约为20次加法操作，而readwrite lock的开销则更大一些。2、CAS的性能为固定值，而mutex则可以通过改变临界区的大小来调节性能；3、如果临界区中真正的修改操作只占一小部分，那么用CAS可以获得更大的并发度。4、多核CPU中线程调度成本较高，此时更适合用CAS。跳表和红黑树的性能相当，最主要的优势就是当调整(插入或删除)时，红黑树需要使用旋转来维护平衡性，这个操作需要动多个节点，在并发时候很难控制。而跳表插入或删除时只需定位后插入，插入时只需添加插入的那个节点及其多个层的复制，以及定位和插入的原子性维护。所以它更加可以利用CAS操作来进行无锁编程。\n阻塞&#x2F;非阻塞同步阻塞同步悲观并发策略。可以让线程进入阻塞状态进行等待，当获得相应的信号（唤醒，时间） 时，才可以进入线程的准备就绪状态，准备就绪状态的所有线程，通过竞争，进入运行状态。阻塞同步最大的问题还是在于线程状态转换导致的性能问题。java 中，能够进入&#x2F;退出 阻塞状态或包含阻塞锁的方法有 synchronized 关键字（其中的重量锁）、ReentrantLock、Object.wait()&#x2F;notify()、LockSupport.park()&#x2F;unpart()（JUC 经常使用)。\n非阻塞同步基于冲突检测的乐观并发策略，需要硬件支持（如 CAS）。通俗讲，就是先进行操作，如果没有其他线程争用共享数据，那么操作成功；如果共享数据有争用，产生了冲突，那就再采取其他的补偿措施（最常见的补偿措施就是不断地重试，直到成功为止），这种乐观的并发策略的许多实现都不需要把线程挂起，因此这种同步操作称为非阻塞同步（Non-Blocking Synchronization）。\n","categories":["java"],"tags":["java","线程","并发"]},{"title":"存储设备","url":"/2018/04/12/CS/%E5%AD%98%E5%82%A8%E8%AE%BE%E5%A4%87/","content":"这里的 CS 指 Computer System。硬件结构相关的扫盲贴。\n计算机的5大组成部分为：输入、输出、存储器、数据通路（运算器）、控制器。后两者合称处理器，即简单来说，计算机组成主要包括：I&#x2F;O 设备，存储设备，CPU。\n\n\n这篇主要关于存储设备。\n局部性原理（比如在图书馆查阅某一类书籍）表明了在任何时间内，程序访问的只是地址空间相对较小的一部分内容：时间局部性（temporal locality）：如果某个数据项被访问，那么在不久的将来它可能再次被访问；空间局部性（spatial locality）：如果某个数据项被访问，与它地址向邻的数据项可能很快也将被访问。\n局部性原理适用于存储器的层次结构。存储器层次结构：一种由多存储器层次组成的结构，存储器的容量和访问时间随着离处理器的距离增加而增加。\n存储器技术目前用于构建存储器层次结构的主要有四中技术：\n\nSRAM（静态随机存取存储器），作为靠近处理器的那层 cache。一种组织成存储阵列结构的简单集成电路，不需要刷新，对任何数据的访问时间都是固定的，并且与周期时间非常接近，只要给它加电，其中的数据就能保持，属于易失去性存储。当今处理器芯片中集成了多层次的 cache（如PC的三级缓存），独立的SRAM几乎没有了。\nDRAM（动态随机存取存储器），作为主存储器。存储单元使用电容保存电荷的方式来存储数据，因此不能长久地保存数据，必须周期性地刷新，这就是：”动态“的由来（相比于SRAM的不需要刷新）。为了进一步优化与处理器的接口，DRAM增加了时钟，因此称之为同步DRAM（SDRAM）。其优势在于使用时钟对存储器和处理器保持同步。其速度上的优势主要源于不需要额外指定地址位，在时钟的控制下以突发方式传送连续数据的能力。最快的版本称为 双数据速率（DDR）  SDRAM。该名称表示在时钟的上升沿和下降沿都传递数据，因此获得双倍的数据带宽。该技术最新版本为 DDR4，一个 DDR4-3200 DRAM 每秒可以传输3200兆次，即其时钟频率为1600MHz。\n闪存（flash），这种非易失存储器主要用于个人移动设备中的非易失二级存储器。一种 电可擦除的可编程只读存取器（EEPROM）。对闪存的写操作会使存储位损耗，因此大多使用控制器用来将写操作从已经写入很多次的块中映射到写入次数较少的块中，从而尽量分散写操作，即损耗均衡（wear leveling）。这种均衡技术也将制造过程中出错的存储单元屏蔽掉，从而提高成品率。\n磁盘（disk），通常是服务器中容量最大且速度最慢的一层。_磁盘简介_：一个磁质硬盘包含一组圆形磁盘片，它们绕着轴心每分钟转动 5 400 - 15 000 周。每个磁盘片的表明划分为同心圆环，称为 磁道（track）。 每个面通常由几万条磁道，即几万个磁道，每条磁道同样被划分为用于存储信息的 扇区（sector），每条磁道有几千个扇区，每个扇区的容量通常是 512 - 4096 字节。扇区是磁道的基本单位，是磁盘上信息数据读写的最小单位。信息的保存顺序为扇区号、一个间隙、包含该扇区纠错码的信息、一个间隙、下一个扇区号。 每层磁盘片的表面有一个包含小的电磁线圈的 读写磁头，访问每个盘面的磁头连在一起相互协调运动，因此磁头全部位于相同的扇区。术语 柱面 用来表示磁头在给定点时访问到所有盘面上的所有扇区的集合。　　为了访问数据，OS 必须对磁盘进行三步操作：\n\n寻道时间：将磁头移动到适当的磁道上，称为 寻道（seek），所需时间即为寻道时间。厂商测量的平均寻道时间通常在 3 - 13 ms，但由于应用程序及磁盘访问调度策略的不同，且磁盘数据具有局部性，实际平均寻道时间通常只有标称数据的 25% - 33%。\n旋转延时（rotational latency）：一旦磁头到达了正确磁道，就必须等待要访问的扇区转动到读写头下面，该等待时间即为旋转延时。平均延时通常是磁盘转动一周时间的一半。5 400 周的磁盘平均旋转延时为：![](http://chart.googleapis.com/chart?cht=tx&amp;chl=Average Rotational Latency&#x3D;\\frac{0.5  rotation}{5400 RPM}&#x3D;5.6 ms)\n传输时间：即传输一块数据需要的时间。该时间是扇区大小、旋转速度和磁道信息密度的一个函数。\n\n\n\n\n磁盘和半导体存储技术的主要差别是前者访问速度慢，因为它们是机械器件——闪存比磁盘快3个数量级，DRAM 比磁盘快5个数量级。与闪存类似，磁盘是非易失的，但却不存在写损耗问题。然而，闪存更加坚固，因此更适合于个人移动设备。\n其他类型的存储介质SSD(Solid State Drives, 固态硬盘) 用固态电子存储芯片阵列组成的硬盘，由控制单元和存储单元（flash 或 DRAM）组成。固盘在接口的规范和定义、功能及使用方法上与普通的磁盘相同，产品外形尺寸上也一致。固盘（的存储单元）使用闪存颗粒制作，读写速度快，内部不存在任何机械部件，防震抗摔；存在闪存擦写次数限制问题，所以寿命短，并且容量不大（目前最大为 4TB）。普遍采用 SATA-2、SATA-3、mSATA、PCIe、M.2等规格接口。使用建议：不要使用碎片整理、小分区&amp;少分区、保留足够剩余空间、及时刷新固件、使用恢复指令（Trim）等。\n","categories":["CS"],"tags":["CS"]},{"title":"存储设备","url":"/2018/04/12/CS/O/%E5%AD%98%E5%82%A8%E8%AE%BE%E5%A4%87/","content":"这里的 CS 指 Computer System。硬件结构相关的扫盲贴。\n计算机的5大组成部分为：输入、输出、存储器、数据通路（运算器）、控制器。后两者合称处理器，即简单来说，计算机组成主要包括：I&#x2F;O 设备，存储设备，CPU。\n\n\n这篇主要关于存储设备。\n局部性原理（比如在图书馆查阅某一类书籍）表明了在任何时间内，程序访问的只是地址空间相对较小的一部分内容：时间局部性（temporal locality）：如果某个数据项被访问，那么在不久的将来它可能再次被访问；空间局部性（spatial locality）：如果某个数据项被访问，与它地址向邻的数据项可能很快也将被访问。\n局部性原理适用于存储器的层次结构。存储器层次结构：一种由多存储器层次组成的结构，存储器的容量和访问时间随着离处理器的距离增加而增加。\n存储器技术目前用于构建存储器层次结构的主要有四中技术：\n\nSRAM（静态随机存取存储器），作为靠近处理器的那层 cache。一种组织成存储阵列结构的简单集成电路，不需要刷新，对任何数据的访问时间都是固定的，并且与周期时间非常接近，只要给它加电，其中的数据就能保持，属于易失去性存储。当今处理器芯片中集成了多层次的 cache（如PC的三级缓存），独立的SRAM几乎没有了。\nDRAM（动态随机存取存储器），作为主存储器。存储单元使用电容保存电荷的方式来存储数据，因此不能长久地保存数据，必须周期性地刷新，这就是：”动态“的由来（相比于SRAM的不需要刷新）。为了进一步优化与处理器的接口，DRAM增加了时钟，因此称之为同步DRAM（SDRAM）。其优势在于使用时钟对存储器和处理器保持同步。其速度上的优势主要源于不需要额外指定地址位，在时钟的控制下以突发方式传送连续数据的能力。最快的版本称为 双数据速率（DDR）  SDRAM。该名称表示在时钟的上升沿和下降沿都传递数据，因此获得双倍的数据带宽。该技术最新版本为 DDR4，一个 DDR4-3200 DRAM 每秒可以传输3200兆次，即其时钟频率为1600MHz。\n闪存（flash），这种非易失存储器主要用于个人移动设备中的非易失二级存储器。一种 电可擦除的可编程只读存取器（EEPROM）。对闪存的写操作会使存储位损耗，因此大多使用控制器用来将写操作从已经写入很多次的块中映射到写入次数较少的块中，从而尽量分散写操作，即损耗均衡（wear leveling）。这种均衡技术也将制造过程中出错的存储单元屏蔽掉，从而提高成品率。\n磁盘（disk），通常是服务器中容量最大且速度最慢的一层。_磁盘简介_：一个磁质硬盘包含一组圆形磁盘片，它们绕着轴心每分钟转动 5 400 - 15 000 周。每个磁盘片的表明划分为同心圆环，称为 磁道（track）。 每个面通常由几万条磁道，即几万个磁道，每条磁道同样被划分为用于存储信息的 扇区（sector），每条磁道有几千个扇区，每个扇区的容量通常是 512 - 4096 字节。扇区是磁道的基本单位，是磁盘上信息数据读写的最小单位。信息的保存顺序为扇区号、一个间隙、包含该扇区纠错码的信息、一个间隙、下一个扇区号。 每层磁盘片的表面有一个包含小的电磁线圈的 读写磁头，访问每个盘面的磁头连在一起相互协调运动，因此磁头全部位于相同的扇区。术语 柱面 用来表示磁头在给定点时访问到所有盘面上的所有扇区的集合。　　为了访问数据，OS 必须对磁盘进行三步操作：\n\n寻道时间：将磁头移动到适当的磁道上，称为 寻道（seek），所需时间即为寻道时间。厂商测量的平均寻道时间通常在 3 - 13 ms，但由于应用程序及磁盘访问调度策略的不同，且磁盘数据具有局部性，实际平均寻道时间通常只有标称数据的 25% - 33%。\n旋转延时（rotational latency）：一旦磁头到达了正确磁道，就必须等待要访问的扇区转动到读写头下面，该等待时间即为旋转延时。平均延时通常是磁盘转动一周时间的一半。5 400 周的磁盘平均旋转延时为：![](http://chart.googleapis.com/chart?cht=tx&amp;chl=Average Rotational Latency&#x3D;\\frac{0.5  rotation}{5400 RPM}&#x3D;5.6 ms)\n传输时间：即传输一块数据需要的时间。该时间是扇区大小、旋转速度和磁道信息密度的一个函数。\n\n\n\n\n磁盘和半导体存储技术的主要差别是前者访问速度慢，因为它们是机械器件——闪存比磁盘快3个数量级，DRAM 比磁盘快5个数量级。与闪存类似，磁盘是非易失的，但却不存在写损耗问题。然而，闪存更加坚固，因此更适合于个人移动设备。\n其他类型的存储介质SSD(Solid State Drives, 固态硬盘) 用固态电子存储芯片阵列组成的硬盘，由控制单元和存储单元（flash 或 DRAM）组成。固盘在接口的规范和定义、功能及使用方法上与普通的磁盘相同，产品外形尺寸上也一致。固盘（的存储单元）使用闪存颗粒制作，读写速度快，内部不存在任何机械部件，防震抗摔；存在闪存擦写次数限制问题，所以寿命短，并且容量不大（目前最大为 4TB）。普遍采用 SATA-2、SATA-3、mSATA、PCIe、M.2等规格接口。使用建议：不要使用碎片整理、小分区&amp;少分区、保留足够剩余空间、及时刷新固件、使用恢复指令（Trim）等。\n","categories":["CS"],"tags":["CS"]},{"title":"内存管理","url":"/2018/04/12/OS/%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/","content":"CPU 所能直接访问的存储器只有内部寄存器和内存。即，如果数据不在内存中，那么在 CPU 使用前必须先把数据移到内存中。而 CPU 和内存的速度差异很大，故在之间增加内存缓存区，即高速缓存（cache）来协调。\n地址绑定源程序中的地址通常是用符号(如 count)来表示的。编译器通常将这些符号地址绑定（binding）到可重定位的地址（如“从本模块开始的第17字节”）。链接程序或加载程序再将这些可重定位的地址绑定成绝对地址（如 0x74014）。每次绑定都是从一个地址空间到另一个地址空间的映射。通常，将指令与数据绑定到内存地址有以下三种情况：\n\n编译时（compile time）：如果在编译时就知道进程将在内存中的驻留地址，那么就可以生成绝对代码（absolute code）；\n加载时（load time）：如果在编译时不知道进程将驻留在内存的什么地方，那么编译器就必须生成可重定位代码（relocatable code）。最后绑定会延迟到加载时才进行。如果开始地址发生变化，只需要重新加载以引入改变值；\n执行时（execution time）：如果进程在执行时可以从一个内存段移到另一个内存段，那么绑定必须延迟到执行时才进行。采用这种方案需要特定的硬件，绝大多数通用计算机 OS 采用这种方法。\n\nCPU 所生成的地址通常称为逻辑地址（logical address），内存单元所看到的地址（即加载到内存地址寄存器（memory-address register）中的地址）通常称为物理地址（physical address）。编译和加载时的地址绑定方法生成相同的逻辑地址和物理地址；但执行时的地址绑定方法导致不同的逻辑地址和物理地址，此时，通常称逻辑地址为虚拟地址（virtual address），二者可以不做区分。由程序所生成的所有逻辑地址的集合称为逻辑地址空间（logical address space），与这些逻辑地址相对应的所有物理地址的集合称为物理地址空间（physical address space）。因此，对于执行时绑定地址方案，逻辑地址空间与物理地址空间是不同的。程序运行时从虚拟地址到物理地址的映射是由硬件 内存管理单元（Memory-Management Unit， MMU） 完成的。内存管理中，逻辑地址空间绑定到单独的一套物理地址空间这一概念至关重要。\n动态加载(dynamic loading)为突破进程大小受物理内存大小的限制，获得更好的内存空间使用，可以使用 动态加载：一个子程序只有在调用时才被加载，所有子程序都以可重定位的形式保存在磁盘上。\n动态链接库（dynamically linked library）有的 OS 只支持 静态链接（static linking），此时系统语言库的处理与其他目标模块一样，由加载程序合并到二进制程序镜像中。动态链接的概念类似于动态加载，但这里不是将加载延迟到运行时，而是将链接延迟到运行时，从而避免系统上每个程序都需要一份语言库的副本（对于需要引用该库的程序而言）。动态链接也可用于库更新（如修改漏洞），一个库可以被新的版本所替代，且所有使用该库的程序都会自动使用新的版本。\n\n内存映射和保护是通过 基地址寄存器（重定位寄存器） 和界限地址寄存器完成的。\n内存分配连续分配：每个内存映射和保护内存映射和保护进程位于一个连续的内存区域。固定大小分区：将内存划分为多个固定大小的分区，每个分区只能容纳一个进程（现已不再使用）；可变分区：OS 用表的形式记录内存中哪些可用和已占用，为新进程分配内存策略有：\n\n首次适应（first-fit）：查找并分配第一个足够大的分区块；\n最佳适应（best-fit）：遍历并分配最小的足够大的分区块；\n最差适应（worst-fit）：遍历并分配最大的分区块。\n\n碎片首次适应和最佳适应都有 外部碎片（external fragmentation）问题：随着进程装入和移出，空闲内存空间被分割成小片段在内存的各处，尽管总的可用内存可以满足新进程，但由于碎片化无法完成分配，即出现外部碎片问题。对应的 内部碎片 是指：通常内存以固定大小的块为单位（如果以字节为单位，管理表的开销可能会很大）来分配，进程所分配的内存可能比所要的大出一些（最后的块产生的剩余），而这个多分配的部分就是内部碎片。一种解决外部碎片的方法是 紧缩（compaction）：移动内存内容，以便所有空闲空间合成一个整块。显然，紧缩策略对重定位发生在动态并在运行时才可使用。该策略开销较大。另一种方法是允许物理地址空间为非连续。一般会合并两种技术，或互补实现之。\n分页内核把物理页作为内存管理的基本单位。允许进程的物理地址空间可以是非连续的。现在的分页支持通过硬件和 OS 配合的方式实现。一方面，把物理内存划分为固定大小的内存块，称为物理页面或者帧（page frame）；另一方面，把虚拟地址空间页划分为同样大小的块，称为虚拟页面（page）。页大小要求是2的整数次幂，由硬件决定，一般在512B-1MB之间。如下图所示，由 CPU 生成的地址分为两部分：页号 p 和页偏移 d。页号作为页表中的索引，页表包含每页所在物理内存的基地址，该基地址和页偏移的组合就形成物理地址，即可送交物理单元。\n\n分页技术不会产生外部碎片：每个物理页都可以分配给需要它的进程。但依然会产生内部碎片（看一下页面大小就知道了）。同时，由于页表记录项的开销会随着页的增大而降低（页面变大则总页数减少），所以要均衡页表开销和内部碎片，选取合适的页大小。有的 CPU 甚至支持多种页大小。但对快速可变的页大小的支持是一项具有挑战性的开发工作。而今页表通常非常大（百&#x2F;万量级），寻址页表项（页表装在内存中）会产生延迟，使用一种小而专用且快速的硬件缓冲——转换表缓冲区（Translation Look-aside Buffer， TLB） 解决。目前采用较多的是多级分页（如两级分页），就是将页表再分页。如下图：\n\n\n分段（Segmentation）从开发者视角看待程序：由主程序加上一组方法、过程、函数，还有各种数据结构：对象、数组、堆栈、变量等等。每个模块或其他元素都可以通过名称引用。我们关心“堆栈”、“主程序”，而不关心这些元素所在内存的位置，不关心栈是放在函数前还是后……分段就是支持这种用户视角的内存管理方案。逻辑空间地址由一组段组成，每个段都有名称和长度。段内的元素通过它们距离段首的偏移来指定：程序的第一条语句、函数的第五条指令等。地址指定了段名称和段内偏移，也就是这两个量指定了地址。示例：\n\n\n内存管理策略的目的主要是同时将多个进程放入内存，以便允许多道程序设计。\n虚拟内存基本页面置换算法：\n\nFIFO 页置换：很简单，就是先进先出的队列形式；\n最优置换：理论算法，通常用于和实际置换算法做比较，对比得出实际算法的性能情况；\nLRU（Least Recently Used，最近最少使用) 置换：当必须置换一页时，选择最长时间没有使用的页换出。\n\n","categories":["OS"],"tags":["OS"]},{"title":"OS-内存管理","url":"/2018/04/12/QA/%E5%B8%B8%E8%A7%81%E9%97%AE%E9%A2%98-lang/OS-%E5%86%85%E5%AD%98%E7%AE%A1%E7%90%86/","content":"CPU 所能直接访问的存储器只有内部寄存器和内存。即，如果数据不在内存中，那么在 CPU 使用前必须先把数据移到内存中。而 CPU 和内存的速度差异很大，故在之间增加内存缓存区，即高速缓存（cache）来协调。\n地址绑定源程序中的地址通常是用符号(如 count)来表示的。编译器通常将这些符号地址绑定（binding）到可重定位的地址（如“从本模块开始的第17字节”）。链接程序或加载程序再将这些可重定位的地址绑定成绝对地址（如 0x74014）。每次绑定都是从一个地址空间到另一个地址空间的映射。通常，将指令与数据绑定到内存地址有以下三种情况：\n\n编译时（compile time）：如果在编译时就知道进程将在内存中的驻留地址，那么就可以生成绝对代码（absolute code）；\n加载时（load time）：如果在编译时不知道进程将驻留在内存的什么地方，那么编译器就必须生成可重定位代码（relocatable code）。最后绑定会延迟到加载时才进行。如果开始地址发生变化，只需要重新加载以引入改变值；\n执行时（execution time）：如果进程在执行时可以从一个内存段移到另一个内存段，那么绑定必须延迟到执行时才进行。采用这种方案需要特定的硬件，绝大多数通用计算机 OS 采用这种方法。\n\nCPU 所生成的地址通常称为逻辑地址（logical address），内存单元所看到的地址（即加载到内存地址寄存器（memory-address register）中的地址）通常称为物理地址（physical address）。编译和加载时的地址绑定方法生成相同的逻辑地址和物理地址；但执行时的地址绑定方法导致不同的逻辑地址和物理地址，此时，通常称逻辑地址为虚拟地址（virtual address），二者可以不做区分。由程序所生成的所有逻辑地址的集合称为逻辑地址空间（logical address space），与这些逻辑地址相对应的所有物理地址的集合称为物理地址空间（physical address space）。因此，对于执行时绑定地址方案，逻辑地址空间与物理地址空间是不同的。程序运行时从虚拟地址到物理地址的映射是由硬件 内存管理单元（Memory-Management Unit， MMU） 完成的。内存管理中，逻辑地址空间绑定到单独的一套物理地址空间这一概念至关重要。\n动态加载(dynamic loading)为突破进程大小受物理内存大小的限制，获得更好的内存空间使用，可以使用 动态加载：一个子程序只有在调用时才被加载，所有子程序都以可重定位的形式保存在磁盘上。\n动态链接库（dynamically linked library）有的 OS 只支持 静态链接（static linking），此时系统语言库的处理与其他目标模块一样，由加载程序合并到二进制程序镜像中。动态链接的概念类似于动态加载，但这里不是将加载延迟到运行时，而是将链接延迟到运行时，从而避免系统上每个程序都需要一份语言库的副本（对于需要引用该库的程序而言）。动态链接也可用于库更新（如修改漏洞），一个库可以被新的版本所替代，且所有使用该库的程序都会自动使用新的版本。\n\n内存映射和保护是通过 基地址寄存器（重定位寄存器） 和界限地址寄存器完成的。\n内存分配连续分配：每个内存映射和保护内存映射和保护进程位于一个连续的内存区域。固定大小分区：将内存划分为多个固定大小的分区，每个分区只能容纳一个进程（现已不再使用）；可变分区：OS 用表的形式记录内存中哪些可用和已占用，为新进程分配内存策略有：\n\n首次适应（first-fit）：查找并分配第一个足够大的分区块；\n最佳适应（best-fit）：遍历并分配最小的足够大的分区块；\n最差适应（worst-fit）：遍历并分配最大的分区块。\n\n碎片首次适应和最佳适应都有 外部碎片（external fragmentation）问题：随着进程装入和移出，空闲内存空间被分割成小片段在内存的各处，尽管总的可用内存可以满足新进程，但由于碎片化无法完成分配，即出现外部碎片问题。对应的 内部碎片 是指：通常内存以固定大小的块为单位（如果以字节为单位，管理表的开销可能会很大）来分配，进程所分配的内存可能比所要的大出一些（最后的块产生的剩余），而这个多分配的部分就是内部碎片。一种解决外部碎片的方法是 紧缩（compaction）：移动内存内容，以便所有空闲空间合成一个整块。显然，紧缩策略对重定位发生在动态并在运行时才可使用。该策略开销较大。另一种方法是允许物理地址空间为非连续。一般会合并两种技术，或互补实现之。\n分页内核把物理页作为内存管理的基本单位。允许进程的物理地址空间可以是非连续的。现在的分页支持通过硬件和 OS 配合的方式实现。一方面，把物理内存划分为固定大小的内存块，称为物理页面或者帧（page frame）；另一方面，把虚拟地址空间页划分为同样大小的块，称为虚拟页面（page）。页大小要求是2的整数次幂，由硬件决定，一般在512B-1MB之间。如下图所示，由 CPU 生成的地址分为两部分：页号 p 和页偏移 d。页号作为页表中的索引，页表包含每页所在物理内存的基地址，该基地址和页偏移的组合就形成物理地址，即可送交物理单元。\n\n分页技术不会产生外部碎片：每个物理页都可以分配给需要它的进程。但依然会产生内部碎片（看一下页面大小就知道了）。同时，由于页表记录项的开销会随着页的增大而降低（页面变大则总页数减少），所以要均衡页表开销和内部碎片，选取合适的页大小。有的 CPU 甚至支持多种页大小。但对快速可变的页大小的支持是一项具有挑战性的开发工作。而今页表通常非常大（百&#x2F;万量级），寻址页表项（页表装在内存中）会产生延迟，使用一种小而专用且快速的硬件缓冲——转换表缓冲区（Translation Look-aside Buffer， TLB） 解决。目前采用较多的是多级分页（如两级分页），就是将页表再分页。如下图：\n\n\n分段（Segmentation）从开发者视角看待程序：由主程序加上一组方法、过程、函数，还有各种数据结构：对象、数组、堆栈、变量等等。每个模块或其他元素都可以通过名称引用。我们关心“堆栈”、“主程序”，而不关心这些元素所在内存的位置，不关心栈是放在函数前还是后……分段就是支持这种用户视角的内存管理方案。逻辑空间地址由一组段组成，每个段都有名称和长度。段内的元素通过它们距离段首的偏移来指定：程序的第一条语句、函数的第五条指令等。地址指定了段名称和段内偏移，也就是这两个量指定了地址。示例：\n\n\n内存管理策略的目的主要是同时将多个进程放入内存，以便允许多道程序设计。\n虚拟内存基本页面置换算法：\n\nFIFO 页置换：很简单，就是先进先出的队列形式；\n最优置换：理论算法，通常用于和实际置换算法做比较，对比得出实际算法的性能情况；\nLRU（Least Recently Used，最近最少使用) 置换：当必须置换一页时，选择最长时间没有使用的页换出。\n\n","categories":[],"tags":["OS"]},{"title":"信号","url":"/2018/04/11/OS/%E4%BF%A1%E5%8F%B7/","content":"信号是软件中断。\n","categories":["OS"],"tags":["OS"]},{"title":"中断和异常","url":"/2018/04/11/OS/%E4%B8%AD%E6%96%AD%E5%92%8C%E5%BC%82%E5%B8%B8/","content":"概念上二者并非界限清晰。\n\n从 OS （操作系统）层面，定义偏向于使用“中断”：中断分为同步（synchronous）中断和异步（ssynchronous）中断，同步中断是当指令执行时由 CPU 控制单元产生的，之所以称为同步，是因为只有在一条指令终止执行后 CPU 才会发出中断；异步中断是由其他硬件设备依照 CPU 时钟信号随机（任何时候）产生的。（UTLK、LKD、APUE）\n从 CA （计算机体系结构）层面，如 CSAPP 中解释：处理器把同步和异步中断分别称为异常（exception）和中断（interruption），并将所有的异常分为 4 类（）：\n（异步的）中断；（同步的）陷阱；（同步的）故障；（同步的）终止；\n\n\n\n但本质上趋同的观点是可以使用 中断信号 来指代二者（同步和异步），且中断一般指 I&#x2F;O 设备也就是硬件发出的异步信号（非指令产生），异常一般指处理器本身产生的同步信号（该同步信号一般由操作系统&#x2F;应用程序指令产生，交送处理器处理）。以下使用中断（异步异常）和异常（同步异常）表述。\n异常控制流（CSAPP）Exceptional Control Flow，ECF，异常控制流，也就是异常&#x2F;中断，导致正常的处理器控制流发生突变来应对异常事件。ECF 发生在计算机系统的各个层次：硬件层，硬件检测到的事件会触发控制转移到异常处理程序；操作系统层，内核通过上下文切换将控制从一个用户进程转移到另一个用户进程；应用层，一个进程可以发送信号到另一个进程，而接收者会将控制转移到它的一个信号处理程序。\nECF 重要作用\n是操作系统实现 I&#x2F;O、进程和虚拟内存的基本机制；\nECF 是计算机系统实现并发的基本机制；\n应用程序通过使用一个陷阱（trap）&#x2F;系统调用（system call）的 ECF 形式，向操作系统请求服务。比如向磁盘写数据，从网络读数据、创建新进程等，都是通过应用程序调用系统调用实现的；\n通过 ECF 理解软件层面异常如何工作。C++、java 等语言都是通过 try…catch…throw 语句来提供软件异常机制。软件异常允许程序进程非本地跳转（即违反通常的调用&#x2F;返回栈规则的跳转）来响应错误情况。而非本地跳转是一种应用层 ECF，理解这些低级实现有助于理解高级软件异常的实现机制。etc\n\n中断机制：让硬件在需要的时候向内核发出信号。中断本质上是一种特殊的电信号，由硬件设备发向处理器。处理器接收中断后，会马上向 OS 反映此信号的到来，然后 OS 负责处理这些新到来的数据。中断可以随时产生，因此内核随时可能因为新到来的中断而被打断。\n\n\n中断处理程序在响应一个特定中断的时候，内核会执行一个函数，该函数叫做中断处理程序（interrupt handler）或中断服务例程（Interrupt service routine，ISR）。每种类型的中断都有一个相应的中断处理程序。一个设备的中断处理程序是其设备驱动程序（driver）的一部分——设备驱动程序是用于对设备进行管理的内核代码。\n中断处理程序与其它内核函数真正的区别在于，中断处理程序是被内核调用来响应中断的，而它们运行于一个被称为中断上下文（Interrupt context）的特殊上下文中（也成原子上下文），该上下文中的执行代码不可阻塞。\n上半部分与下半部分鉴于中断处理程序既要运行得快，又要完成很多的工作量，一般把中断处理程序分为两个部分：\n\n上半部（top half）：中断处理程序，接收到一个中断，立即开始执行，但只做有严格时限的工作，例如对接收的中断进行应答或复位硬件，该阶段可能禁止一些&#x2F;全部其它中断；\n下半部（bottom half）：能够被允许稍后完成的工作推迟到这个部分来完成，在合适的时机，下半部开始执行，该阶段可以响应所有中断。以网卡为例 TBA\n\n三种下半部接口：\n\n软中断：中断上下文，相同类型的也允许同时执行，数据被软中断共享情况下需要锁；\ntasklet：中断上下文，自己负责执行的序列化保障，相同类型的tasklet不允许同时执行，所以不需要锁；\n工作队列：进程上下文，需要锁来避免数据共享等问题。\n\n中断上下文（interrupt handler）（对比进程上下文），中断上下文和进程没有什么关系，与 current 宏也无关（尽管它会指向被中断的进程）。因为没有后备进程，中断上下文不睡眠（一旦睡眠就无法重新调度了）。因此不能从中断上下文调用某些（能够睡眠的）函数。中断上下文打断了其它代码的执行（甚至打断在其他中断线上的另一中断处理程序），因此有严格的时间限制，应当迅速、简洁地完成，尽量不要用循环去处理繁重的工作。尽量把工作从中断处理程序（上半部）分离出来，放到下半部去执行。中断处理程序的栈空间是专用的一个页，在 32 系统上为 4 KB。编写中断处理程序可以不关心栈如何设置或大小，但要尽量节约内核栈空间。\n","categories":["OS"],"tags":["OS"]},{"title":"UNIX","url":"/2018/04/11/OS/UNIX/","content":"OS 是指在整个系统中负责完成最基本功能和系统管理的那些部分。 包括内核、设备驱动程序、启动引导程序、命令行 Shell 或其它用户界面、基本的文件管理工具和系统工具等。\nUnix 特点：\n\n明确的设计目的，并且仅有几百个系统调用；\n所有的东西都被当作文件对待（并非所有，Sockets就是个典型的例外）。这种抽象使得对数据和对设备的操作是通过一套相同的系统调用接口来进行的：open()、read()、write()、lseek()、close()；\n内核和相关的系统工具软件用C语言编写，具备强大的移植能力；\n创建进程非常迅速——独特的fork()系统调用；\n提供了一套简单但稳定的进程间通信元语。\n\nLinuxLinux 是类 Unix 系统，但它不是Unix：采用Unix的设计目标并且实现了其API（由 Posix 等标准定义），并未像其它 Unix 变种那样使用 Unix 的源代码。使用 GNU GPL v2 作为限制条款。一般，Linux 这个词主要还是指 Linux 内核，而非 Linux 系统，后者在前者基础上集成了 C库、工具集甚至如 GNOME 等图形界面。Linux 是模块化的、多线程的、内核本身可调度的 OS：\n\n支持动态加载内核模块。尽管是但内核，但允许在需要的时候动态地卸载&#x2F;加载部分内核代码；\n支持对称多处理（SMP）机制；\n可以抢占（preemptive），具有允许在内核运行的任务优先执行的能力；\n不区分线程和一般进程，对于内核来说，所有的进程都一样。\n提供具有设备类的面向对象的设备模型、热插拔事件，以及用户空间的设备文件系统（sysfs）；\n忽略了一些被认为很拙劣的 Unix 特性，提现了自由这个词的精髓。\n\nLinux 进程树Linux 和 Unix 类似，其进程之间存在明显的继承关系：所有的进程都是 PID 为 1 的 init 进程的后代。内核在系统启动的最后阶段启动 init 进程。\n\n进程在创建它的时刻开始存活。在 Linux 系统中，这通常是调用 fork() 系统的结果，该系统调用通过复制一个现有进程来创建一个全新的进程。现代 Linux 内核中，fork() 实际上是由 clone() 系统调用实现的；\nfork() 系统调用结束时，从内核返回两次：一次回到父进程，在返回点这个位置上恢复执行；一次回到新产生的子进程，子进程开始执行；\n接着调用 exec() 函数，创建新的地址空间，并把新的程序（可执行文件）载入其中；\n最终，进程通过 exit() 系统调用退出执行，终结进程并释放所占用的资源。父进程可以通过 wait4() 系统调用查询子进程是否终结。进程退出执行后被设置为僵死状态，直到它的父进程调用 wait() 或 waitpid() 为止。\n\n内核通常由负责响应中断的中断服务程序、负责管理多个进程从而分享处理器时间的调度程序、负责管理进程地址空间的内存管理程序、负责网络与进程间通信等系统服务程序共同组成。对于提供保护机制的现代 OS 来说，内核独立于普通应用程序，一般处于系统态，拥有受保护的内存空间和访问硬件设备的所有权限。这种系统态和被保护起来的内存空间，统称为内核空间。相对地，应用程序在用户空间执行。当内核运行的时候，系统以内核态进入内核空间执行；执行一个普通用户程序时，系统以用户态进入用户空间执行。应用程序通过系统调用与内核通信。当一个应用程序执行一条系统调用，实际上是内核正在代其执行，此时，应用程序被称为通过系统调用在内核空间运行，内核被称为运行于进程上下文中。这种交互关系——应用程序通过系统调用陷入内核，是应用程序完成其工作的基本行为方式。可以将每个处理器在任何指定时间点上的活动概括为下列三者之一（即使 CPU 空闲也不例外，此时运行一个空进程，处于进程上下文，运行于内核空间，即第二种）：\n\n运行于用户空间，执行用户进程；\n运行于内核空间，处于进程上下文，代表某个特定的进程执行；\n运行于内核空间，处于中断上下文，于任何进程无关，处理某个特定的中断。\n\n中断不在进程上下文中执行，它们在一个与所有进程都无关的、专门的中断上下文中运行：为了保证中断服务程序能够在第一时间相应和处理中断请求，然后快速地退出。\n","categories":[],"tags":["OS"]},{"title":"线程","url":"/2018/04/10/OS/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B/%E7%BA%BF%E7%A8%8B/","content":"\n\nCPU 调度的基本单位是线程——比进程更轻量的调度执行单位。由线程 ID、程序计数器、寄存器集合、栈组成。与属于同一进程的其他线程共享代码段、数据段、内存地址和其他 OS 资源，如打开的文件和信号等。线程的引入可以把一个进程的资源分配和执行调度分开，各个线程既可以共享进程资源，又可以独立调度。\n为什么引入线程\n应用需要。如图形处理软件。\n性能的考虑。有的线程去执行计算，有的线程执行 I&#x2F;O，提高执行效率。\n开销的考虑。空间开销小；创建&#x2F;销毁一个新线程花费时间少；线程切换花费时间少；线程之间通信无需调用内核（同一进程内的线程共享内存和文件）。\n\n线程属性\n有标识符号 ID；\n有状态及状态转换 → 需要提供一些操作；\n不运行时需要保存上下文：有上下文环境，程序计数器等资源；\n有自己的栈和栈指针；\n共享所在进程的地址空间和其他资源；\n可以创建、销毁另一个线程。程序开始可以看成是以一个单线程进程方式运行的。\n\n线程实现及模型主要有 3 种方式：使用内核线程实现、使用用户线程实现、使用用户线程+轻量级进程混合实现。\n内核线程实现（一对一）内核线程（Kernel-Level Thread, KLT）就是直接由 OS Kernel 支持的线程，这种线程由内核来完成线程切换：内核通过操控调度器对线程进行调度，并负责讲线程的任务映射到各个处理器上。每个内核线程可以视为内核的一个分身，这样 OS 就有能力同时处理很多任务。支持多线程的内核就叫多线程内核（Multi-Threads Kernel）。程序一般不会直接去使用内核线程，而是去使用内核线程的一种高级接口——轻量级进程（Light Weight Process，LWP），轻量级进程就是通常意义上的线程。由于每个轻量级进程都由一个内核线程支持（所以只有先支持内核线程，才能有轻量级进程），这种轻量级进程和内核线程之间 1:1 的关系，即将每个用户线程映射到一个内核线程（准确说是其高级接口：轻量级进程），称之为 一对一线程模型：\n\n优点\n\n该模型在一个线程执行阻塞系统调用时，允许另一个线程继续执行，因而提供了比多对一更好的并发功能，也允许多个线程并行地运行在多处理器系统上。\n\n缺点\n\n每创建一个用户线程就需要创建一个相应的内核线程，由于创建内核线程的开销会影响应用程序的性能，所以这种模型的绝大多数实现都限制了系统所支持的线程数量；\n由于是基于内核线程实现，所以各种线程操作，如创建、析构及同步等，都需要进行系统调用，而系统调用的代价相对较高：需要在用户态和内核态来回切换。\n\n用户线程实现（一对多）广义上，一个线程只要不是内核线程，就可以看作是用户线程（User Thread，UT）。从这个角度讲，LWP 也属于用户线程，但 LWP 的实现始终是建立在内核之上的，许多操作都要进行调用，效率因此受到限制；狭义上的 UT 指的是完全建立在用户空间的线程库上，系统内核不能感知线程存在的实现。用户线程的建立、同步、调度、销毁等完全在用户态种完成，不需要内核的帮助。如果程序实现得当，这种线程不需要切换到内核态，因此操作快速且消耗较低，也可以支持大规模的线程数量。_部分高性能数据库种的多线程就是由用户线程实现的_。这种进程与用户线程之间 1:n 的关系称为 一对多线程模型，也称二级模型：\n\n该模型不需要系统内核支援（这也是劣势），也无须用户态到内核态的状态转换，效率更高；而所有的线程操作都需要用户程序自行处理，需要考虑各种问题。而且由于 OS 只把处理器资源分配到进程，诸如“阻塞如何处理”、“多处理器系统中如何将线程映射到其他处理器上”这类问题解决起来异常困难甚至不可能完成。并且如果一个线程执行了阻塞系统调用，那么整个进程都会阻塞，而且因为任一时刻只有一个线程能访问内核，多个线程并不能并行运行在多处理器上，即并没有增加并发性。具体就是：优点\n\n线程切换快；\n调度算法由应用程序特定；\n可以运行在任何操作系统之上（只需要实现线程库）。\n\n缺点\n\n内核只将处理器分配给进程，同一进程中的两个线程不能同时运行于两个处理器上；\n大多数系统调用是阻塞的，因此由于内核阻塞进程，所以进程中所有的线程都将被阻塞。\n\n实现的复杂度使得用户线程的使用越来越少，java、ruby 等曾经使用过用户线程，但后来也都放弃了。\n用户线程+轻量级进程混合实现（多对多）以上两种方法的混合实现：该模式即存在用户线程，也存在轻量级进程。用户线程还是完全建立在用户空间，因此用户线程的创建、切换、析构等操作依然保持低消耗的优势，并且可以支持大规模的用户线程并发。而 OS 提供支持的轻量级进程则作为用户线程和内核线程之间的桥梁，这样可以使用内核提供的线程调度能力和处理器映射，并且用户线程的系统调用要通过轻量级进程来完成，大大降低了整个进程被完全阻塞的风险。该模式种用户线程和轻量级进程的数量不固定，即 n:m 的关系，称为 多对多线程模型：\n\n\n\n线程库为程序员提供创建和管理线程的 API。主要有两种方式来实现线程库：\n\n在用户空间中提供一个没有内核支持的库，此库的所有代码和数据结构都存在于用户空间中。调用库中的一个函数只是导致了用户空间的一个本地函数调用，而不是系统调用。\n执行一个有操作系统直接支持的内核级的库。此时，库的代码和数据结构存在于内核空间中。调用库中的一个 API 函数通常会导致对内核的系统调用。\n\n目前使用的三种主要线程库是：\n\nPOSIX Pthread：作为 POSIX 标准的扩展，可以提供用户级或内核级的库。它是由 POSIX 标准（IEEE 1003.1c）为线程和同步定义的 API，这是线程的规范，而不是实现。\nWin32：适用于 Windows OS 的内核级线程库。\nJava 线程 API：允许线程在 Java 程序中直接创建和管理线程。然而，大多数 JVM 实例运行在宿主 OS 之上，Java 线程 API 通常采用宿主系统上的线程库来实现，即，在 UNIX 和 Linux 上，采用 Pthread 实现，在 Windows 上，采用 Win32 API 来实现。\n\n同属一个进程的线程共享进程数据。不过，在有些情况下每个线程可能需要一定数据的自己的副本，这种数据成为线程特定数据。\n并发与线程并发不一定要依赖多线程（如 PHP 中常见的多进程并发），但 java 中的并发大多数与线程相关。\n","categories":["OS"],"tags":["OS","线程"]},{"title":"IO","url":"/2018/04/10/OS/IO/","content":"[toc]I&#x2F;O 是在主存和外部设备（磁盘、终端、网络等）之间复制数据的过程。\n系统 I&#x2F;O说到 I&#x2F;O，不免地先简要介绍一下文件相关的重要概念。\n文件类型Unix 里一切皆文件。\n\n普通文件：文本文件、二进制文件对内核而言都是普通文件。\n目录文件：包含了其他文件的名字和指向与这些文件有关信息的指针。只有内核可以直接写目录文件。\n块特殊文件：提供对块设备（磁盘、缓存等）带缓冲的访问，每次访问固定长度的数据。\n字符特殊文件：提供对设备不带缓冲的访问，每次访问长度可变。系统中所有的设备要么是字符特殊文件，要么是块特殊文件。\npipeline：管道。\nFIFO：可用于进程间通信，也称命名管道。\nsocket：用于进程间的网络通信。\n符号链接：指向另一个文件。\n\n文件描述符file descriptors，fd。对于内核而言，所有打开的文件都通过文件描述符引用（即用 fd 来指代打开的文件），它是一个（一般数值比较小的）非负整数。获取文件描述符的常用方法是调用 open()。UNIX 系统 shell 把文件描述符 0 与 标准输入关联，1 与标准输出关联，2 与标准错误关联。尽管这和内核无关，但各种 shell 和应用都遵循此惯例，在 stdio 函数库中，这几种描述符分别对应文件流 stdin、stdout、stderr。\nI&#x2F;O 模型Linux 提供 5 种 I&#x2F;O 模型，前 4 个是同步 I&#x2F;O 模型：\n\n阻塞式 I&#x2F;O\n非阻塞式 I&#x2F;O\nI&#x2F;O 复用\n信号驱动 I&#x2F;O（SIGIO）\n异步 I&#x2F;O\n\nI&#x2F;O 多路复用I&#x2F;O 多路复用允许同时检查多个文件描述符，看其中是否有可以执行 I&#x2F;O 操作的。基本思路就是使用 select、poll、epoll 等函数，要求内核挂起进程，只有在一个或多个 I&#x2F;O 事件发生，才将控制返回给应用程序。可以在普通文件、终端、伪终端、管道、FIFO、socket以及其他字符型设备上使用这些函数来检查文件描述符。它们允许进程一直等待（以阻塞的方式）文件描述符成为就绪态，或者调用时指定等待超时时间。\nselect以 select 为例，当我们对多个描述符感兴趣（想要进行操作）时，调用该函数，进入阻塞状态，在这些描述符中任一个准备好进行 I&#x2F;O 时才返回，携带该描述符的信息，从而开始 I&#x2F;O 操作。其中 select 的参数给内核的信息有：\n\n调用者所关心的描述符列表；\n对于每个描述符所关心的条件（读、写，以及是否关心该描述符的异常状态）；\n等待时长（永久、定时、不等待）；\n\n而 select 返回时，内核提供的信息有：\n\n已准备好的描述符的数量；\n对于读、写、异常这 3 个条件中的每一个，哪些描述符已经准备好。\n\n过程具体过程：\n\n使用 copy_from_user 从用户空间拷贝 fd_set 到内核空间\n注册回调函数 __pollwait\n遍历所有 fd，调用其对应的 poll 方法（对于 socket，这个 poll 方法是 sock_poll，sock_poll 根据情况会调用到 tcp_poll，udp_poll 或 datagram_poll）。以 tcp_poll 为例，其核心实现就是__pollwait，也就是上面注册的回调函数\n__pollwait 的主要工作就是把 current（当前进程）挂到设备的等待队列中，不同的设备有不同的等待队列，对于 tcp_poll 来说，其等待队列是 sk-&gt;sk_sleep（注意把进程挂到等待队列中并不代表进程已经睡眠了）。在设备收到一条消息（网络设备）或填写完文件数据（磁盘设备）后，会唤醒设备等待队列上睡眠的进程，这时 current 便被唤醒了。\npoll 方法返回时会返回一个描述读写操作是否就绪的 mask 掩码，根据这个 mask 掩码给 fd_set 赋值。\n如果遍历完所有的 fd，还没有返回一个可读写的 mask 掩码，则会调用 schedule_timeout，使得调用 select 的进程（也就是 current）进入睡眠。当设备驱动发生自身资源可读写后，会唤醒其等待队列上睡眠的进程。如果超过一定的超时时间（schedule_timeout 指定），还是没唤醒则调用 select 的进程会重新被唤醒获得 CPU，进而重新遍历 fd，判断有没有就绪的 fd\n把 fd_set 从内核空间拷贝到用户空间。\n\n3 个缺点\n每次调用 select 都需要把 fd_set(filedescriptor，即文件句柄集合)从用户态拷贝到内核态，这个开销在 fd 很多时会很大；\n每次调用 select 都需要在内核遍历传递进来的所有 fd，这个开销在 fd 很多时也很大；\nselect 支持的文件描述符数量太少，默认是 1024。\n\npoll和 select 类似，主要区别在于如何指定待检查的文件描述符。select 中是提供 3 个集合，每个集合中标明感兴趣的文件描述符，而在 poll 中，提供一列文件描述符，并在每个文件描述符上标明感兴趣的事件。\nepollevent poll，同样可以检查多个文件描述符上的 I&#x2F;O 就绪状态。可以看作对 select 和 poll 的改进，Linux 专有。主要优点：\n\n当检查大量文件描述符时，性能比 select、poll 高很多：无需多次向内核传递表示所有需要被检查的文件描述符所构成的数据结构，而是内核会为之记录需要检查的文件描述符有哪些；\n既支持水平触发（LT），也支持边缘触发（ET），对应地，select、poll 只支持水平触发，信号驱动 I&#x2F;O 只支持边缘触发；etc\n\nLT ET即 Level Trigger，水平触发；Edge Trigger，边缘触发。\n\n水平触发：如果文件描述符上可以非阻塞地执行 I&#x2F;O 系统调用，此时认为它已经就绪。多路复用（如 select、poll）采用水平触发通知描述符就绪。水平触发可以在任意时刻检查文件描述符的就绪状态，这意味着当确定文件描述符处于就绪状态时，就可以对其执行一些 I&#x2F;O 操作（也可以不执行），然后重复检查文件描述符状态，看其是否如仍然处于就绪状态。这也表明，我们无需在发现就绪状态的文件描述符上进行尽可能多的 I&#x2F;O 操作，因为检查可以重复进行。\n边缘触发：如果文件描述符自从上次状态检查以来有了新的 I&#x2F;O 活动（如新的输入），此时需要触发通知。信号驱动 I&#x2F;O 采用边缘触发通知描述符就绪。只有当 I&#x2F;O 事件发生时才收到内核通知，在另一个 I&#x2F;O 事件到来之前不会有新的通知产生。另外，在通知到来时，我们通常并不知道需要处理多少 I&#x2F;O（比如有多少字节可以读取），因此一般会尽可能多地处理：意即，一直执行 I&#x2F;O 操作，直到相应的系统调用（read、write 等）以失败告终，此时证明该文件描述符上出现饥饿现象，不能再继续执行 I&#x2F;O 操作。\n\n参考：https://cloud.tencent.com/developer/article/1005481http://www.cnblogs.com/Anker/p/3265058.htmlhttps://zhuanlan.zhihu.com/p/38277885\n","categories":["OS"],"tags":["OS"]},{"title":"OS","url":"/2018/04/10/OS/OS/","content":"[toc]\n中断&#x2F;异常操作系统是由中断驱动的，也可以说是由事件驱动的。中断&#x2F;异常 是 CPU 对系统发生的某个事件作出的一种反应。事件的发生改变了 CPU 的控制流：CPU 暂停正在执行的程序，保留现场后 自动 转去执行相应的事件处理程序，处理完成后返回断点继续执行被打断的程序。这里的“自动”是说，该操作是由硬件来完成的，硬件完成控制流的转移工作。\n中断（外中断）外部事件，正在运行的程序所不期望的，是异步的。其引入是为了支持 CPU 和设备之间的并行操作：当 CPU 启动设备进行 I&#x2F;O 后，设备便可以独立工作，CPU 就可以转去处理与此次 I&#x2F;O 无关的事情，当设备完成 I&#x2F;O 后，通过向 CPU 发送中断报告此次 I&#x2F;O 的结果，让 CPU 决定如何处理后续操作。包括：\n\nI&#x2F;O 中断\n时钟中断\n硬件故障\n\n##异常（内中断）由正在执行的指令引发，是同步的。表示 CPU 执行指令时本身出现的问题：算术溢出、内存访问越界、除零等。这时硬件改变了 CPU 当前的执行流程，转到相应的错误处理程序或异常处理程序或执行系统调用。包括：\n\n系统调用\n页故障&#x2F;页错误\n保护性异常\n断点指令\n其他程序性异常（如算术溢出）\n\n硬件&#x2F;软件分工硬件：响应硬件负责捕获中断源发出的中断&#x2F;异常请求，以一定方式响应，将处理器控制权转交给特定的处理程序。由中断硬件部件完成。\n\n\n软件：处理识别中断&#x2F;异常类型并完成相应的处理。系统运行时若响应中断，中断硬件部件将 CPU 控制权转交给中断处理程序，处理程序执行：\n\n保存相关寄存器信息；\n分析中断&#x2F;异常的具体原因；\n执行对应的处理功能；\n恢复现场，返回被事件打断的程序。\n\n","categories":["OS"],"tags":["OS"]},{"title":"并发","url":"/2018/04/10/OS/%E5%B9%B6%E5%8F%91/","content":"[toc]逻辑控制流在时间上重叠，即是并发的，是内核运行多个应用程序的机制，也是提升应用执行效率的手段。\n现代 OS 提供 3 种构造并发程序的方法：进程、I&#x2F;O 多路复用、线程。\nI&#x2F;O 多路复用基本思路就是使用 select 函数，要求内核挂起进程，只有在一个或多个 I&#x2F;O 事件发生，才将控制返回给应用程序。\n","categories":["OS"],"tags":["OS"]},{"title":"进程","url":"/2018/04/10/OS/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B/%E8%BF%9B%E7%A8%8B/","content":"进程程序本身并不是进程，进程是 处于执行期的程序以及相关的资源的总称，也叫任务（task）。Linux 内核通常把进程叫做任务，线程仅仅被视为一个与其它进程共享某些资源的进程。\n进程三种基础状态：\n运行态，该时刻进程实际占用CPU；\n就绪态，可运行，但因为其他进程正在运行而暂时停止；\n阻塞态，除非某外部事件发生，否则不能运行。\n\n此外，还有五状态进程模型、七状态进程模型：\n\n\n\n进程控制块Process Control Block，PCB\n相关概念临界区《现代操作系统》中对临界区的定义：对共享内存进行访问的程序片段（代码段），就是临界区。进一步解释，当多个进程都要使用同一个共享资源时，它的代码里会有相应的操作，这些代码段就叫做临界区&#x2F;互斥区。所谓临界区：是多个进程，对某一个临界资源实施操作的程序片段，也就是说这些程序片段分散在不同的进程中，它们的共同的特点，是对同一个临界资源进行一些操作。即这一段代码，和另外一个进程的这一段代码，他们互为临界区。临界区问题是设计一个以便进程协作的协议。其解答必须满足三个条件：\n\n互斥（mutual exclusion）：如果有一个进程在其临界区内执行，那么其他进程都不能在其临界区内执行；\n前进（progress）：如果没有进程在其临界区内执行，且有进程需要进入临界区，那么只有那些不在剩余区内执行的进程可参与选择，以确定下一个进入临界区的进程，且这种选择不能无限推迟；\n有限等待（bounded waiting）：从一个进程做出进入临界区的请求，直到该请求允许为止，其他进程允许进入其临界区的次数有上限。\n\n临界区问题的解决都需要一个简单的工具——锁：从硬件到软件 API 实现，都需要实现锁的概念。\n忙等待 &amp; 自旋锁忙等待（busy waiting），进程在得到临界区访问权之前，持续循环测试而不做其他事情，浪费了 CPU 资源，所以单核处理器时应避免忙等待。克服忙等待的方式是修改信号量操作的定义，将一个进程执行 wait() 操作时，不进入忙等待，而是阻塞自己，从而将控制权转到 CPU 调度程序，以选择另一个进程来执行（需要上下文切换）。自旋锁（spin lock），允许忙等待，进程在其等待锁时还在运行，这在多处理器中常用到。优点在于：进程在等待锁时不进行上下文切换，而这种切换可能会花费相当长的时间。因此，如果锁的占用时间短，自旋锁就很有用。多处理器系统中常用自旋锁，这样一个线程在一个处理器上自旋时，另一个线程可以在另一个处理器上进入其临界区。\n[参考]{https://www.cnblogs.com/youngforever/p/3250270.html)\n","categories":["OS"],"tags":["OS","进程"]},{"title":"进程生命周期","url":"/2018/04/10/OS/%E8%BF%9B%E7%A8%8B%E4%B8%8E%E7%BA%BF%E7%A8%8B/%E8%BF%9B%E7%A8%8B%E7%94%9F%E5%91%BD%E5%91%A8%E6%9C%9F/","content":"创建进程Linux 用户进程不能直接被创建出来，不存在这样的 API，而只能从某个进程中复制产生一个新的进程。这主要涉及到三个系统调用：fork 函数、vfork 函数、clone 函数。\nfork 函数一个现有的进程可以调用 fork 函数创建一个新进程，新进程被称为子进程。fork 被调用一次，会返回两次：子进程返回值是 0（因为进程 ID 都大于 0，返回 0 是为了提供程序在该子进程中执行），父进程返回值是新建子进程的 ID。子进程是父进程的副本，除了 ID 以外，子进程的各种数据结构（主要是正文段、数据段、堆、栈这 4 部分）都是父进程的拷贝副本。fork() 的实际开销是复制父进程的页表和给子进程创建唯一的进程描述符（task_struct）。\n写时复制Copy-On-Write，COW。直接把父进程所有资源（也就是地址空间）全盘复制给子进程虽然简单，但效率低下，再考虑那些子进程可能很快甚至立即就执行（会修改数据）的情况，这种复制显得有些多余，所以引入了写时复制。即，只有进程空间各段的内容要发生变化（要写入）时，才会将父进程的内容复制一份给子进程，没有复制之前则处于和父进程共享同一个副本的状态。写时复制的思想在 C++、java（一些线程安全的集合类）都有体现。\n参考\nvfork 函数vfork 函数的调用方式和返回值与 fork 相同，它的实现主要是为了优化那些创建好就立即调用 exec 函数而进入执行的进程的创建。它并不将父进程的地址空间复制到子进程中，而是共享父进程的地址空间。因为子进程会立即调用 exec 函数进入执行阶段，所以没有必要进行拷贝；另一个区别是，vfork 保证子进程先运行，即它会阻塞父进程，直到子进程退出或执行 exec()。引入 COW 技术之后，fork 函数的开销也降低了很多，vfork() 的意义也不是特别明显了。甚至有的实现直接是调用 fork() 完成的。\nclone 函数clone() 主要用于线程的创建，为用户线程提供了良好的支持。这个接口提供了更多的灵活性，可以让用户指定父进程和子进程（也就是创建的进程）共享的内容。其实通过传递不同的参数，clone() 可以实现 fork() 和 vfork() 的功能。\n运行子进程创建完毕之后，往往要调用 exec() 来执行一个程序（父进程、子进程都有可能）。exec 是一个函数族，包括 execl、execlp、execle、execv、execve、execvp 6 个具体实现，区别在于对路径名、参数以及环境变量的指定上。\n参考\n终止进程8 种方式使进程终止（termination），5 种正常终止：\n\n从 main 返回\n调用 exit\n调用 _exit 或 _Exit\n最后一个线程从其启动例程返回\n从最后一个线程调用 pthread_exit3 种异常终止：\n调用 abort\n接收到一个信号\n最后一个线程对取消请求做出响应\n\nwait waitpid当一个进程终止（正常或异常）时，内核就会向其父进程发送 SIGCHLD 信号。因为子进程的终止是个异步事件（可以在父进程运行的任何时候发生），所以该信号也是内核向父进程发送的异步通知。父进程可以选择忽略该信号（系统默认动作就是忽略），或者提供一个该信号发生时即被调用的函数（信号处理函数）。而可提供的信号处理函数中，就有 wait&#x2F;waitpid。调用它们将：\n\n如果所有子进程都还在运行，则阻塞；\n如果一个子进程已经终止，正等待父进程获取其终止状态，则取得该子进程的终止状态并立即返回；\n如果它没有任何子进程，则立即报错并返回。具体即，如果子进程处于僵死状态，则 wait 立即取得该子进程的状态并返回，否则 wait 使其调用者阻塞，直到有一个子进程终止。如果调用者阻塞而且它有多个子进程，则在其某个子进程终止时，wait 立即返回，返回信息中就包含子进程的 ID 等信息，所以调用者了解是哪个子进程终止了。\n\n两个函数的区别，主要在于是否阻塞调用者：\n\n在一个子进程终止前，wait 使其调用者（该子进程的父进程）阻塞，而 waitpid 有一个选项可以使调用者不被阻塞；\nwaitpid 并不等待在其被调用之后的第一个终止子进程，它有若干选项，可以控制所等待的进程。\n\nwaitid和 waitpid 类似，waitid 允许一个进程指定要等待的子进程，但它使用两个单独的参数表示要等待的子进程所属的类型。\nwait3 wait4大多数 UNIX 系统提供这两个函数，使用附加参数，使得功能上比上述 wait 函数多一个：允许内核返回由终止进程及其所有字进程使用的资源概况，包括用户&#x2F;系统 CPU 使用时间总量、缺页次数、接收到信号的次数等。\n僵尸进程（APUE：Unix 术语中）僵尸进程是指：一个已经终止、但是其父进程尚未对其进行善后处理（获取该终止子进程的有关信息，释放终止状态占用的资源）的进程。进程退出时，内核会释放该子进程所使用的存储区、关闭其打开的文件以及其他清理工作。同时内核为每个终止的进程仍然保留了一定量的信息，如进程 ID、终止状态、使用的总 CPU 时间等，父进程通过调用 wait()&#x2F;waitpid() 可以获取这些信息，直到此时（父进程完成 wait&#x2F;waitpid 调用），这些额外保留的信息才会被释放。如果一个长期进程在执行中 fork 了很多子进程，那么除非父进程等待获取子进程的状态，否则这些子进程终止后都会变成僵死进程。考虑这样的场景：如果父进程一直不调用 wait&#x2F;waitpid，那么终止进程保留的信息就会一直占据一些资源，包括有限的进程号。在僵尸进程数量过大的情况下，就有可能导致系统无法再分配资源给新建进程，危害系统安全。\n避免有两个相关信号 SIGCLD、SIGCHLD，它们的来源不同（SIGCLD 来自 System V，而 SIGCHLD 来自 BSD 和 POSIX.1），处理方式也不同：\n\nBSD SIGCHLD 的语义：当该信号发生时，说明子进程的状态发生了改变，这时需要调用 wait 函数确认状态的变化。\nSystem V 的 SIGCLD 信号处理方式为：\n如果进程设置信号 SIGCLD 的处理动作为 SIG_DFL，即默认的处理方式，不理会这个信号，但是也不会丢弃子进行状态，所以如果不用 wait&#x2F;waitpid 对其子进行进行状态信息回收，会产生僵尸进程；如果进程设置信号 SIGCLD 的处理动作为 SIG_IGN，该进程的子进程将不会变成僵尸进程。这和默认的处理动作（SIG_DFL）是不同的，子进程状态信息会被丢弃，也就是自动回收了，所以不会产生僵尸进程，但问题是，如果随后调用 wait&#x2F;waitpid，也无法捕捉到子进程的状态信息，并且会阻塞到所有的子进程结束，返回错误 ECHILD，也就是没有子进程等待的情况下调用 wait&#x2F;waitpid 的情况。\n\n\n\nSIGCLD语义信号\n孤儿进程即没有父进程的进程（父进程出于某些原因提前终止了），这时候该进程会重新找一个父进程。这个动作由父进程在调用 exit() 退出时，会调用 exit_notify()向其父进程发送信号，并给子进程重新找一个父进程：在当前线程组中寻找，如果失败则转由 init 进程作为父进程。由 init 进程收养的孤儿进程不会变成僵尸进程。init 进程的机制是，无论何时只要有一个子进程终止，init 就会调用 wait 取得其终止状态，也就防止了系统中滞留（init 的子进程造成的）僵死进程。所以从这个角度看，孤儿进程并不会造成什么副作用。\n僵尸进程 孤儿进程\n","categories":["OS"],"tags":["OS","进程"]},{"title":"表","url":"/2018/04/10/MySQL/%E8%A1%A8/","content":"以InnoDB存储引擎表为例。\n索引组织表InnoDB存储引擎中，表都是根据主键顺序组织存放的，称为索引组织表（index organized table）。每张表都有个主键（Primary Key），如果建表时没有显式定义，则按如下顺序选择或创建：\n\n是否有非空的唯一索引（Unique NOT NULL），如有，则选为主键。如果有多个，选择建表时第一个定义的非空唯一索引列；\n自动创建一个6字节大小的指针。\n\n逻辑存储结构所有数据逻辑地存放在一个名为表空间（tablespace）的地方。表空间由段（segment）、区（extent）、页（page）组成（页在一些文档中也成为块（block））。结构大致如下：\n\n\n表空间默认情况下所有数据存放在同一个共享表空间（名为 ibdata1）内。如果启用 innodb_file_per_table 参数，则每张表内的数据单独存放到一个表空间内。但即使启用该参数，每张表的表空间也只是用来存放数据、索引和入缓冲Bitmap页，其它类数据如回滚（undo）信息，插入缓冲索引页、系统事务信息、二次写缓冲（Double Write Buffer）等还是存放在原来的共享表空间内。所以共享表空间还是会不断增大。\n段（segment）常见的段有数据段、索引段、回滚段等。数据段就是B+树的叶子节点（上图的 Leaf node segment），索引段就是B+树的非索引节点（上图的 Non-leaf node segment），回滚段见事务部分。对段的管理都由InnoDB存储引擎自身完成。\n区（extent）由连续页组成的空间，在任何情况下每个区的大小都是1MB。为保证区中页的连续性，InnoDB一次从磁盘申请4~5个区。默认情况下，InnoDB页大小为16KB，即一个区中共有64个连续的页。InnoDB 1.2.x引入 innodb_page_size 参数（一次性设置，不可再次修改），可将默认页大小设置为4K、8K等。\n页（page） &#x2F; 块（block）InnoDB磁盘管理的最小单位。默认页大小为16KB。常见页类型：\n\n数据页（B-tree Node）\nundo页（undo Log Page）\n系统页（System Page）\n事务数据页（Transaction system Page）\n插入缓冲位图页（Insert Buffer Bitmap）\n插入缓冲空闲列表页（Insert Buffer Free List）\n未压缩的二进制大对象页（Uncompressed BLOB Page）\n压缩的二进制大对象页（compressed BLOB Page）\n\n行InnoDB存储引擎是面向行的（row-oriented），即数据是按行进行存放的。每个页存放的行记录最多为 16KB &#x2F; 2 - 200，即7992条（？）。\n分区MySQL5.1 添加了对分区的支持。分区的过程是将一个表或索引分解为多个更小、更可管理的部分。从逻辑上看，用户在访问数据库时，依然只能看到一个表&#x2F;一个索引，但物理层面上这个表&#x2F;索引可能是由数十个物理分区组成，每个分区都是独立的对象，可以独自处理，也可以作为一个更大的对象的一部分进行处理。MySQL 只支持水平分区，不支持垂直分区，且数据库的分区是局部分区，而非全局分区。这几个概念如下：\n\n水平分区：将同一个表中的不同行的记录分配到不同的物理文件中；\n垂直分区：将同一个表中的不同列的记录分配到不同的物理文件中；\n局部分区：一个分区中既存放了数据又存放了索引；\n全局分区：数据存放在各个分区中，但所有数据的索引存放在一个对象中；\n\n分区类型当前 MySQL 支持 4 种类型的分区：\n\nRANGE 分区：行数据基于属于一个给定连续区间的列值被放入分区；\nLIST 分区：和 RANGE 分区类似，只是 LIST 分区面向的是离散的值；\nHASH 分区：根据用户自定义的表达式返回值进行分区，返回值不为负；\nKEY 分区：根据 MySQL 数据库提供的哈希函数进行分区。\n\n分区类型\n子分区在分区的基础上再分区，也称复合分区。MySQL 允许在 RANGE、LIST 类型的分区上再进行 HASH、KEY 类型的子分区。\n分区与性能针对 OLAP（在线分析处理）类型的数据库应用，如数据仓库等，一般查询涉及大型表的扫描，该场景分区确实能有效提高性能；而对于 OLTP（在线事务处理）类型的数据库应用，如博客、电商、网络游戏等，通常都是通过索引获取少量数据，这种情况使用 B+ 树索引管理大型表已经能够获得很好的效率，分区可能提升并不明显甚至会变差。\n分区表行记录格式TBA\n数据页（B-tree Node）TBA\n约束\nInnoDB提供以下几种约束：\nPrimary Key\nUnique Key\nForeign Key\nDefault\nNOT NULL\n\n两种创建方式：\n\n表建立时就进行约束定义；\n利用 ALTER TABLE 命令创建。\n\n约束 vs 索引Primary Key、Unique Key 也是创建索引的方法。当创建了一个唯一索引，也会同时自动创建一个唯一的约束。不同在于，约束更是一个逻辑的概念，用来保证数据的完整性；索引是一个数据结构，既有逻辑上的概念，在数据库中还代表着物理存储的方式。\nENUM 和 SET 约束MySQL不支持传统的CHECK约束，但可以通过ENUM和ET类型解决这种约束需求。例如性别：\nENUMmysql > CREATE TABLE a (\n          -> id INT,\n          -> sex ENUM('male', 'female'));\n\n外键约束外键用来保证参照完整性。InnoDB完整支持外键约束（MyISAM不支持）。一般称被引用的表为父表，引用表为子表。外键定义是的 ON DELETE 和 ON UPDATE 表示在对父表进行 DELETE 和 UPDATE 操作时，对子表所做的操作，有：\n\nCASCADE：对子表中的数据也进行相应操作（DELETE | UPDATE）；\nSET NULL：将子表中的数据更新为 NULL（对应列必须允许为 NULL）；\nNO ACTION：抛出错误，不允许这类操作发生；\nRESTRICT：同上，抛出错误，不允许这类操作发生（默认设置）。\n\n","categories":["DB"],"tags":["DB","MySQL"]},{"title":"MySQL","url":"/2018/04/09/MySQL/MySQL/","content":"[toc]单进程多线程数据库模型。\n相关概念MVCC多版本并发控制。包括 MySQL、Oracle、PostgreSQL 等数据库系统都实现了MVCC，尽管实现机制不尽相同。可以认为 MVCC 是行级锁的一个变种，在很多情况下避免了加锁操作，从而减小开销。实现方式一般为 读操作为非阻塞式的，写操作只锁定必要的行。理想的 MVCC 能够解决幻读问题，但难以实现，因为企图通过乐观锁代替两阶段提交。修改两行数据，但为了保证其一致性，与修改两个分布式系统中的数据并无区别，而两阶段提交是目前这种场景保证一致性的唯一手段。两阶段提交的本质是锁定，乐观锁的本质是消除锁定，二者矛盾，故理想的 MVCC 难以真正在实际中被应用。包括 InnoDB 也只是借了 MVCC 这个名字，提供了非阻塞读，但真正解决幻读问题使用的是 Next-Key Lock。\n[参考]https://blog.csdn.net/chen77716/article/details/6742128\n","categories":["DB"],"tags":["DB","MySQL"]},{"title":"复制 备份","url":"/2018/04/09/MySQL/%E5%A4%8D%E5%88%B6%20%E5%A4%87%E4%BB%BD/","content":"[toc]MySQL 服务可以在一台服务器上启动多个，也可以分布在不同的服务器上。其内建的复制功能是构建大型、高性能、高可用、可扩展、灾难恢复、备份以及数据仓库用程序的基础。使用所谓“水平扩展”架构，通过为服务器配置一个&#x2F;多个备用库（从库）的方式来进行数据同步。\n复制解决的问题数据分布多数据中心，使得数据分布在不同地理位置。\n负载均衡通过复制将数据的读操作分布到多个服务器上，实现对读密集型应用的优化。实现上可以使用 DNS 轮询，也可以添加网络负载均衡解决方案的思路。\n备份复制是备份的技术补充。\n高可用性和故障切换帮助应用避免数据库单点失败，包含复制的故障切换系统能够显著缩短宕机时间。\nMySQL 复制复制方式复制不会增加主库的开销，主要是启用二进制日志的开销。MySQL 支持两种复制方式：\n基于语句的复制也称逻辑复制。主库会记录那些造成数据更改的查询，当备库读取并重放这些事件时，实际上时把主库上执行过的 SQL 在本地再执行一遍。这种方式并不常见。\n\n好处实现简单，并且保持二进制日志里的事件紧凑，所以不会造成太大的带宽压力：语句本身很小，但可能执行数据量很大的操作。\n缺点主要是主库和备库执行语句的时间异步造成的问题。二进制日志中的查询语句外，还包含有时间戳等元数据；有些特殊语句可能无法正确复制；存储过程和触发器在该模式下也可能存在问题；并且更新必须时串行的，这需要更多的锁。\n\n基于行的复制MySQL 5.1 开始支持，跟其他数据库实现比较相似：将实际数据记录到二进制文件中，备库直接读取并重放这些数据。好处是能够正确复制每一行；但该模式很难进行时间点恢复。\n对比二者并不能定性言明孰优孰劣，比如逻辑复制如果语句执行量很大但产生的结果很少，那么显然使用行复制更好；相应如果执行语句开销小于复制大量数据，那么应该使用逻辑复制。所以 MySQL 的实现是，根据需要在这两种复制模式之间动态切换：默认使用基于语句的复制，如果发现语句无法被正确复制，就切换到基于行的复制模式。\n基于 GTID 的复制MySQL 5.6.5 新增的复制方式（但可能到 MySQL 5.7 才真正支持并行复制）。GTID (Global Transaction ID)，一个已提交事务的编号，全局唯一，实际上由 UUID+TID 组成，其中 UUID 是一个 MySQL 实例的唯一标识；TID 代表了该实例上已经提交的事务数量，并且随着事务提交单调递增。采用了新的复制协议：支持以全局统一事务 ID (GTID) 为基础的复制。当在主库上提交事务或者被从库应用时，可以定位和追踪每一个事务。GTID 复制是全部以事务为基础，使得检查主从一致性变得非常简单。如果所有主库上提交的事务也同样提交到从库上，一致性就得到了保证。\n参考：GTID 复制\n步骤概述\n\n在主库上把数据更改记录到二进制日志中（这些记录被称为二进制日志事件）；\n备库将主库上的日志复制到自己的中继日志（Relay Log）中；\n备库读取中继日志中的事件，将其重放到备库数据上。\n\n复制配置基本步骤（新安装配置）此时各服务器上数据一致（都没有或数据相同），然后通过配置主从关系开始复制。\n\n在每台服务器上创建复制账号；\n设置主库和备库；\n通知备库连接到主库并从主库复制数据。\n\n创建复制账号MySQL 会赋予一些特殊权限给复制线程。在备库运行的 I&#x2F;O 线程会建立一个到主库的 TCP&#x2F;IP 连接，这意味着必须在主库创建一个用户，并赋予其合适的权限。备库 I&#x2F;O 线程以该用户名连接到主库并读取其二进制日志。创建语句：\nmysql> GRANT REPLICATION SLAVE, REPLICATION CLIENT ON *.*\n    -> TO repl@'host' IDENTIFIED BY 'password',; \n需要在主库和备库都创建该账号。\n配置主库和备库在主库（server1）上开启一些设置，需要打开二进制日志，并指定一个独一无二的服务器 ID（server ID），在主库的 my.cnf 文件中配置相关项。备库上也需要相似的配置，还有中继日志目录等。\n启动复制告知备库如何连接到主库并重放二进制日志。可以通过配置文件配置，但一般使用”CHANGE MASTER TO”语句设置，后一种方式在后续指向别的主库时无需重启备库。然后执行复制命令。\n从另一台服务器开始复制上面全新安装的配置并非一般情况，更多的是，（新配置安装的）备库从一台已经运行了一段时间的主库复制数据，此时数据是不一致的：主库有数据，备库没有数据。这也可以看作备库的初始化。方法有：\n\n从主库复制数据\n从另一台备库克隆数据 \n使用最近的一次备份数据来启动备库\n\nMySQL 备份复制是备份的手段。\n备份方式按备份操作方式逻辑备份优点\n\n可以用编译器或像 grep 和 sed 之类的命令查看和操作的普通文件；\n恢复简单，非常灵活；\n与存储引擎无关。\n\n缺点\n\n还原时需要 MySQL 加载和解释语句，转化为存储格式，并重建索引，所以会比较慢；\n无法保证导出后再还原出来的一定是同样的数据。浮点数、软件BUG等都会导致问题；\n必须由数据库服务器完成生成逻辑备份的工作，因此要使用更多的CPU周期。\n\n物理备份优点\n\n基于文件的物理备份，只需要将需要的文件复制到其他地方即可完成备份；\n恢复更简单；\n恢复快，因为 MySQL 服务器不需要执行任何SQL或构建索引。\n\n缺点\n\nInnoDB 的原始文件通常比相应的逻辑备份要大得多；\n物理备份不总是可以跨平台、操作系统及 MySQL 版本。文件名大小写敏感和浮点格式可能会遇到麻烦。\n\n按是否备份全部数据\n完全备份\n增量备份\n差异备份一般是组合使用：完全+增量；完全+差异。\n\n备份工具mysqldumpmysqlbinlogXtrabackuphttp://www.cnblogs.com/yuyue2014/p/3650117.html\n","categories":["DB"],"tags":["DB","MySQL"]},{"title":"存储过程","url":"/2018/04/09/MySQL/%E5%AD%98%E5%82%A8%E8%BF%87%E7%A8%8B/","content":"[toc]\n相关概念MVCC多版本并发控制。包括 MySQL、Oracle、PostgreSQL 等数据库系统都实现了MVCC，尽管实现机制不尽相同。可以认为 MVCC 是行级锁的一个变种，在很多情况下避免了加锁操作，从而减小开销。实现方式一般为 读操作为非阻塞式的，写操作只锁定必要的行。理想的 MVCC 能够解决幻读问题，但难以实现，因为企图通过乐观锁代替两阶段提交。修改两行数据，但为了保证其一致性，与修改两个分布式系统中的数据并无区别，而两阶段提交是目前这种场景保证一致性的唯一手段。两阶段提交的本质是锁定，乐观锁的本质是消除锁定，二者矛盾，故理想的 MVCC 难以真正在实际中被应用。包括 InnoDB 也只是借了 MVCC 这个名字，提供了非阻塞读，但真正解决幻读问题使用的是 Next-Key Lock。\n[参考]https://blog.csdn.net/chen77716/article/details/6742128\n","categories":["DB"],"tags":["DB","MySQL"]},{"title":"范式","url":"/2018/04/09/MySQL/%E8%8C%83%E5%BC%8F/","content":"[toc]关系数据库设计的目标是生成一组关系模式，使得存储信息时避免不必要的冗余，从而可以更方便高效地获取数据。其实现方式是使设计 满足适当的范式。范式用来描述 属性间依赖关系规范化程度。\n\n一个低一级范式的关系模式通过模式分解（Schema Decomposition）可以转换为若干个高一级范式的关系模式，这个过程叫做 规范化。\n第一范式 1NF定义：如果一个关系模式 R 的所有属性的域都是 原子的，则 R 属于第一范式。原子的域，即该域的元素被认为是不可再分割的单元。比如名字一般包含 last name、first name，就不是原子的；地址一般包含 city、zip 等，也不是原子域。\n第二范式 2NF定义：若 R ∈ 1NF，且每个非主属性完全函数依赖于任何一个候选码，则 R ∈ 2 NF。\n第三范式 3NF","categories":["DB"],"tags":["DB","MySQL"]},{"title":"触发器","url":"/2018/04/09/MySQL/%E8%A7%A6%E5%8F%91%E5%99%A8/","content":"[toc]\n相关概念MVCC多版本并发控制。包括 MySQL、Oracle、PostgreSQL 等数据库系统都实现了MVCC，尽管实现机制不尽相同。可以认为 MVCC 是行级锁的一个变种，在很多情况下避免了加锁操作，从而减小开销。实现方式一般为 读操作为非阻塞式的，写操作只锁定必要的行。理想的 MVCC 能够解决幻读问题，但难以实现，因为企图通过乐观锁代替两阶段提交。修改两行数据，但为了保证其一致性，与修改两个分布式系统中的数据并无区别，而两阶段提交是目前这种场景保证一致性的唯一手段。两阶段提交的本质是锁定，乐观锁的本质是消除锁定，二者矛盾，故理想的 MVCC 难以真正在实际中被应用。包括 InnoDB 也只是借了 MVCC 这个名字，提供了非阻塞读，但真正解决幻读问题使用的是 Next-Key Lock。\n[参考]https://blog.csdn.net/chen77716/article/details/6742128\n","categories":["DB"],"tags":["DB","MySQL"]},{"title":"锁","url":"/2018/04/09/MySQL/%E9%94%81/","content":"[toc]\n锁锁是数据库系统区别于文件系统的一个关键特性。锁机制用于管理对共享资源的并发访问，提供数据的 完整性和一致性。多用户、数据库驱动的应用中，很大的一个难点是：一方面要最大程度地利用数据库的并发访问，一方面要确保每个用户能以一致的方式读取和修改数据。为此有了锁（locking）机制。\n不同数据库的锁实现机制一般不同MySQL 中，MyISAM 引擎使用表锁，并发读没有问题，但并发插入的性能就要差很多了。InnoDB 引擎提供一致性的非锁定读、行级锁支持。行级锁没有相关额外的开销，并可以同时得到并发性和一致性。\nMySQL 锁MySQL 中共有 4 种锁。\n\n表锁\n页锁\n行锁（少数独立存储引擎才有，如 InnoDB）\n元数据锁：5.5 版本加入的新特性。仅对表中的元数据启用，当有线程开始使用表时，元数据锁就会锁住表的所有元数据。\n\n元数据DDL 语句的更改信息，如 CREATE、DROP、ALTER 等修改方案的语句。老版本中引入元数据是为了解决线程可以在其他线程中的并发事务使用相同表的情况下修改表定义或是删除表的问题。\nlatch 和 lock这是锁中容易混淆的两个概念。两者都可以称为“锁”。\n\nlatch 一般称为闩锁（轻量级的锁），对象是线程，因为其要求锁定的时间必须非常短，若持续时间长，则应用的性能会非常差，InnoDB 中，latch 又分为 mutex（互斥量）和 rwlock （读写锁）。目的是用来保证并发线程操作临界资源的正确性，通常没有死锁检测的机制；\nlock 的对象是事务，用来锁定的是数据库中的对象，如表、页、行等，一般 lock 的对象仅在事务 commit&#x2F;rollback 后进行释放（不同事务隔离级别释放的时间可能不同），有死锁检测机制。\n\nInnoDB 中的锁类型标准行级锁InnoDB 提供两种标准的行级锁：\n\n共享锁（S Lock）：允许事务读一行数据；\n排他锁（X Lock）：允许事务删除或更新一行数据；\n\n锁兼容（Lock Compatible）：如果一个事务 T1 已经获得了行 r 的共享锁，那么另外的事务 T2 可以立即获得行 r 的共享锁，因为读取并不会改变行 r 的数据，这种情况就是锁兼容。S 和 X 都是行锁，兼容是指对同一行记录（row）锁的兼容性情况。\n行级锁优缺点InnoDB 行锁效率很高，占用内存也很少，但细粒度的行锁在锁定的时候仍然会带来额外开销，比表锁、页锁消耗的内存要多；细粒度意味着锁的请求数量可能较多，而较多的锁会占用资源，降低性能；在执行对大部分数据的 GROUP BY 操作或频繁扫描很多数据时，性能会明显下降。\n意向锁（表级）InnoDB 支持多粒度（granular）锁定，允许 事务在行级上的锁和表级上的锁同时存在。为此，InnoDB 支持一种额外的 表级别锁——意向锁。可以理解为意向锁将锁定的对象分为多个层次，意味着事务希望在更细粒度（fine granularity）上进行加锁，先要在粗粒度上加相应的意向锁，以表明在接下来的动作想要获取该记录的锁。如果将上锁的对象看成一棵树，那么对最下层的对象上锁，也就是对最细粒度的对象进行上锁，则首先需要对粗粒度的对象上锁。如，对页上的记录 r 上 X 锁，那么分别要对数据库A、对应表、对应页上意向锁 IX，最后对记录 r 上 X 锁。如果其中任何一个部分导致等待，那么该操作需要等待粗粒度锁的完成才能继续。\n\n意向锁作为表级锁，其设计目的是为了在一个事务中揭示下一行将被请求的锁类型。意向锁的枷锁过程是自动的，无需用户干预。InnoDB 支持两种意向锁：\n\n意向共享锁（IS Lock）：事务想要获得一张表中某几行的共享锁；\n意向排他锁（IX Lock）：事务想要获得一张表中某几行的排他锁。\n\n由于 InnoDB 支持的是行级别的锁，因此意向锁不会阻塞除全表扫描以外的任何请求。锁的兼容性如下：\n\n\n一致性非锁定读（Consistent Nonlocking Read）指 InnoDB 通过行多版本控制（multi versioning）的方式来读取当前执行时间数据库中行的数据。如果读取的行正在执行 DELETE 或 UPDATE 操作，这时读取操作不会因此去等待行上的锁释放。而是，InnoDB 会去读取该行的一个快照数据：\n\n之所以称之为非锁定读，因为不需要等待访问的行上 X 锁的释放。快照数据是指该行的之前版本的数据，一个行记录可能有不止一个快照数据，该实现是通过 undo 段来完成，而 undo 用来在事务中回滚数据，因此快照数据本身没有额外开销。此外，读取快照数据不需要上锁，因为没有事务需要对历史数据进行修改操作。非锁定读机制极大提高了数据库的并发性，这是 InnoDB 默认设置下的读取方式。但在不同事务隔离级别下，读取的方式不同：\n\nREAD COMMITTED：总是读取行的最新版本，锁定则读最新快照版本；\nREPEATABLE：总是读取事务开始时的行数据。\n\n一致性锁定读对于增删改语句，InnoDB 会自动给涉及的数据集加排他锁，而对普通的 SELECT 语句则不会加任何锁。某些情况下如典型的事务、存储过程等，用户需要显式地对数据库读取操作加锁，以保证数据逻辑的一致性。InnoDB 对于 SELECT 语句支持两种一致性的锁定读（Locking Read）操作：\n\nSELECT…FOR UPDATE：对读取的行记录加一个 X 锁，\nSELECT…LOCK IN SHARE MODE：对读取的行记录加一个 S 锁。\n\n上述语句必须在一个事务中，当事务提交了，锁也就释放了。因此要加上  BEGIN，START TRANSACTION 或 SET AUTOCOMMIT&#x3D;0。\n外键和锁InnoDB 中，如果外键列没有显式添加索引，则自动对其添加一个索引，以避免表锁。\n锁算法InnoDB 由 3 种行锁算法：\n\nRecord Lock：单个行记录上的锁，总是锁住索引记录，如果表上没有索引，则使用隐式的主键进行锁定；\nGap Lock：间隙锁，锁定一个范围，但不包含记录本身；\nNext-Key Lock：Record Lock + Gap Lock，锁定一个范围，并锁定记录本身。能够解决幻读问题。当查询的索引含有唯一属性时，InnoDB 会将其优化降级为 Record Lock，即仅锁住索引本身而不再是范围。\n\nNext-Key 锁当我们用范围条件（而非相等条件）检索数据并请求锁时，InnoDB 会给符合条件的已有数据记录项加锁，对于键值在条件范围内但并不存在的记录，叫做“间隙（Gap）”，InnoDB 也会对这个间隙加锁，这就是所谓的 Next-Key 锁机制。如，emp 表有 101 条记录，其 empid 值分别为 1、2、3…101，则以下语句：\nSELECT * FROM emp WHERE empid > 100 FOR UPDATE;\n这条查询语句就是范围检索，InnoDB 不仅会对符合条件的 empid 记录，这里只有 101 一行加锁，也会对 empid &gt; 100 的“间隙”加锁，尽管并不存在这样的数据，但考虑这样一个场景，如果其他事务试图插入 empid &gt; 100 的数据，此时就不会成功，因为该范围被锁定，插入操作会失败。而如果不采取该锁机制，则插入有可能会成功，就会出现幻读现象。显然，这种锁机制会阻塞符合条件查询内键值的并发插入，这往往造成严重的锁等待和性能问题，因此，在并发场景下，应该考虑优化业务逻辑，尽量使用相等条件进行检索，避免范围检索。但要注意一个问题：如果使用相等条件查询，而查询结果不存在这样的记录，那么 InnoDB 会使用 Next-Key 锁，这就意味着，几乎将全部的范围都锁定了。\n_事务隔离级别为 READ COMMITTED 时，仅采用 Record Lock_。\n锁导致的问题因为事务隔离性的要求，锁只会带来三种问题：\n\n脏读\n不可重复读\n丢失更新\n\n阻塞指由于不同锁之间的兼容性关系，在有些时刻一个事务中的锁需要等待另一个事务中的锁释放它所占用的资源。阻塞并不是一件坏事，是为了确保事务可以并发且正常执行。超时会跑出1205错误。调整参数↓innodb_lock_wait_timeout：设置等待时间（默认50秒），可动态调整；innodb_rollback_on_timeout：设置是否在等待超时时对进行中的事务进行回滚操作（默认OFF，不回滚），静态的，不可在启动时修改。\n死锁解决死锁最简单的方式是不要有等待，将任何的等待都转化为回滚，并且重新开始事务。然而这将导致并发性能的下降甚至所有的事务都无法进行。另一种解决方法是超时，即当事务相互等待时，当其中一个事务等待时间超过设置的阈值，进行回滚操作，这时其它事务就有可能继续执行。InnoDB中超时设置参数：innodb_lock_wait_timeout（默认50秒）。超时机制虽然简单，但若超时的事务所占权重较大，如操作更新了很多行，占用了较多的 undo log，此时回滚该事务的时间相比于其它事务所占用的时间可能更多。因此除了超时机制外，当前数据库普遍采用 wait_for graph（等待图）的方式来进行死锁检测。较之超时的解决方案，这是一种更为主动的死锁检测方式。等待图要求数据库保存以下两种信息：\n\n锁的信息链表；\n事务等待链表；\n\n通过上述链表构造出一张图，如果这个图中存在回路，就代表存在死锁，此时 InnoDB 选择一个 undo 量最小的事务进行回滚，并报告一个立即可见的错误，如果不能解除死锁，则继续选择回滚，直到死锁解除。等待图的死锁检测通常采用深度优先的非递归算法实现（1.2.x版本之后，之前采用递归的深度优先算法实现）。\n乐观锁 vs 悲观锁互斥同步、非互斥同步，并发控制技术手段上的概念。乐观锁（Optimistic Lock）假设数据一般情况下不会发生并发冲突，所以在数据进行提交更新的时候，才会正式对数据的冲突与否进行检测。如果冲突，则返回错误，让用户决定如何去做，这意味着乐观锁不能解决脏读问题，其实现算是一种 CAS 操作。其实现：\n\n使用数据版本记录机制实现。为数据增加一个版本标识，如“version”，每更新一次数据，则对标识进行一次累加操作。\n时间戳（timestamp）记录机制：在更新提交的时候检查当前数据库中数据的时间戳和自己更新前取到的时间戳进行对比，如果不一致则冲突。\n\n适用于多读少写的场景，可以提高吞吐率。\n悲观锁（Pessimistic Lock）假定数据会发生并发冲突，从而以预防冲突的方式屏蔽可能违反数据完整性的冲突操作。简言之就是每次读写数据都认为会被其他线程修改，所以都需要先上锁。java synchronized 就属于悲观锁的一种实现。\n","categories":["DB"],"tags":["DB","MySQL"]},{"title":"事务","url":"/2018/04/09/MySQL/%E4%BA%8B%E5%8A%A1/","content":"事务（Transaction） 是数据库区别于文件系统的重要特性之一。事务会把数据库从一种一致状态转变为另一种一致状态：提交工作时，可以确保所有修改要么都被保存好了，要么都不保存。\nACID 特性\n原子性（Atomicity）：指数据库的事务是不可分割的工作单位，即事务中任何一个SQL语句执行失败，已经成功的部分也必须撤销，数据库会退到执行事务之前的状态；\n一致性（Consistency）：指事务将数据库从一种一致状态转变为下一种一致状态，在事务开始前和结束后，数据库的完整性约束没有被破坏，如列值的唯一性等；\n隔离性（Isolation）：也称并发控制（Concurrency Control）、可串行化（Serializability）、锁（Locking）等。要求每个读写事务的对象对其它事务的操作对象之间能够相互分离，即该事务提交前对其它事务都不可见，通常使用锁来实现。当前数据库系统都提供了一种粒度锁（Granular Lock）的策略，允许事务仅锁住一个实体对象的子集，以此来提高事务的并发度；\n持久性（Durability）：事务一旦提交，其结果就是永久性的，即使发生宕机等故障，数据库也能将数据恢复。持久性保证事务系统的高可靠性（High Reliability），但不能保证高可用性（High Availability）：_从事务本身的角度保证结果的永久性，但无法避免数据库本身的故障，如RAID卡损坏、自然灾害等_；\n\n_尽管理论上事务的定义需要满足这四个特性，但数据库厂商出于各种目的并不一定会完全遵循该准则_。\n事务分类从事务理论的角度来说，可以把事务分为以下几个类型：\n扁平事务（Flat Transactions）最简单的一种，也是实际生产环境中使用最为频繁的。所有操作都处于同一层次，由 BEGIN WORK 开始，由 COMMIT WORK &#x2F; ROLLBACK WORK 结束，其间的操作都是原子的——要么都执行，要么都回滚。是应用程序成为原子操作的基本组成模块。三种执行结果如下：\n\n\n带有保存点的扁平事务（Flat Transactions with Savepoints）允许事务执行过程中回滚到同一事务中较早的一个状态——某些事务可能在执行过程中出现的错误并不会导致所有的操作都无效，放弃整个事务不合乎要求，开销也太大。保存点（Savepoint）用来通知系统应该记住事务当前的状态，以便之后发生错误时，事务能回滚到保存点的状态。（扁平事务隐式在起始点设置一个保存点，即只能回滚到事务开始的状态）。保存点用 SAVE WORK 函数来建立。在发生系统崩溃时会丢失所有保存点，因为保存点是易失的（Volatile），而非持久的（Persistent），这意味着进行恢复时，事务需要从开始处重新执行而不能从最近的一个保存点继续执行。\n\n\n链事务（Chained Transactions）可以看作保存点模式的一个变种。在提交事务时，释放不需要的数据对象（如事务所持有的锁），将必要的处理上下文隐式地传给下一个要开始的事务（提交事务操作和开始下一个事务操作将合并为一个原子操作）。这意味着，下一个事务将看到上一个事务的结果，就好像在一个事务中进行的一样：\n\n链事务的回滚仅限于当前事务，即只能恢复到最近一个保存点。\n嵌套事务（Nested Transactions）层次结构框架，由一个顶层事务（top-level transaction）控制各个层次的事务，之下嵌套的事务称为子事务（subtransaction），其控制每一个局部的变换。\n\n嵌套事务的定义\n\n由若干事务组成的一棵树，子树既可以是嵌套事务，也可以是扁平事务；\n处在叶节点的事务是扁平事务，但每个子事务从根到叶节点的距离可以不同；\n位于根节点的事务称为顶层事务，其他事务为子事务。事务的前驱（predecessor）称为父事务（parent），下一层称为子事务（child）；\n子事务既可以提交也可以回滚，但它的提交操作并不会马上生效，除非其父事务已经提交。因此，任何子事务都在顶层事务提交后才真正的提交；\n树中的任意一个事务的回滚都会引起它的所有子事务一同回滚，因此，子事务仅保留 A、C、I 特性，不具有 D 的特性。\n\n在Moss的理论中，实际的工作是交由叶子节点完成的，即只有叶子节点的事务才能才能访问数据库、发送信息、获取其他类型的资源。而高层的事务仅负责逻辑控制，决定何时调用相关的子事务。即使一个系统不支持嵌套事务，用户也可以通过保存点技术来模拟嵌套事务：\n\n\n分布式事务（Distributed Transactions）通常是一个在分布式环境下运行的扁平事务，因此需要根据数据所在位置访问网络中的不同节点。分布式事务处理的关键是必须有一种方法可以知道事务在任何地方所做的所有动作，提交或回滚事务的决定必须产生统一的结果（全部提交或全部回滚）。假如一个用户在 ATM 机上进行银行的转账操作，例如持卡人从招商银行存储卡转账 10000 元到工商银行的存储卡。这种情况下，可以将 ATM 机视为节点 A，招商银行的后台数据库视为节点 B，工商银行的后台数据库视为 C，这个转账的操作可分解为以下的步骤：\n\n\n节点 A 发出转账命令\n节点 B 执行存储卡中的余额减去 10000\n节点 C 执行存储卡终端的余额增加 10000\n节点 A 通知用户操作完成或者节点 A 通知用户操作失败\n\n\n这里需要使用到分布式事务，因为节点 A 不能通过一台数据库就完成任务，其需要访问网络中两个节点的数据库，而在每个节点的数据库执行的实务操作又都是扁平的，对于分布式事务，其同样需要满足 ACID 特性，要么都发生，要么都失效。对于上述例子，如果 2、3 步中任何一个操作失败，都会导致整个分布式事务回滚，若非这样，结果不可预知。\nInnoDB 支持的事务类型InnoDB存储引擎支持扁平事务、带有保存点的事务、链事务、分布式事务。MySQL数据库、InnoDB存储引擎都不原生支持嵌套事务，可通过带有保存点的扁平事务来模拟串行的嵌套事务。注意，使用分布式事务时，InnoDB 的事务隔离级别必须设置为 SERIALIZABLE。\n事务的实现事务的原子性、一致性、持久性通过数据库的 redo log 和 undo log 完成。redo log 称为重做日志，用来保证事务的原子性、持久性，undo log 用来保证事务的一致性。事务的隔离性由锁来实现。_undo 不是 redo 的逆过程_。redo 和 undo 都可以看作是一种恢复操作，redo 恢复提交事务修改的页操作，undo 回滚行记录到某个特定版本：两者记录的内容不同，并且 redo 通常是物理日志，记录的是页的物理修改操作，undo 是逻辑日志，根据每行记录进行记录。\nredo重做日志记录了事务的行为，由两部分组成：内存中的重做日志缓冲（redo log buffer），易失的；重做日志文件（redo log file），持久的物理保存。都是以512字节的块进行存储：重做日志块（redo log block）。通过 Force Log at Commit 机制实现事务的持久性，即当事务提交（commit）时，必须先将该事务的所有日志写入到重做日志文件进行持久化，待事务的commit操作完成才算完成。这里的日志分为两部分：redo log 和 undo log。redo log 基本是顺序写的，在数据库运行时不需要对 redo log 的文件进行读取操作，undo log 是需要进行随机读写的。为确保日志写入重做日志文件，重做日志缓冲写入文件系统缓存后，会进行一次fsync操作，以将缓冲写入磁盘文件，该同步操作的参数 innodb_flush_log_at_trx_commit 可以手动设置：\n\n1（默认）：事务提交时必须调用一次fsync操作；\n0：事务提交时不调用fsync，而是放到 master thread 中完成（默认每秒调用一次）；\n2：仅写入文件系统缓存，不进行fsync操作。宕机情况下会丢失未刷新到磁盘日志文件的那部分事务。\n\nundo对事务进行回滚操作。与redo存放在重做日志文件中不同，undo存放在数据库内部的一个特殊段（segment）中，这个段称为undo段（undo segment），位于共享表空间内。undo 是逻辑日志，只是将数据库逻辑地恢复到原来的样子，所有的修改都被逻辑地取消了：对于每个 INSERT，回滚执行一个 DELETE，相应的 DELETE、UPDATE也是同样执行一个相反的操作，将修改前的行放回去。除了回滚操作，另一个作用是完成 MVCC：当拥护读取一行记录时，若该记录已经被其它事务占用，当前事务可以通过undo读取之前的行版本信息，以此实现非锁定读。_uodo log 会产生 redo log，也就是 uodo log 的产生会伴随这 redo log 的产生，因为 undo log 也需要持久性的保护_。\nuodo log 格式InnoDB 中，undo log 分为：insert undo log：在 INSERT 操作中产生的 undo log。因为 INSERT 操作记录只对本事务可见（隔离性的要求），对其它事务不可见，所以可以在事务提交后直接删除；update undo log：在 DELETE、UPDATE 操作中产生的 undo log，该 undo log 需要提供 MVCC 机制，因此不能在事务提交时就删除，提交时放入 undo log 链表，等待 purge 线程进行最后的删除。\npurge用于最终完成 DELETE、UPDATE 操作。DELETE、UPDATE 操作可能不直接删除原有数据，可以仅将该行主键的 delete flag 设置为 1，行记录本身暂时不执行删除操作，而是延时到最终的 purge 操作中完成。这样设计是因为 InnoDB 支持 MVCC，所以记录不能在事务提交时立即进行处理。这时其它事务可能正在引用这行，故需要保存记录之前的版本。若该行记录已经不被任何其它事务引用，即可进行真正的删除操作。\ngroup commit为提高磁盘 fsync 操作的效率，数据库提供 group commit 功能使得一次 fsync 操作可以刷新多个事务日志到磁盘文件。\n概念XA 规范XA 是 X&#x2F;Open DTP 组织（X&#x2F;Open DTP group）定义的交易中间件与数据库之间的接口规范（即接口函数），交易中间件用它来通知数据库事务的开始、结束以及提交、回滚等。 XA 接口函数由数据库厂商提供（MySQL、Oracle、SQL Server、DB2等数据库都本地支持）。在这个模型中，包括：\n\n应用程序（Application Program）：定义事务的边界，指定全局事务中的操作；\n事务管理器（Transaction Manager）：协调参与全局事务中的各个事务，需要和参与全局事务的所有资源管理器进行通信；\n资源管理器（Resource Managers）：提供访问事务资源的方法，通常一个数据库就是一个资源管理器。\n通信资源管理器（CRM）。\n\n两阶提交协议和三阶提交协议就是根据这一思想衍生出来的。可以说两阶段提交其实就是实现 XA 分布式事务的关键(两阶段提交主要保证了分布式事务的原子性)。\n两阶段提交协议two phase commit protocol，2PC。在计算机网络以及数据库领域内，为了使基于分布式系统架构下的所有节点在进行事务提交时保持一致性而设计的一种算法(Algorithm)。在分布式系统中，每个节点虽然可以知晓自己的操作时成功或者失败，却无法知道其他节点的操作的成功或失败。当一个事务跨越多个节点时，为了保持事务的 ACID 特性，需要引入一个作为协调者的组件来统一掌控所有节点(称作参与者)的操作结果并最终指示这些节点是否要把操作结果进行真正的提交(比如将更新后的数据写入磁盘等等)。因此，两阶段提交的算法思路可以概括为：参与者将操作成败通知协调者，再由协调者根据所有参与者的反馈情报决定各参与者是否要提交操作还是中止操作。\n所谓的两个阶段是指：第一阶段：准备阶段(投票阶段)和第二阶段：提交阶段（执行阶段）。\n准备阶段事务管理器（事务协调者）给每个资源管理器（事务参与者）发送 Prepare 消息，每个参与者要么直接返回失败（如权限验证失败），要么在本地执行事务，并且写本地的 redo 和 undo 日志，但不提交，而是处于一种“准备好了”的状态：\n\n协调者向所有参与者询问是否可以执行提交操作（vote），并开始等待它们的响应；\n参与者执行询问发起为止的所有事务操作，并将 undo 和 redo 信息写入日志；\n各参与者响应协调者发起的询问，如果参与者成功执行事务操作，返回“同意”，否则返回“终止”。\n\n提交阶段如果协调者收到了（任一）参与者的失败消息或者超时，那么直接给每个参与者发送回滚（Rollback）消息；否则，发送提交（Commit）消息。参与者根据收到的指令执行回滚&#x2F;提交操作，随之释放所有事务处理过程中使用的锁资源(必须在最后阶段释放锁资源)。不管最后结果如何，第二阶段都会结束当前事务。\n提交\n如果进入提交阶段（所有参与者都返回的是“同意”消息）：\n\n协调者节点向所有参与者节点发出“正式提交(commit)”的请求。\n参与者节点正式完成操作，并释放在整个事务期间内占用的资源。\n参与者节点向协调者节点发送”完成”消息。\n协调者节点受到所有参与者节点反馈的”完成”消息后，完成事务。\n\n回滚\n如果任一参与者节点在第一阶段返回的响应消息为”中止”，或者 协调者节点在第一阶段的询问超时之前无法获取所有参与者节点的响应消息时：\n\n协调者节点向所有参与者节点发出“回滚操作(rollback)”的请求。\n参与者节点利用之前写入的 undo 信息执行回滚，并释放在整个事务期间内占用的资源。\n参与者节点向协调者节点发送“回滚完成”消息。\n协调者节点受到所有参与者节点反馈的“回滚完成”消息后，取消事务。\n\n容错\n协调者正常，参与方 crash若参与方在准备阶段 crash，则协调者收不到 Prepared 回复，协调方不会发送 commit 命令，事务不会真正提交。若参与方在提交阶段提交，当它恢复后可以通过从其它参与方或者协调方获取事务是否应该提交，并作出相应的响应。\n协调者 crash，参与者正常可以通过选出新的协调者解决。\n协调者和参与方都 crash两阶段提交无法完美解决。尤其是当协调者发送出 commit 命令后，唯一收到 commit 命令的参与者也 crash，此时其它参与方不能从协调者和已经 crash 的参与者那儿了解事务提交状态。但如同上一节两阶段提交前提条件所述，两阶段提交的前提条件之一是所有 crash 的节点最终都会恢复，所以当收到 commit 的参与方恢复后，其它节点可从它那里获取事务状态并作出相应操作。\n\n存在的问题\n同步阻塞问题执行过程中，所有参与节点都是事务阻塞型的。当参与者占有公共资源时，其他第三方节点访问公共资源不得不处于阻塞状态。\n单点故障由于协调者的重要性，一旦协调者发生故障。参与者会一直阻塞下去。尤其在第二阶段，协调者发生故障，那么所有的参与者还都处于锁定事务资源的状态中，而无法继续完成事务操作（如果是协调者挂掉，可以重新选举一个协调者，但是无法解决因为协调者宕机导致的参与者处于阻塞状态的问题）。\n数据不一致在二阶段提交的阶段二中，当协调者向参与者发送commit请求之后，发生了局部网络异常或者在发送 commit 请求过程中协调者发生了故障，这回导致只有一部分参与者接受到了 commit 请求。而在这部分参与者接到commit请求之后就会执行 commit 操作。但是其他部分未接到 commit 请求的机器则无法执行事务提交。于是整个分布式系统便出现了数据部一致性的现象。\n无法解决的问题：协调者再发出 commit 消息之后宕机，而唯一接收到这条消息的参与者同时也宕机了。那么即使协调者通过选举协议产生了新的协调者，这条事务的状态也是不确定的，没人知道事务是否被已经提交。\n\n三阶段提交协议three phase commit protocol，3PC。2PC 的改进版。3PC 主要解决的单点故障问题，并减少阻塞。\n[参考]http://www.hollischuang.com/archives/681\n","categories":["DB"],"tags":["DB","MySQL"]},{"title":"事务隔离","url":"/2018/04/09/MySQL/%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB/","content":"[toc]\n数据库操作面临的问题\n更新丢失两个事务同时更新某一行数据，可能会导致一个事务的更新将另一个事务的更新给覆盖了的情况。这是因为没有锁，导致事务没有正确隔离开。当前多数数据库事务隔离的最低级别也都能保证不会发生更新丢失问题。\n\n脏读指当一个事务正在访问数据，并且对数据进行了修改，而这种修改还没有提交到数据库中，此时，另外一个事务也访问了这个数据，然后使用了这个数据。由于这个数据是还没有提交的数据，那么另外一个事务读到的这个数据就是脏数据，依据脏数据所做的操作可能是不正确的。\n\n不可重复读指在一个事务中，多次取读同一数据集合，在这个事务还没有结束时，另一个事务也访问该数据集合，并且做了一些 DML 操作。那么，在第一个事务中的两次读取数据之间，由于第二个事务的修改，导致两次读到的数据可能是不一致的。这样就发生了在一个事务中两次读到的同一数据却不一样的情况，即不可重复读。脏读读取的是未提交的数据，而不可重复读读取的是已提交的数据，但该提交违反了数据库事务的 一致性 要求。\n\n幻读指当事务不是独立执行时发生的一种现象：如一个事务对一个表中的数据进行了修改，这种修改涉及到表中的全部数据行，同时，另一个事务也修改这个表中的数据，其操作是插入&#x2F;删除一行数据。那么，第一个事务就会发现表中的数据没有被完全修改，好像发生了幻觉一样，即幻读。\n\n\n为了避免以上情况，标准 SQL 规范中定义了 4 个事务隔离级别。不同隔离级别对事务的处理不同。\n隔离级别SQL 标准定义了四个隔离级别：\nREAD UNCOMMITTED未提交读&#x2F;未授权读。不允许丢失更新，但允许脏读。如果一个事务已经开始写数据，则其他事务不允许同时进行写操作，但允许其他事务读取该数据。该隔离级别可通过 排他写锁 实现。\nREAD COMMITTED提交读&#x2F;授权读。不允许脏读，但允许不可重复读。可通过 瞬间共享读锁 和 排他写锁 实现。读取数据的事务允许其他事务继续访问该数据，但是未提交的写事务将会禁止其他事务访问该行。\nREPEATABLE READ可重复读。不允许不可重复度，有可能出现幻读。可通过 共享读锁 和 排他写锁 实现。读取数据的事务不允许其他写事务，允许其他读事务；写事务不允许其他任何事务。\nSERIALIZABLE可串行化。提供最高级别的事务隔离，它强制事务序列化执行（可以看作串行），事务只能一个接一个地执行，不能并发执行。仅仅通过“行级锁”是无法实现事务序列化的，必须通过其他机制保证新插入的数据不会被刚执行查询操作的事务访问到。\n事务的隔离级别越高，越能保证数据访问的完整性和一致性，相应地对并发性能的影响也越大。对于多数应用程序，可以优先考虑把数据库系统的隔离级别设置为 Read Commited，它能够避免脏读，且具有较好的并发性能，尽管可能会导致不可重复读、幻读等并发问题，但在这些场景下由应用程序采用乐观锁&#x2F;悲观锁，能够有效控制并发问题。\nMySQL 事务隔离级别InnoDB 默认的隔离级别是 REPEATABLE READ，与标准 SQL 不同的是，该级别下，InnoDB 使用 Next-Key Lock 锁算法避免幻读的产生。所以在该级别下已经完全能够保证事务的隔离性要求，即达到 SQL 标准的 SERIALIZABLE 隔离级别。MVCC 的具体实现一般很难达到（解决幻读问题）要求，所以各数据库采用了不同的方案，InnoDB 存储引擎采用 Next-Key Lock 锁算法来解决幻读问题。隔离级别越低，事务请求的锁越少或保持锁的时间越短。SERIALIZABLE 隔离级别几乎不会带来性能问题，同样地，即使使用 READ COMMITTED 的隔离级别，也不会得到性能的大幅度提升。\n相关概念脏页指缓冲池中已经被修改的页，但还没有刷新回磁盘，即数据库实例内存中的页和磁盘中的页的数据是不一致的。对脏页的读取是正常现象，因为数据库实例内存到磁盘是异步的，这并不影响数据的一致性（或者说二者最终会达到一致性，即当脏页都刷新回磁盘）。这里的异步刷新并不影响数据库的可用性，因此可以带来性能的提高。\n脏数据指事务对缓冲池中行记录的进行修改，但修改还没有被提交（commit）。读脏数据（脏读）就不同了，由于脏数据是某个事务还未提交的已修改数据，此时能被其他事务读取到，显然违背了事务的隔离性。\nhttps://blog.csdn.net/claram/article/details/51646808\n","categories":["DB"],"tags":["DB","MySQL"]},{"title":"视图","url":"/2018/04/06/MySQL/%E8%A7%86%E5%9B%BE/","content":"视图（View）是一个命名的虚表，由 SELECT 查询语句定义，没有实际的物理存储，不存放任何数据，只包含从其他表检索出来的数据。意即，视图本身是从其他表中由 SQL 查询语句生成的。视图和表在同一个命名空间，除了不能对视图创建索引、触发器等操作，MySQL在很多地方将视图和表同等对待：比如执行 SELECT 操作、过滤、排序、联结到其他表&#x2F;视图等。\n视图的好处：\n\n重用SQL语句；\n简化复杂的SQL操作；\n使用表的一部分而不是整个表；\n保护数据。授予用户特定部分的访问权限而不是整个表的；\n更改数据格式和表示：视图可返回与底层的格式和表示不同的数据。etc.\n\n视图可以更新，意即通过视图的定义更新其基表（视图本身没有数据）。但如果视图含有如下操作，则不能进行更新：\n\n分组（GROUP BY、HAVING)；\n联结；\n子查询；\n并；\n聚集函数（Mina()、Count()、Sum()等；\nDISTINCT;\n导出（计算）列。etc.\n\nMySQL不支持物化视图。但可以通过定时将视图导入到新建表的方式模拟物化视图功能（对于ON DEMAND）；或者使用触发器定时导入新建表的方式物化ON COMMIT视图。\n定义视图时，可以在视图名后面括号内为列设置别名。\n使用视图时，只能引用在该视图定义里列出的那些列。\n每次使用视图，都必须处理查询执行时所需的任一个检索，所以可能导致性能问题。\n","categories":["DB"],"tags":["DB","MySQL"]},{"title":"存储引擎","url":"/2018/04/06/MySQL/%E5%AD%98%E5%82%A8%E5%BC%95%E6%93%8E/","content":"MySQL 架构MySQL 体系结构如图所示：\n\n由上图可以看出，MySQL由以下几部分组成：\n\n连接池组件；\n管理服务和工具组件；\nSQL 接口组件；\n查询分析器组件；\n优化器组件；\n缓冲（Cache）组件；\n插件式存储引擎；\n物理文件；\n\n其中，MySQL 数据库区别于其他数据库的最重要的一个特点就是其插件式的表存储引擎。并且为这种架构提供了一系列标准的管理和服务支持，这些标准与存储引擎本身无关，作为底层物理结构的实现，每个存储引擎按照自己的意愿进行开发。MySQL 的核心就在于存储引擎。存储引擎是基于表的，而不是数据库。\n常用存储引擎对比下面是MySQL几种存储引擎特性对比：\n\n可以看出，不同存储引擎对诸如事务、全文索引等的支持是不同的；另外对B-树等索引、锁机制等的具体算法实现也有很大差异。\n选取 MySQL 中较为常用的 InnoDB、MyISAM、MEMORY、Archive 四个存储引擎作为对比。它们都有各自适用的环境，这取决于其独有的一些特征。主要体现在性能、事务、并发控制、参照完整性、缓存、 故障恢复，备份及回存等几个方面。\nInnoDB\nMySQL 5.7.x 默认的存储引擎为 InnoDB，被设计成适用于高并发读写的情况。使用MVCC(Multi-Version Concurrency Control)以及行级锁来提供遵从ACID的事务支持，提供了具有__提交、回滚和崩溃恢复能力的事务安全__，对比MyISAM的存储引擎，InnoDB 写处理效率差一些并且会占用更多的磁盘空间以保留数据和索引。\n提供外键约束（MySQL 中只有 InnoDB 支持外键约束）。在创建外键的时候，父表必须有对应的索引，子表在创建外键的时候也会自动创建对应的索引。在创建索引的时候，可以指定在删除、更新父表时，对子表进行的相应操作，包括restrict、cascade、set null和no action。其中restrict和no action相同，是指限制在子表有关联的情况下，父表不能更新；casecade表示父表在更新或删除时，更新或者删除子表对应的记录；set null 则表示父表在更新或者删除的时候，子表对应的字段被set null。\n在行级别上对表数据上锁，提供非锁定读。行级锁没有相关额外的开销，并可以同时得到并发性和一致性。\n使用 Next-Key Lock 算法来避免不可重复读问题。MySQL 文档中将不可重复读问题定义为（Phantom Problem），即幻读问题。\n\n适合场景：\n\n可靠性要求较高\n要求事务\n表更新和查询都相当频繁，锁定表的可能性较大，等\n\nMyISAM不支持事务，也不支持外键。访问速度快，占用内存较少。数据文件和索引文件可以分开存储，平均分配IO以获取更快的速度。每个MyISAM表在磁盘上存储3个文件：\n\n.frm（存储表定义）\nMYD（MYData，存储数据）\nMYI（MYIndex，存储索引）\n\nMyISAM表支持3种不同的存储格式：\n\n静态(固定长度)表\n动态表\n压缩表\n\n其中静态表是默认的存储格式。静态表中的字段都是非变长字段，这样每个记录都是固定长度的，这种存储方式的优点是存储非常迅速，容易缓存，出现故障容易恢复；缺点是占用的空间通常比动态表多。静态表在数据存储时会根据列定义的宽度定义补足空格，但是在访问的时候并不会得到这些空格，这些空格在返回给应用之前已经去掉。同时需要注意：在某些情况下可能需要返回字段后的空格，而使用这种格式时后面到空格会被自动处理掉。动态表包含变长字段，记录不是固定长度的，这样存储的优点是占用空间较少，但是频繁到更新删除记录会产生碎片，需要定期执行OPTIMIZE TABLE语句或myisamchk -r命令来改善性能，并且出现故障的时候恢复相对比较困难。压缩表由myisamchk工具创建，占据非常小的空间，因为每条记录都是被单独压缩的，所以只有非常小的访问开支。\n适合场景：\n\n对事务完整性没有要求；\n插入不频繁、查询非常频繁；等\n\nMERGEMERGE存储引擎是一组MyISAM表的组合，这些MyISAM表结构必须完全相同，MERGE表中并没有数据，对MERGE类型的表可以进行查询、更新、删除的操作，这些操作实际上是对内部的MyISAM表进行操作。对于对MERGE表进行的插入操作，是根据INSERT_METHOD子句定义的插入的表，可以有3个不同的值，first和last值使得插入操作被相应的作用在第一个或最后一个表上，不定义这个子句或者为NO，表示不能对这个MERGE表进行插入操作。可以对MERGE表进行drop操作，这个操作只是删除MERGE表的定义，对内部的表没有任何影响。MERGE在磁盘上保留2个以MERGE表名开头文件：.frm文件存储表的定义；.MRG文件包含组合表的信息，包括MERGE表由哪些表组成，插入数据时的依据。可以通过修改.MRG文件来修改MERGE表，但是修改后要通过flush table刷新。\nMEMORYMEMORY使用存在内存中的内容来创建表。每个MEMORY表实际对应一个磁盘文件，格式是.frm。MEMORY类型的表访问非常快，因为它到数据是放在内存中的，并且默认使用HASH索引，但是一旦服务器关闭，表中的数据就会丢失，但表还会继续存在。默认情况下，MEMORY数据表使用散列索引，利用这种索引进行“相等比较”非常快，但是对“范围比较”的速度就慢多了。因此，散列索引值适合使用在”&#x3D;”和”&lt;&#x3D;&gt;”的操作符中，不适合使用在”&lt;”或”&gt;”操作符中，也同样不适合用在order by字句里。如果确实要使用”&lt;”或”&gt;”或betwen操作符，可以使用B-tree索引来加快速度。存储在MEMORY数据表里的数据行使用的是长度不变的格式，因此加快处理速度，这意味着不能使用BLOB和TEXT这样长度可变的数据类型。VARCHAR是一种可变长类型，但因为它在MySQL内部被当作长度固定不变的CHAR类型，所以可以使用。\n","categories":["DB"],"tags":["DB","MySQL"]},{"title":"索引","url":"/2018/04/06/MySQL/%E7%B4%A2%E5%BC%95/","content":"[toc]\n索引是数据库中用来加速查询的最为重要的技术手段。\n索引存储：\n对于 MyISAM 表，其数据保留在数据文件中，索引值保留在索引文件中，即使用数据的物理位置引用被索引的行，并使用前缀压缩技术使得索引更小，一个表可以有多个索引，但它们都保存在同一个索引文件里。索引文件里的每个索引都由一组有序的关键字行构成，这组关键字行主要用于快速访问数据文件；\n对于 InnoDB 表，默认情况下，只使用一个表空间，用于管理所有的 InnoDB 数据存储和索引存储，也可以修改配置，让它创建的每个表都有自己的表空间，但此时，给定表的数据和索引也同样保存在同一个表空间文件。同样地，InnoDB 将索引值当作一组有序值。InnoDB 存储引擎表是索引组织表，即表中数据按照主键顺序存放，即根据主键引用被索引的行。\n\n高效索引并非在所有的查询条件中出现的列都需要添加索引。对于添加 B+ 树索引的一般经验是，在访问表中很少一部分时考虑使用 B+ 树索引。如果一个字段取值范围很广，重复出现较少，即属于高选择性字段，此时使用 B+ 树索引比较合适。否则，如性别、类型等字段，可取值范围很小（性别显然只能筛选 50%），即属于低选择性字段，此时不适合使用 B+ 树索引。事实上，在低选择性的字段上，即使建立了如 B 树索引，数据库可能也不会使用，而是仍然以全扫描（如果没有其他可用索引）的方式进行查找，因为此时使用这种索引可能反而降低性能。\n指导原则\n为用于搜索、排序、分组的列创建索引，而对于用作输出显示的列不需要建立索引。即，最佳索引候选列是出现在 WHERE、连接、ORDER BY、GROUP BY 子句中的列，而出现在 SELECT 关键字后面的输出列表里的列则不是很好的选择。\n\n认真考虑数据列基数列的基数（cardinality）是指它所容纳的所有非重复值的个数。相对于表的总行数来说，列的基数越大（也就是包含的唯一值越多，重复值越少，即上述的高选择性的列），使用索引的效果越好。\n\n索引短小值应尽量选择较小的数据类型。如，当使用 MEDIUMINT 列便能够容纳所需要存储的数据时，就不要选用 BIGINT，如果值的长度都不会超过 25 个字符，那么就不要使用 CHAR(100)。短小的值可以提高索引的处理性能：\n\n短小的值操作更快，从而加快索引查找速度；短小的值可以让索引更小，从而减少磁盘 I&#x2F;O；对于短小的键值，键缓存里的索引块可以容纳更多的键值，也就可以在更少的磁盘 I&#x2F;O 下读取更多的索引块，从而提高找到键值的几率。\n\n\n索引字符串值的前缀要对字符串列建立索引，应该尽可能指定前缀长度。如，对于一个 CHAR(200) 列，如果大多数值的前 10 个 或 20 个字符都是唯一的，那么就可以不用为整个列进行索引，而只为前 10 个或 20 个字符进行索引，这样可以节省大量的索引空间，而且能够加速查询；但只索引列的第一个字符恐怕不行，因为会导致索引无法获得大量的唯一值。\n\n利用最左前缀当创建包含 n 个列的复合索引时，实际上会创建 n 个索引，即相当于多个索引，因为索引中最左边的任意数据列集合都可以用于匹配各个行。这样的集合即为 最左前缀。假设：多个列的复合索引中包含列：county、state、city，索引中行的排列顺序为 country&#x2F;state&#x2F;city。那么，行首先会按照 county&#x2F;state 顺序排序，然后按 country 顺序排序，这意味着，即使在查询中只指定了 county 值，或者只指定了 country 和 state 值，MySQL 也可以充分利用索引。因此，索引可用于搜索这些列组合：country, state, citycountry, statecountry对于没有包含最左前缀的搜索，如按照 state 或者 city 来搜索，MySQL 则无法使用该索引；而如果要所搜 country 和 city（索引的第 1、3 列，跳过第 2 列），那么索引能够找到与 country 匹配的行以缩小搜索范围，但无法继续用于 city 列。\n\n不要建立过多的索引显然，索引的建立并非无代价的，要考虑对性能和存储的影响。过多的索引也会导致\n\n选择合适的索引类型对于精确查找（使用 &#x3D;、&lt;&gt; 的查找），那么使用 MEMORY 的默认索引类型，即 hash 索引，可能效果更好：hash 的精确查找速度非常快，而对范围匹配表现欠佳；所以对于范围查找，使用 B+ 树类型的索引效果更好，InnoDB、MyISAM、MEMORY 等都支持 B 树索引。\n\n利用慢查询日志找出性能低劣的查询参见“慢查询日志”部分。\n\n\n辅助手段为数据选择利于高效查询的数据类型。多用数字运算，少用字符串运算数字运算通常比字符串运算更快。尽可能使用数字表示数据，如以点记号表示的 IP 地址，可以采用 4 组数字依次存入 INT UNSIGNED，而非直接使用字符串，尽管更方便，但数字对数据操作更高效，且更加节省空间。\n把数据列声明为 NOT NULL这可以加快查询，因为查询处理期间不再需要检查该列的值是否可以为 NULL，也有利于编写更简洁的 sql 语句。如果必须考虑 NULL 的情况，也可以考虑默认值等方式。\n考虑使用 ENUM 列如果必须采用字符串的列，恰好其基数很小（差异值较少），可以考虑转用 ENUM 列，即内部实际上采用数字形式存储，从而获得数字运算的处理速度。\n使用 PROCEDURE ANALYSE()运行 PROCEDURE ANALYSE()，可以根据输出得出一些优化手段。\n整理表碎片对频繁修改的表，尤其是包含可变长数据列的表，往往会产生大量碎片，导致空间浪费。定期使用 OPTIMIZE TABLE，可以消除&#x2F;减少碎片化的 InnoDB、MyISAM 表的空间浪费，并有助于防止性能降低。适用于各存储引擎的碎片整理方式是：先用 mysqldump 转储表，再利用该转储文件重建之：\nmysqldump db_name table_name > dump.sql\nmysql db_name &lt; dump.sql\n\n压缩数据把数据压缩到 BLOB 或 TEXT 列。使用 BLOB 或 TEXT 列来存储那些可以在应用程序中对其进行压缩和解压的数据，使之能够使用单个索引操作找出所有内容的目的。这种方法特别适用于存储那些难以用标准表数据结构表示的数据，或者会随时间变化的数据。\n把 BLOB 或 TEXT 列剥离处出来形成一个单独的表将 BLOB 或 TEXT 列单独存入一个附表，可以更好地管理原表里的数据。\n一个索引是否适合某个查询的“三星系统”\n\n索引将相关的记录放到一起则获得一星；\n索引中的数据顺序和查找中的排练顺序一致则获得二星；\n索引中的列包含了查询中需要的全部列则获得三星。\n\n索引使用方式\n加快对 WHERE 字句匹配的行进行搜索的速度&#x2F;加快对与另一个连接表里的行匹配的行进行搜索的速度；\n对于使用 MIN() 或 MAX() 函数的查询，可以在不用逐行检查的情况下，快速找到索引列里的最值；\n对于 ORDER BY 和 GROUP BY 字句，MySQL经常使用索引来高效地完成分类&#x2F;分组操作；\n通过索引来读取查询所请求的所有信息。\n\n索引类型InnoDB 存储引擎支持的类型有 3 种：B+ 树索引、全文索引、哈希索引。其中，哈希索引是自适应的，InnoDB 存储引擎会根据表的使用情况自动为表生成哈希索引，不能人为干预该过程。另外，还有一种 MySQL 不支持但很常见（如 Oracle）的索引：位图索引（BitMap BitMap index）。从这个开始。\n位图索引上面提到建立 B 树索引的条件：高选择性的列。对于低选择性的列（这里应该描述成：只有固定几个值可选的列）如性别、婚否等，位图索引可能是个好的选择。示例：\n\n\n适用条件\n只有几个固定值的列；\n不会频繁更新；\n\n位图索引原理\nB+ 树索引（InnoDB）B+ 树是为磁盘或其它直接存取辅助设备设计的一种平衡查找树。目前关系型数据库系统中查找最为常用和最为有效的索引。特点由于 B+ 索引在数据库中有 高扇出性 的特点，一般高度在 2-4 层，意即查找某一键值的行记录最多只需要 2-4 次 I&#x2F;O。B+ 树索引并不能找到一个给定键值的具体行，而是查找该行所在的页，然后通过把页读入内存，再在内存中进行查找，最后得到要查找的数据行。可以分为聚集索引（Clustered Index）和辅助索引（Secondary Index），叶子节点存放着所有的数据，不同之处是，叶子节点存放的是否是一整行的信息。\n聚集索引（clustered index）&#x2F;聚簇索引按照每张表的主键构造一棵 B+ 树，同时叶子节点中存放的即为整张表的行记录数据，也将聚集索引的叶子节点成为数据页。聚集索引的这个特性决定了索引组织表中数据也是索引的一部分。同 B+ 树数据结构一样，每个数据页都通过一个双向链表来进行链接。由于实际的数据页只能按照一棵 B+ 树进行排序，因此每张表只能拥有一个聚集索引。查询优化器倾向于采用聚集索引，因为能够在叶子节点上直接找到数据，对于主键的排序查找和范围查找速度都非常快。聚集索引的存储并不是物理上连续的（维护成本将非常高），而是逻辑上连续的。\n辅助索引&#x2F;非聚簇索引叶子节点并不包含行记录的全部数据，除了包含键值以外，每个叶子节点的索引行中还包含了一个书签，用来告诉InnoDB存储引擎哪里可以找到与索引相对应的行数据。辅助索引的存在并不影响数据在聚集索引中的组织，因此每张表上可以有多个辅助索引。当通过辅助索引来查找数据时，InnoDB存储引擎会遍历辅助索引并通过叶级别的指针获得指向主键索引的主键，然后通过主键索引来找到一个完整的行记录。例：如果在一棵高度为3的辅助索引树中查找数据，那么需要对这棵辅助索引树遍历3次找到指定主键，如果聚集索引树的高度同样为3，那么还需要对聚集索引树进行3次查找，最终找到一个完整的行数据所在的页，因此共需要6次逻辑IO访问以得到最终的一个数据页。\n为什么使用 B+ 树数据结构\n数据库索引一般数据量很大，超出了内存范围，这时候传统的内存数据结构比如红黑树不再适用，而 B+ 树更适合磁盘数据结构，它通过降低树的高度，来减少磁盘操作，从而提高查询效率。\nMysql 是一种关系型数据库，区间访问是常见的一种情况，B+ 树叶节点增加的链指针,加强了区间访问性，可使用在范围区间查询等，而 B- 树每个节点 key 和 data 在一起，则无法区间查找。\n\nB 树索引的限制：\n如果不是按照索引的最左列开始查找，则无法使用该索引；\n不能跳过索引中的列。即，如果一个索引中含有三个列，则只有在使用了第一、二列的情况下，才能使用第三列；\n如果查询中有某个列的范围查询，则其右边所有列都无法使用索引查找。如果范围查询列值的数量有限，可以通过使用多个等于条件替代之。etc.\n\n哈希索引（Hash Index）基于哈希表实现，只有精确匹配索引所有列的查询才有效。对于每一行数据，存储引擎都会对所有的索引列计算一个哈希码（Hash Code），哈希码是一个比较小的值，并且不同键值的行计算出来的哈希码是不同的。哈希索引将所有的哈希码存储在索引中，同时在哈希表中保存指向每个数据行的指针。\nMySQL中，只有 Memory 引擎显式支持哈希索引，也是 Memory 引擎表默认索引类型，并且支持非唯一哈希索引。如果多个列的哈希值相同，索引会以链表的方式存放多个记录指针到同一个哈希条目中；InnoDB 引擎支持的哈希索引是自适应的，会根据表的使用情况自动为表生成哈希索引，不能人为干预是否在一张表中生成哈希索引。\n全文索引（Full-Text Search Index)将存储于数据库中的整本书或整篇文章中的任意内容信息查找出来的技术。MyISAM支持全文索引，InnoDB 从 1.2.x 版本开始支持全文索引。Memory、NDB、Archive等不支持全文索引。\n倒排索引全文索引通常使用倒排索引（Inverted Index）来实现：在辅助表（Auxiliary Table）中存储了单词与单词自身在一个&#x2F;多个文档中所在位置之间的映射，这通常利用关联数组实现，有两种表现形式：\n\nInverted File Index，表现形式为 {单词，单词所在文档 ID}；\nFull Inverted Index，表现形式为{单词，（单词所在文档 ID，在具体文档中的位置1，位置2…）}示例如下：\nInnoDB 全文索引采用 Full Inverted Index 的方式，将（DocumentId， Position1, Position2…）视为一个 ilist。故在全文索引的表中，有两个列：word字段、ilist字段，并且在word字段上设有索引。此外，由于 InnoDB 在ilist字段中存放了 Position 信息，故可以进行 Proximity Search（MyISAM不支持该特性）。为提高全文检索的并行性能，InnoDB中共有6张 Auxiliary Table，目前每张表根据 word 的 Latin 编码进行分区。Auxiliary Table 是存放在磁盘上的持久表。此外，还有一个 FTS Index Cache（全文检索索引缓存），用来提高全文检索的行能。它是一个红黑树结构，根据（word，ilist）进行排序。\n\n限制：\n每张表只能有一个全文索引的索引；\n由多列组合而成的全文索引的索引列必须使用相同的字符集和排序规则；\n不支持没有单词界定符（delimiter）的语言，如中、日、韩等语言。\n\n相关性：在 WHERE 中使用 MATCH 函数，查询返回的结果是根据相关性（Relevance）进行降序排序的，即相关性最高的结果放在第一位，0表示没有任何相关性。计算条件：\n\nword是否在文档中出现；\nword在文档中出现的次数；\nword在索引列中的数量；\n多少个文档包含该word。\n\nBOOLEAN全文检索可以使用 IN BOOLEAN MODE 修饰符，此时查询字符串的前后字符会有特殊的含义，如：\n\n+ word：表示word必须存在；\n- word：表示word必须被排除；\n@distance：可选，表示字符字节间距最大值；\n&gt;：表示出现该词时增加相关性；\n&lt;：表示出现该词时降低相关性；\n*：表示以该词开头的单词，如lik*，可以是lik、like、likes…\n“：表示短语；\n~：表示允许出现该单词，但相关性为负\netc.\n\nQuery Expansion全文索引的扩展查询，通常在查询的关键词太短，用户需要 implied knowledge（隐含知识）时进行。如，对于单词 database 的查询，用户可能希望查询的不仅仅是 database 的文档，可能还指那些包含 MySQL、Oracle、DB2、RDBMS 等的单词，这时可以使用 Query Expansion 模式来开启全文索引的 implied knowledge。通过在查询短语中添加 WITH QUERY EXPANSION 或 IN NATURAL LANGUAGE MODE WITH QUERY EXPANSION 可以开启 blind query expansion（automatic relevance feedback）。该查询分为两个阶段：\n\n根据索引的单词进行全文索引查询；\n根据第一阶段产生的分词再进行一次全文检索的查询。\n\n由于 Query Expansion 的全文检索可能带来许多非相关性的查询，因此在使用时需要非常谨慎。\n索引代价主要体现在索引导致的写操作效率降低和空间占用两方面。\n降低写操作效率写入操作（插入、删除、更新等）同时需要更新索引，所以表上的索引越多，需要做出的索引修改操作越多。所以在写操作频繁的表中，需要一些优化措施。\n占用空间索引会占用磁盘空间，尤其在多个索引的表中，索引可能导致很快达到表大小上限，这跟具体存储引擎有关：\n\nInnoDB 中，使用独立表空间的表，索引 + 数据行有文件大小限制，受操作系统影响；使用系统表空间则所有表和索引共享同一个存储空间池，添加索引会使存储空间减少得很快，但总大小不受操作系统的影响，逻辑上可以配置多个文件，所以可以使用磁盘扩容表空间。\nMyISAM 中，大量的索引可能导致索引文件比数据文件更快达到文件大小的上限。\n\nQ&amp;A为什么不直接对数据进行排序呢？这样就不需要索引了而且能够加速搜索如果表只有一个索引，自然可以这样做。如果想添加两个&#x2F;多个索引，又不能同时按照两种方式对数据进行排序，比如一个关于顾客姓名的索引和一个电话号码索引，这种情况就无法排序。将索引从数据行中整体分离出来，就可以创建多个索引，并且不需要对原始数据排序，但搜索过程即先在索引中找到对应值，然后根据匹配的记录找到对应的数据行。此外，索引行数据通常比表里的数据行更短，插入&#x2F;删除值时，为保持排序顺序，来回移动较短的索引值，比来回移动较长的数据行更加容易。\n","categories":["DB"],"tags":["DB","MySQL"]},{"title":"IP","url":"/2018/04/02/CN/IP/","content":"网络层提供的不可靠、无连接数据报传送服务。不可靠（Unreliable）： 不能保证IP数据报成功到达目的地，简单处理错误的方式如：丢弃数据报，发送TCMP消息报给信源端。无连接（Connectionless）： 不维护任何关于后续数据报的状态信息，即独立处理，独立到达（不同路线的选择可能造成失序、丢失等）。\nIP 数据报首部格式数据报首部（20字节+选项内容）包含的内容如下：\n\nIP 长度字段要求首部始终是 32 bit 的倍数，所以选项内容有可能需要填 0 补充。\n4 位版本号目前有 IPv4、IPv6；\n4 位首部长度首部中 32 bit 字的数目，即首部长度最多只能有 60 字节（20 + 最多 40 选项字段）。普通 IP 数据报（不含选项内容）该字段值为5（5 * 4 byte，即 20 字节）；\n8 位服务类型（TOS）包括 3 bit 优先权子字段（已被忽略），4 bit 的 TOS 子字段和 1 bit 未用但必须置 0，4 bit 分别为：\n\n最小时延\n最大吞吐量\n最高可靠性\n最小费用\n\n4 bit 中只能置其中 1 bit，均为 0 代表是一般服务。（RFC 1349）推荐的 TOS 值有：\n\n最小时延：Telnet、FTP（控制连接）、SMTP（命令阶段）、DNS（UDP查询）等；\n最大吞吐量：FTP（数据连接）、SMTP（数据阶段）、DNS（区域传输）等；其他略。并且，现在大多数 TCP&#x2F;IP 实现都不支持 TOS 特性。\n\n16 位数据报(字节数)整个 IP 数据报的长度：首部+数据。最大 65535 字节（16位），当数据被分片时，该字段的值也随之变化。\n16 位标识（Identificationr）唯一标识主机发送的每一份数据报，通常每发送一份其值加 1。也能和标志位、片偏移联合使用，对较大的上层数据报进行分片和重新组装（重组时有足够的信息处理片失序）。\n3 位标志（Flags）第一位不用，第二位为 DF（Don’t Fragment），置 1 表示不分片（如果导致无法转发，则丢弃该数据报并返回错误信息），第三位为 MF（More Fragments），如果 DF 为 0，那么 MF 除最后一片外，其他每个组成片都置 1；\n13 位片偏移（Offset）该片偏移原始数据报开始处（可通过总长-首部长获得）的位置；\n8 位生存时间（TTL）设置了数据报最多可经过的路由器数量。由发送端主机设置（通常为 32 或 64），每经过一个处理该报文段的路由器，该值减 1。当该值减为 0 时，数据报被丢弃，并发送 ICMP 报文通知发送端主机；\n8 位协议识别向 IP 传送数据报的协议类型。在向上层交付数据时，通过解析该字段来确定数据交付给具体上层协议（TCP、UDP、SCTP 等），所以，TPC 和 UDP 可以使用相同的端口号而不产生冲突：端口是封装在具体协议里的，IP 协议不会解析其承载的数据，只会解析自己的头部信息，从而完成交付。\n\nTCP（6）\nUDP（17）\nICMP（1）\nIGMP（2）\nOSPF（89）…\n\n16 位首部检验和只计算首部，对首部中每个二进制 16 位进行反码求和。TTL 递减的情况可以通过递增检验和解决而无需重新计算整个首部；\n32 位源 IP 地址发送端主机IP地址；\n32 位目的 IP 地址接收端主机IP地址；\n选项内容变长，一般有：\n\n安全和处理限制（军事领域）；\n记录路径（由于4位首部长限制导致该选项现今已无用处）；\n时间戳（让每个路由器都记录下它的IP地址和时间）；\n宽松的源站选路（为数据报指定一系列必须经过的IP地址）；\n严格的源站选路（与上面的类似，但要求只能经过指定的这些地址，不能经过其他地址）。\n\n这些选项都以 32 bit 为界限，必要时插入值为 0 填充字节（IP 长度字段要求首部始终是 32 bit 的倍数）。实际上这些选项很少被使用，也并非所有主机和路由器都支持它们。\nIP 数据报分片物理网络层要求限制每次发送数据帧的最大长度。任何时候 IP 层收到一份要发送的数据报时，要判断向哪个接口发送数据（选路），并查询该接口的 MTU（最大传输单元）。IP 把 MTU 与数据报长度对比，按需分片。分片过程可以发生在原始发送到主机上，也可以发生在中间路由器上。但重新组装要在目的端 IP 层完成：实现分片与重新组装最运输层是透明的。尽管透明，但即使只丢失一个分片，也要重传整个数据报（IP 层没有超时重传机制），因此要尽量避免分片。\nIP 编址相关概念：DHCP、NAT、CIDR\nNATNetwork Address Translation，网络地址转换。示例（见 CNATD p234）：\n\n\n关于 NAT 的讨论一般认为端口号用于进程编址，而非主机编址；并且 NAT 违反了端到端原则（主机之间应该直接对话），节点（NAT 路由器）不应介入修改 IP 地址与端口号；应该使用 IPv6 解决 IP 地址短缺问题，而非如 NAT 之类的权宜之计来修补。\nIPv6","categories":["CN"],"tags":["CN"]},{"title":"拥控算法","url":"/2018/04/02/CN/%E6%8B%A5%E6%8E%A7%E7%AE%97%E6%B3%95/","content":"当过多的包在网络缓冲区中竞争某个相同链路时，队列会溢出丢包，当这种丢包成为普通事件时，网络即发生拥塞。即，对聚合带宽的需求超过了链路的可用容量。\n判断标准，一般网络中有以下情况：\n\n\n分类首先，从拥控算法的实现位置上来说，主要分为链路算法和源算法两种：\n\n\n链路控制算法的研究主要集中在 主动队列管理（AMQ） 算法方面：\n\n\n源控制算法中使用最广泛的是TCP协议中的拥塞控制算法：\n\n\n还有就是根据是否开闭环分类：\n\n\n这里只关注源控制算法中，几种主要的实现。根据不同的反馈类型，TCP中拥控算法可以按照这样的方式分为几类：\n\n\n其中：\n\n基于丢包反馈：通过ACK所带回的丢包信息来调整源端的拥塞窗口。Reno等是针对ACK返回的丢包信息改进传统TCP协议。近年来，随着网络带宽的提高、传输时延的增大，针对提高TCP带宽利用率这一点，出现了一系列HSTCP、BIC-TCP、STCP等。　　以使用最广泛的Reno算法为例。其实现主要分为四个阶段：\n\n慢启动：cwnd呈现指数增长趋势；\n拥塞避免：cwmd&gt;ssthresh，呈现线性增长趋势；\n快速重传&gt;：发送方只要连续收到三个重复确认就认为丢包发生，应该立即重传，而不必等到重传计时器超时后发送；\n快速恢复：取决于收到的重复确认数据的初始阈值（一般为3）。与慢启动不同，Reno的发送方用额外到达的应答为后续包定时。\n\n\n\n\n\n\n\n基于路径时延反馈：RTT相对于丢包信息反应更灵敏，更能及时反映出一般网络的拥塞情况。适用于小缓存的中间节点，效率比较理想。\n\n\n经典的Vegas算法采用了带宽估计，缩短慢启动阶段的时间。基本思路是：RTT增加，拥塞窗口减小；RTT减小，拥塞窗口增加。\n无线传输中的Westwood算法的基本思路是：发送端利用检测到的ACK的到达率来估测可使用的带宽。\n\n\n基于显式拥塞反馈：典型的ENC利用中间节点自检测雍塞状态，如路由器的反馈状态，直接反馈给TCP源端，以此调节源端的窗口值和发送速率。HSTCP与STCP的基本思想：当cwnd&gt;ssthresh时，窗口增加因子a（w）与减少因子b（w）成为窗口调节大小w的函数。\n\n\n\nHSTCP-high speed TCP适用于高速度、大时延网络  窗口快速增长、乘性缩小。HSTCP(高速传输控制协议)是高速网络中基于AIMD(加性增长和乘性减少)的一种新的拥塞控制算法,它能在高速度和大时延的网络中更有效地提高网络的吞吐率。它通过对标准TCP拥塞避免算法的增加和减少参数进行修改，从而实现了窗口的快速增长和慢速减少，使得窗口保持在一个足够大的范围，以充分利用带宽，它在高速网络中能够获得比TCP Reno高得多的带宽，但是它存在很严重的RTT不公平性。公平性指共享同一网络瓶颈的多个流之间占有的网络资源相等。\n\n\n\n\nSTCP- scable TCP通过修改 TCP的窗口增加和减少参数来调整发送窗口大小 ,以适应高速网络的环境。该算法具有很高的链路利用率和稳定性，但该机制窗口增加和 RTT成反比 ,在一定的程度上存在着 RTT不公平现象 ,而且和传统 TCP流共存时 ,过分占用带宽 ,其 TCP友好性也较差。\n\n\n\n\nCUBICCUBIC在设计上简化了BIC-TCP的窗口调整算法，在BIC-TCP的窗口调整中会出现一个凹和凸(这里的凹和凸指的是数学意义上的凹和凸，凹函数&#x2F;凸函数)的增长曲线，CUBIC使用了一个三次函数(即一个立方函数)，在三次函数曲线中同样存在一个凹和凸的部分，该曲线形状和BIC-TCP的曲线图十分相似，于是该部分取代BIC-TCP的增长曲线。另外，CUBIC中最关键的点在于它的窗口增长函数仅仅取决于连续的两次拥塞事件的时间间隔值，从而窗口增长完全独立于网络的时延RTT，之前讲述过的HSTCP存在严重的RTT不公平性，而CUBIC的RTT独立性质使得CUBIC能够在多条共享瓶颈链路的TCP连接之间保持良好的RTT公平性。\n\n\n流控&amp;拥控首先，在路由器资源分配上下文中，数据流是在源&#x2F;目的主机对之间，通过相同路由而发送的一些列数据包，它们具有若干相同的头部特征，如，源地址与端口号、目的地址与端口号、协议类型、服务类型（TOS）等。对比：拥控问题：某些点上存在资源瓶颈目的：防止发送者把太多的数据发送到网路中，适应瓶颈链路和路由器有限buffer，保护网络概况：与全网有关，涉及多个端到端、主机、路由器等很多网络元素；目的是确保通信子网能够承载用户提交的通信量，是一个全局问题；流控问题：接收方可能存在缓存不足、进程等待目的：防止发送方的发送速度比接收方的接收速度快，适应收发双方的buffer＋cpu能力，保护端点概况：只与一对端到端的通信量有关，只涉及快速发送方与慢速接收方的问题，是局部问题，一般都是基于反馈进行控制的。\n参考：http://blog.sina.com.cn/s/blog_73b05f070101ipaw.htmlhttps://blog.csdn.net/zhangskd/article/details/6715751\n","categories":["CN"],"tags":["CN"]},{"title":"TCP","url":"/2018/03/30/CN/TCP/","content":"提供面向连接的、可靠的字节流服务。全双工，即能在两个方向上独立地进行传输。通过超时重传、流量控制、检验和、失序重排等保证可靠等特性。数据传输过程概述TCP 连接建立好之后，进程通过套接字传递数据流，数据流经过套接字之后，就转由 TCP 控制。TCP 将数据流引导到该连接的发送缓存（send buffer）中，并时不时从发送缓存取出一块数据，_TCP 规范中并未规定何时发送缓存中的数据_。TCP 可从缓存中取出并放入报文段中的数据量受限于最大报文段长度（Maximum Segment Size，MSS），MSS 通常根据最初确定的由本地发送主机发送的最大链路层帧长度（Maximum Transmission Unit，MTU）来这是。设置 MSS 要保证一个 TCP 报文段加上 TCP 首部（通常 40 字节）将适合单个链路层帧。以太网和 PPP 链路层协议具有 1500 字节的 MTU，因此 MSS 典型值为 1460 字节。注意 MSS 并不包括 TCP&#x2F;IP 首部，简单理解成：MSS + TCP 首部 &#x3D; TCP 报文段长度。\n首部内容20字节+选项内容：\n\n16 位源端口号寻找发端应用程序。\n16位 目的端口号寻找收端应用程序。\n32 位序号Sequence Number。无符号循环，标识字节流。序号字段初始值（ISN）由发端主机选择，要发送的第一个字节序号为ISN+1：SYN 标志消耗了一个序号。接下来的发送会累加每个字节。\n32 位确认序号Acknowledgement Number，即 ack。无符号循环。包含发送确认的一端所期望收到的下一个序号，即上次已成功收到数据字节号 +1。只有 ack 字段为 1 时确认序号才有效。\n4 位首部长度首部中 32 bit 字的数目，即首部长度最多只能有 60 字节（20 + 最多 40 选项字段）。\n6 位保留位6 位标志位\nURG：紧急指针有效TCP 提供了“紧急方式（urgent mode）”，它使一端可以告诉另一端有些具有某种方式的“紧急数据”已经放置在普通的数据流中，另一端被通知这个紧急数据已经被放置在普通数据流中，由接收方决定如何处理。使用方式是该位置 1，配合“紧急指针”设置的正偏移量，该偏移量 + ack，即得到紧急数据的最后一个字节的序号。\nACK：确认序号有效\nPSH：接收方应尽快将这个报文段交给应用层该标志位通知接收方将所收到的数据全部提交给接收进程，即接收到的数据不继续缓存在 TCP 接收缓存中，而是直接提交给进程处理。\nRST：重建连接\nSYN：同步序号用来发起一个连接\nFIN：发端完成发送任务\n\n16 位接收窗口提供流量控制。用于指示接收方愿意接收的字节数量。\n16位检验和覆盖整个 TCP 报文段。使用 12 字节伪首部，对每个 16 bit 进行反码求和。发端计算并存储，收端验证（全 1 为真）。\n16 位紧急指针URG 位为 1 时有效。\n选项内容最常见的是最长报文大小（MSS：Maximum Segment Size）。每个连接方通常在通信的第一个报文段中（SYN 中）指明这个选项：表明本端所能接收的最大长度的报文段（字节单位）。\n连接建立&#x2F;终止三次握手\n请求端（通常为客户）发送一个 SYN 段指明客户打算连接的服务器的端口，以及初始序号（ISN: Initial Sequence Number）。这个 SYN 段为报文段 1；\n服务器发回包含服务器的初始序号的 SYN 报文段（报文段 2）作为允许连接的应答。同时，将确认序号设置为客户的 ISN+1 以对客户的 SYN 报文段进行确认。一个 SYN 将占用一个序号。并且，服务器会为该连接分配 TCP 缓存和变量。\n客户必须将确认序号设置为服务器的 ISN+1 以对服务器的 SYN 报文段进行确认（报文段 3）。同时为连接分配缓存和变量。此时连接已经建立，所以 SYN 置为 0（以后的都为 0），并且该阶段可以在报文段负载中携带数据。\n这三个报文段完成连接的建立。这个过程也称三次握手（three-way handshake）。\n\nWHY为什么需要初始序号？为什么是 3 次而不是 2 或者 4 次？初始序列号随机产生首先是出于安全性考虑：如果非随机初始序列号，黑客很容易获取到该值，从而伪造序列号进行攻击；其次，如果硬编码初始序号，在连接过程中出现中断、滞留以及频繁连接等情况时，可能会因为序列号的问题接收到错误连接&#x2F;已经过时的旧连接上的错误数据报。假定只有两次握手：第一次 A 发起连接请求，第二次 B 发送确认请求以及本方向上的连接初始序号，到此完成连接，问题是此时 A 还没有确认 B 的初始序号，即 A 和 B 还没有就 B 的初始序号达成一致。同理四次握手的情况：A 发起连接请求，B 确认，B 发起连接请求，A 确认，这个过程中的第二次、第三次可以合并执行，即三次完成，可以提高连接的速度和效率。三次而非二或者四次同时保证了数据能够可靠传输和提高传输效率。\nSYN 攻击在三次握手过程中，服务器发送 SYN-ACK 之后，收到客户端的 ACK 之前的 TCP 连接称为半连接(half-open connect)。此时服务器处于 Syn_RECV 状态.当收到 ACK 后，服务器转入 ESTABLISHED 状态。SYN 攻击就是攻击端在短时间内伪造大量不存在的 IP 地址，向服务器不断地发送 SYN 包，服务器回复确认包，并等待客户的确认，由于源地址是不存在的，服务器需要不断的重发直至超时，这些伪造的 SYN 包将长时间占用未连接队列，导致正常的 SYN 请求被丢弃，使得目标系统运行缓慢，严重者引起网络堵塞甚至系统瘫痪。SYN 攻击是一个典型的 DDos 攻击。检测 SYN 攻击非常容易：当在服务器上看到大量的半连接状态时，特别是源 IP 地址是随机的，基本上可以断定这是一次 SYN 攻击。在 Linux 下可以如下命令检测是否被 SYN 攻击：netstat -n -p TCP | grep SYN_RECV一般较新的 TCP&#x2F;IP 协议栈都对这一过程进行修正来防范 SYN 攻击：修改 TCP 协议实现。主要方法有 SynAttackProtect 保护机制、SYN cookies 技术、增加最大半连接和缩短超时时间等。但是它们也不能完全防范 SYN 攻击。\n参考\n断开连接方式close()&#x2F;closesocket()意味着完全断开连接，即不能发送数据也不能接收数据，这种“生硬”的方式有时候会显得不太“优雅”。\nshutdown有些特殊时刻，需要只断开一条数据传输通道，而保留另一条。\nvs确切地说，close()&#x2F;closesocket() 用来关闭套接字，将套接字描述符（或句柄）从内存清除，之后再也不能使用该套接字，与 C 语言中的 fclose() 类似。应用程序关闭套接字后，与该套接字相关的连接和缓存也失去了意义，TCP 协议会自动触发关闭连接的操作。shutdown() 用来关闭连接，而不是套接字，不管调用多少次 shutdown()，套接字依然存在，直到调用 close()&#x2F;closesocket() 将套接字从内存清除。调用 close()&#x2F;closesocket() 关闭套接字时，或调用 shutdown() 关闭输出流时，都会向对方发送 FIN 包。FIN 包表示数据传输完毕，对方收到 FIN 包就知道不会再有数据传送过来了。默认情况下，close()&#x2F;closesocket() 会立即向网络中发送 FIN 包，不管输出缓冲区中是否还有数据，而shutdown() 会等输出缓冲区中的数据传输完毕再发送 FIN 包。这意味着，调用 close()&#x2F;closesocket() 将丢失输出缓冲区中的数据，而调用 shutdown() 不会。\n四次挥手建立一个连接需要三次握手，而终止一个连接需要四次握手（也称四次挥手），这是由 TCP 的半关闭（half-close）造成的：一个 TCP 连接是全双工（数据能在两个方向上同时传递）的，因此每个方向必须单独地进行关闭。具体原则就是当一方完成它的数据发送任务后就能发送一个 FIN 来终止这个方向上的连接。当一端收到 FIN，它必须通知应用层另一端已经终止了那个方向上的数据传送。发送 FIN 通常是应用层进行关闭的结果。\n\n一端发送含有置位 FIN（和 SYN 一样，一个 FIN 将占用一个序号）的报文段；\n另一端收到后，将确认序号设置为收到序号 +1 发回 ACK，同时传送给应用程序一个文件结束符，从而关闭该文件传送连接（主动关闭）；\n当另一端也完成了所有操作后，同样发送一个 FIN 报文段给一端；\n一端发回确认序号 ACK，关闭连接。\n这四个报文段完成连接的双向关闭。这个过程也称四次挥手（four-way handshake）。注意连接双方不同状态的变化。这里用主动关闭方（一般为 Client）和被动方（一般为 Server）描述。\n\nFIN_WAIT_1FIN_WAIT，从名字上来看，就是等待对方的 FIN 报文，两者有所区别。FIN_WAIT_1 是主动发起关闭方才会出现的状态。主动关闭方发送关闭请求，即发送置位 FIN 的报文段，随即进入 FIN_WAIT_1 状态。当收到对方的 ack，进入 FIN_WAIT_2 状态。\nFIN_WAIT_2当收到被动方发回的连接关闭请求的 ack，主动方进入 FIN_WAIT_2 状态。此时一般的场景应该是等待被动方的应用层意识到对方已经请求并被确认关闭该连接（半关闭），很快被动方应用层也会请求关闭。也可能仅仅是主动方想进入半关闭状态，主动方没有要发送的数据了，但还需要继续接收数据。FIN_WAIT_2 持续时间为从收到被动方 ack 到收到被动方发起关闭请求（即 FIN 报文段）的这段时间。\nCLOSE_WAIT被动方等待关闭。被动方接收到对方发送的 FIN 报文段，予以回应的同时，将自己的状态由 ESTABLISHED 转变为 CLOSE_WAIT。此时需要做的工作是确认是否还有数据要发送给对方，如果有则继续发送，否则也应该发起关闭连接请求。\nLAST_ACK被动方发出 FIN 报文段后即进入该状态，等待最后一个 ack 到来。\nTIME_WAIT主动关闭 TCP 连接的一方会进入 TIME_WAIT 状态，也称 2MSL 等待状态，并且维持该状态时长为 2 * MSL。为什么是 2MSL：可靠安全地关闭全双工 TCP 连接。如果网络有拥塞，主动方最后一个 ack 并没有被正确接收，那么被动方会重传置位了 FIN 的 ack，此时由于主动方还没有真正关闭，也就有时间处理该重传。而如果等待时间不足，连接在被动方的重传 FIN 在到达前就已经彻底关闭，此时，首先是被动方没有正确关闭；还有需要考虑这种情况：关闭后主动方马上又和该被动方建立起一个 TCP 连接，那么，之前的 TCP 连接的重传过来的置位了 FIN 的 ack 会对本次连接造成影响。\n大量 TIME_WAIT?原因：在高并发短连接的 TCP 服务器上，当服务器处理完请求后立刻按照主动正常关闭连接。该场景下，会出现大量 socket 处于 TIME_WAIT 状态。如果客户端的并发量持续很高，此时部分客户端就会显示连接不上。因为短连接服务时间可能小于 TIME_WAIT 超时时间，而每个连接都会占用端口，导致资源浪费甚至无法继续服务。解决方法是相关参数的设置：&#x2F;etc&#x2F;sysctl.conf 文件：\n\nnet.ipv4.tcp_syncookies&#x3D;1开启 SYN Cookies。当出现 SYN 等待队列溢出时，启用 cookies 来处理，可防范少量 SYN攻击，默认为 0，表示关闭；\nnet.ipv4.tcp_tw_reuse&#x3D;1开启重用。允许将 TIME_WAIT sockets 重新用于新的 TCP 连接，默认为 0，表示关闭；\nnet.ipv4.tcp_tw_recycle&#x3D;1开启 TCP 连接中 TIME_WAIT sockets 的快速回收，默认为 0，表示关闭;\nnet.ipv4.tcp_fin_timeout&#x3D;30修改系統默认的 TIMEOUT 时间为 30s。\n\n如果连接数量本来就很多，继续优化 TCP&#x2F;IP 的可使用端口范围等，进一步提升服务器的并发能力。\n\nnet.ipv4.tcp_keepalive_time&#x3D;1200当 keepalive 启用的时候，TCP 发送 keepalive 消息的频度。缺省是 2 小时，改为 20 分钟；\nnet.ipv4.ip_local_port_range&#x3D;10000 65000用于向外连接的端口范围。缺省情况下很小：32768 到 61000，改为 10000 到 65000。（注意：这里不要将最低值设的太低，否则可能会占用掉正常的端口！）\nnet.ipv4.tcp_max_syn_backlog&#x3D;8192SYN 队列的长度，默认为 1024，加大队列长度为 8192，可以容纳更多等待连接的网络连接数；\nnet.ipv4.tcp_max_tw_buckets&#x3D;5000系统同时保持 TIME_WAIT 的最大数量，如果超过这个数字，TIME_WAIT 将立刻被清除并打印警告信息。默认为 180000，改为 5000。对于 Apache、Nginx 等服务器，上几行的参数可以很好地减少 TIME_WAIT 套接字数量，但是对于 Squid 效果却不大。此项参数可以控制 TIME_WAIT 的最大数量，避免 Squid 服务器被大量的 TIME_WAIT 拖死。\n\nTCP 分岔滑动窗口协议滑动窗口，即首部中的 16 位 Receive Window，也称接收窗口，简写“rwnd”。分为接收窗口、发送窗口。提供 TCP 的可靠性、流控制特性，也体现了 TCP 面向字节流的设计思路。滑动窗口的主要作用是 TCP 流量控制：让发送方以合适的速率发送报文段，以使接收方有能力接收数据。双方各自维护一个滑动窗口。\n原理\n首先，对于会话的发送方，任何时候在其发送缓存内的数据都可以分为 4 类：\n\nSent and Acknowledged：已收到 ack 确认的数据，这些数据已经发送成功并已经被确认的数据。即图中的前 31 个 bytes，这些数据位置在窗口之外，因为窗口内顺序最低的被确认之后，要移除窗口，实际上是窗口进行合拢，同时打开接收新的带发送的数据。\nSend But Not Yet Acknowledged：已发送但还没收到 ack 的数据，这部分数据已经发送但还没有收到 ack，认为并没有完成发送，这个属于窗口内的数据。\nNot Sent，Recipient Ready to Receive：在窗口中还没有发出的（接收方还有空间），是需要尽快发送的数据。接收方在首部“接收窗口”字段指明还能接收的字节数量，发送端设置这个值为当前窗口大小，而第二部分数据已经占据了一部分窗口空间（有可能已经占满窗口大小），所以这部分是需要马上发送的，因为接收方表明此时能够接收。\nNot Sent，Recipient Not Ready to Receive：窗口以外的数据（接收方没空间），这些数据属于未发送，同时接收端也不期望发送的，因为这些数据已经超出了接收所能接收的范围。\n\n窗口大小会根据接收端的首部携带值来动态调整。\n移动使用滑动窗口使得接收方不必确认每一个收到的分组。窗口两个边沿的相对运动（术语如下）将改变窗口大小：\n\n合拢：窗口左边右移，发生在数据被发送和确认时；\n张开：窗口右边右移，将允许发送更多的数据，发生在另一端的接收进程读取已经确认的数据并释放了TCP的接收缓存时；\n收缩：窗口右边左移，RFC强烈建议不要使用该操作。但TCP必须能够在某一端产生这种情况时进行处理。不存在窗口左边左移的情况，因为确认序号是递增的。而如果收到一个指示窗口左移的 ACK，则它被认为是一个重复的 ACK，将被丢弃。由接收方提供的窗口的大小通常可以由接受进程控制，这将影响 TCP 的性能。\n\n扩展窗口大小随着以太网等的发展，TCP 中 16 bit 窗口大小成为了一个限制，通过在首部的可选项字段增加一个选项，将窗口扩大为 32 bit（原首部 16 bit + 扩展 16 bit，不改变原首部内容）。\nTCP 的那些事儿TCP-IP详解：滑动窗口滑动窗口具体是怎样控制流量的\n超时重传使用 RTO 计时器实现超时重传机制。在时限内如果没有收到报文段的确认回复，则重新发送该数据段。\n拥塞控制TCP 的拥控方法简单来说是：让每个发送方根据所感知到的当前网络拥塞程度来限制其向连接发送流量（报文段）的速率。如果感知到线路不怎么拥塞，则发送方增加发送速率，vice verse。问题来了：\n\n一个发送方如何感知线路上是否拥塞？\n当感知到拥塞，如何限制发送速率，采用什么算法改变发送速率？\n\nTCP 拥塞控制算法中包含 3 个主要部分：慢启动、拥塞避免、快速重传和快速恢复。首先是一些概念。\nRTTRTT，Round-Trip Time，往返时间。超时与重传中最重要的部分是对一个给定连接的往返时间的测量。由于路由器和网络流量均会变化，RTT 可能也会经常变化，TCP 应该跟踪这些变化并相应地改变其超时时间。\n典型的估计方法：R ← αR + (1 - α)MM为前一个估计，R为当前测量，一般 α 取 1&#x2F;8。\n除了测量RTT，一般还会测量RTT偏差值：DevRTT，用于估算R一般会偏离M的程度：DevRTT ← (1 - β)DevRTT + β|R - M|同样是指数加权移动平均（EWMA）。β推荐值为 1&#x2F;4。\n超时间隔：一般设置为TimeoutInterval &#x3D; R + 4·DevRTT\ncwndcongestion window，简写“cwnd”，拥塞窗口。TCP 连接的每一端都由一个接收缓存、一个发送缓存和一些变量（LastByteRead、rwnd 等）组成。运行在发送方的 TCP 拥塞控制机制跟踪一个额外的变量，即拥塞窗口。它对一个 TCP 发送方能向网络中发送流量的速率进行限制。发送方取 cwnd 和 rwnd 中的最小值最为发送数据量的上限，可见滑动窗口不仅在流量控制中很重要，在拥塞控制中依然有作用。\n慢启动通过观察“新分组进入网络的速率应该与另一端返回确认的速率相同”而进行工作。{ asset_img 慢启动.PNG 慢启动 %}慢启动为发送方的 TCP 增加了一个拥塞窗口。TCP 建立链接时，cwnd 一般被置为 1 个报文段大小（也有的说是 1 个 MSS，基本相同，后续采用 MSS），即为初始发送数据的速率。发送端发送并等待第一个确认，当该确认到达，发送端设置 cwnd &#x3D; cwnd * 2，即 cwnd 大小为 2 个单位。同样发送这些数据，并等待这两个的确认；当确认到达，对每个确认增加一个报文段（结果依然是 cwnd * 2），即此时是 cwnd 为 4；…这是一种指数增加的关系。因此，TCP 发送速率起始慢，但在慢启动阶段以指数增长。所以可以理解成，“慢启动”名字的由来，是为了解决“TCP 连接初始阶段发送数据过慢的问题”。\n结束慢启动显然，网络环境必然存在一个阈值使得慢启动在一段时间后造成网络拥堵。而结束慢启动的方式一般是进入拥塞避免。\n检测拥塞发生简单来说有些指标会隐含“线路可能拥堵”：丢包和重复 ack、超时。重复确认（一般达到 3 次）意味着，该 ack 代表的序列号的前一部分数据没有正常到达接收端（否则应该收到确认），也就是发生了丢包，这种情况可以看作线路拥堵的征兆。另一种情况是超时。拥控机制使用 RTO 记录包传输的时限，超过该时限则认为拥塞发生。\n拥塞避免除了 cwnd 外，拥控机制里还有一个变量跟慢启动与拥塞避免关系密切：sshresh（Slow-Start Threshold，慢启动阈值的速记）。确认发生拥塞时，ssthresh 被置为 cwnd 的一半，同时结束慢启动并将 TCP 转移到拥塞避免模式。该状态下，TCP 会更为谨慎地选择增加 cwnd：每收到一个确认时将 cwnd 增加（1&#x2F;cwnd），即在 1 个 RTT 内最多为 cwnd 增加 1 个 MSS。可见，与慢启动阶段的乘性增&#x2F;指数增加相比，这是一种加性增&#x2F;线性增长（additive increase）。\n快速重传和快速恢复超时重传的问题在于有可能提前（重传定时器 RTO 还未停止计时）发现丢包，典型的是收到多次（一般为 3 次）重复 ack，这种情况可以看作是丢包发生，此时直接选择重传数据段，而非继续等待 RTO 溢出，这就叫快速重传。而快速重传完成后，恢复到拥塞避免状态，而非慢启动状态，这就是快速恢复。一般快速重传和快速恢复配合使用。具体的拥控实现有所不同。\n4 个定时器（Timer）重传定时器Retransmission TimeOut，TRO。重传超时时间的计算跟 RTT 相关，动态调整，用于指示“超过该时限未收到确认则可能发生丢包”。\n坚持定时器Persist Timer。TCP 通过窗口大小进行流量控制，接收方窗口大小为 0（发送方确认该值）时，发送方将不再发送携带数据的报文段而是等待非0窗口大小的 ACK 到来。考虑到：接收方将窗口大小置为非 0，但该确认并未到达（即发生丢失），双方有可能因为等待对方而使连接终止。\n保活定时器Keep Alive。连接可以在中间路由器崩溃、重启等各种情况下（只要两端主机没有重启）保持数小时甚至数月。非 TCP 规范的一部分。\n2MSL 定时器MSL，Maximum Segment Lifetime，最长报文段寿命：任何报文段在网络上存活的最长时间，超过这个时间报文将被丢弃。Linux 中 MSL 固定为 30s，RFC-793 定义 MSL 为 2min。而 2MSL 定时器（2 倍 MSL 时间）主要作用就是 TCP 主动发起关闭请求的一端在发送最后一个 ack 后进入 TIME_WAIT 状态的计时，即 2MSL 后关闭该状态。\n","categories":["CN"],"tags":["CN"]},{"title":"初级排序","url":"/2018/03/29/Algs/%E5%88%9D%E7%BA%A7%E6%8E%92%E5%BA%8F/","content":"[toc]几种基础排序算法，时间复杂度为O(n^2)。\n冒泡排序冒泡排序是最简单基础的排序算法：\n\n比较相邻的元素。如果第一个比第二个大，就交换他们两个；\n对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对。这步做完后，最后的元素会是最大的数；\n针对所有的元素重复以上的步骤，除了最后一个；\n持续每次对越来越少的元素重复上面的步骤，直到没有任何一对数字需要比较；其时间复杂度为O(n^2)，在原地交换，不需要额外的空间开销。是一种稳定排序。C++实现：void BubbleSort(int *a, int length)\n&#123;\n    for (int i = 0; i &lt; length; ++i)\n        for (int j = 0; j &lt; length - 1 - i; ++j)\n            if (a[j] > a[j + 1])\n                swap(a[j], a[j + 1]);\n&#125;\n\n插入排序来源于整理扑克牌的排序算法：将每一个元素插入到已经有序的序列中合适的位置，即前向交换使之到达正确位置。\nvoid InsertionSort(int *a, int length)\n&#123;\n    for (int i = 1; i &lt; length; ++i)\n        for (int j = i; j > 0; --j)\n            if (a[j] > a[j - 1])\n                swap(a[j], a[j - 1]);\n&#125;\n\n选择排序每次（第 i 次：0..N-1）都选择出剩余元素的最小值，将其置换到 i 的位置上去。\nvoid SelectionSort(int *a, int length)\n&#123;\n    for (int i = 0; i &lt; length; ++i) &#123;\n        int min = i;  // 最小元素的索引\n        for (int j = i + 1; j &lt; length; ++j)\n            if (a[j] > a[min])\n                min = j;\n            swap(a[i], a[min]);\n    &#125;\n&#125;\n\n希尔排序思想：使数组中任意间隔为 h 的元素都是有序的。类似于插入排序，只不过插入排序是交换相邻（间隔为1）元素，而希尔排序是交换间隔为 h 的元素。\n\nvoid ShellSort(int *a, int length)\n&#123;\n    int h = 1;\n    while (h &lt; length / 3)\n        h = 3 * h;\n    while (h >= 1) &#123;\n        // 将数组变为h有序\n        for (int i = h; i &lt; length; ++) &#123;\n            // 将a[i]插入到a[i-h]，a[i-2*h]，a[i-3h]...中\n            for (int j = i; j >= h &amp;&amp; a[j] &lt; a[j - h]; j -= h)\n                swap(a[j], a[j - h]);\n        &#125;\n        h = h / 3;\n    &#125;\n&#125;\n","categories":["Algs"],"tags":["Algs","Sort"]},{"title":"线性时间排序算法","url":"/2018/03/28/Algs/%E7%BA%BF%E6%80%A7%E6%97%B6%E9%97%B4%E6%8E%92%E5%BA%8F/","content":"比较排序的时间复杂度下限 O(n*logn) 是确定的。在这篇博客里有各种比较排序的对比。还有一类非比较排序算法，适用于一些特定情况。这种特定情况一般是对集合的范围界定：当集合满足一定条件，可以不使用比较的方式实现排序，从而获得优于比较排序下限的时间复杂度：线性时间复杂度内完成排序。常见的线性时间复杂度排序算法有：\n\n计数排序（Counting Sort）\n基数排序（Radix Sort）\n桶排序（Bucket Sort）\n\n计数排序限制条件：取值范围在 [m, n] 之间的整数，wiki解释集合分布在 [0, 100] 时最适合使用计数排序。原理：对每一个输入元素x，确定出小于x的元素个数，有了这一信息，就可以把x直接放在它在最终输出数组的位置上，例如，如果有17个元素小于x，则x就是属于第18个输出位置。当几个元素相同是，方案要略作修改。时间复杂度：O(n)。空间复杂度：O(n)。这是一种稳定排序。伪代码：\nCOUNTING-SORT(A;B; k)\nlet C[0..k] be a new array\nfor i = 0 to k\n\tC[i] = 0;\nfor j = 1 to A.length\n\tC[A[j]] = C[A[j]] + 1\n// C[i] now contains the number of elements equal to i .\nfor i = 1 to k\n\tC[i] = C[i] + C[i-1]\n// C[i] now contains the number of elements less than or equal to i .\n for j = A.length downto 1\n \tB[C[A[j]]] = A[j]\n \tC[A[j]] = C[A[j]] - 1\n\n基数排序原理：以十进制数组n为例，k&#x3D;10，最大数字的位数是d。把元素从个位排好序，然后再从十位排好序，，，，一直到元素中最大数的最高位排好序，那么整个元素就排好序了。时间复杂度：O(d(n+r))。空间复杂度：O(n+r)。这是一种稳定排序。伪代码：\nRADIX-SORT(A, d)\nfor  i = 1 to d\n\tuse a stable sort  to sort array A on digit i.\n\n桶排序假定数据服从均匀分布，均匀独立分布在[0， 1)区间。假设有m个桶，即将区间划分为m个大小相同的子区间。将n个元素分别存放到相应的桶中，再对各个桶进行排序，如插入排序。最后遍历每个桶，按照次序列出所有元素即可。时间复杂度：平均为O(n)。空间复杂度：O(n)。伪代码：\nBUCKET-SORT(A)\nn = A.length\nlet B[0.. n-1] be a new array\nfor i = 0 to n-1\n\tmake B[i] an empty list\nfor i = 1 to n\n\tinsert A[i] into B[⌊A[i]⌋]\nfor i = 0 to n-1\n\tsort list B[i] with insertion sort\nconcatenate the lists B[0], B[i],...B[n-1] together in order.\n","categories":["Algs"],"tags":["Algs","Sort"]},{"title":"about","url":"/about/index.html","content":"A computer programmer based in hangzhou, China.@alibaba.Ex@kwai.Ex@baidu ABC.\ngithub:https://github.com/lazy-snail\n","categories":[],"tags":[]}]